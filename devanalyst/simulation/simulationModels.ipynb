{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from random import choices\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\users\\aleja\\documents\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\statics.ipynb\n",
      "importing Jupyter notebook from c:\\users\\aleja\\documents\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\businessObjects.ipynb\n"
     ]
    }
   ],
   "source": [
    "import devanalyst.simulation.statics as S_\n",
    "from devanalyst.simulation.businessObjects import Ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stochastic Utilities</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     4,
     13
    ]
   },
   "outputs": [],
   "source": [
    "class Random():\n",
    "# Helper class to make random choices, but with a consistent generator instance across all calling sequences \n",
    "# so that if required a deterministic output is produced system-wide from a single seed.\n",
    "\n",
    "    def __init__(self):\n",
    "        self.seed = None\n",
    "        self.random = np.random.RandomState()\n",
    "        \n",
    "    def reset(self, seed):\n",
    "        self.seed = seed\n",
    "        self.random = np.random.RandomState(self.seed)\n",
    "        \n",
    "    # Returns a random element from an array. Returns None if array is empty\n",
    "    def pickOne(self, array):\n",
    "        if len(array)==0:\n",
    "            return None\n",
    "        return array[self.random.randint(0, len(array))]\n",
    "\n",
    "    # Returns a random index from a Pandas Series\n",
    "    def pickOneIdx(self, series):\n",
    "        return series.index[self.random.randint(0, len(series))]   \n",
    "\n",
    "    # Returns an integer corresponding to a random duration between 1 day and the maxDuration. \n",
    "    def pickHowLong(self, maxDuration):\n",
    "        return self.random.randint(1, maxDuration +1) \n",
    "    \n",
    "    # Returns a random member of the population, selected with a likelihood given by the weights\n",
    "    #\n",
    "    # -population: a list of possible values over which to take a random selection\n",
    "    # -weights: a list of equal size to population. The probability of selecting a particular item \n",
    "    # population[x] is equal to weights[x] divided by the sum of all weights.\n",
    "    # If the sum of all weights is 0, or its length different than that of population, it returns None\n",
    "    def pickOneWithWeights(self, population, weights):\n",
    "        if len(population) != len(weights):\n",
    "            return none\n",
    "        total = sum(weights)\n",
    "        if total == 0:\n",
    "            return None\n",
    "\n",
    "        probalityDist = []\n",
    "        for w in weights:\n",
    "            probalityDist.append(w/total)\n",
    "        return self.random.choice(population, 1, replace=False, p=probalityDist)[0] # Pick 1 selection only, without replacement\n",
    "    \n",
    "    # Selects a list of integers corresponding to a random subset of indices from the given collection. The returned\n",
    "    # list has a minimum size of 1 and a maximum size less than the given collection, unless the collection is \n",
    "    # has length less than 2, in which case an empty list is returned\n",
    "    #\n",
    "    # -collection: a list of objects\n",
    "    def pickSubsetIndices(self, collection):\n",
    "        if len(collection) < 2:\n",
    "            return []\n",
    "        \n",
    "        subset_size    = self.random.randint(1, len(collection))\n",
    "        subset_indices = self.random.choice(range(subset_size), subset_size, replace=False)\n",
    "        return list(subset_indices)\n",
    "    \n",
    "    # Returns a list corresponding to a random subset of the given collection. It may be empty, be the whole\n",
    "    # collection, or anything in between,\n",
    "    # -collection: a list of objects\n",
    "    def pickSubset(self, collection):\n",
    "        subset_size    = self.random.randint(0, len(collection))\n",
    "        subset         = self.random.choice(collection, subset_size, replace=False)\n",
    "        return list(subset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ModelsConfig:\n",
    "    \n",
    "    # -costModels: array of CostModel instances, each representing an independent driver for how actual costs deviate from\n",
    "    # estimates. Thus the real cost is obtained by applying all the models in succession to the estimate.\n",
    "    # -qualityModels: TBD\n",
    "    # -allocationModel: an instance of an AllocationModel\n",
    "    def __init__(self, costModels, qualityModels, allocationModel):\n",
    "        self.costModels        = costModels\n",
    "        self.qualityModels     = qualityModels\n",
    "        self.allocationModel   = allocationModel\n",
    "        \n",
    "        self.random            = Random() # used for all stochastic-related calculations.\n",
    "        self.globalRepo        = None # Set after construction, once the repos have been built\n",
    "        self.context           = None #Should be set in each cycle of the release (changes per cycle), not at instance construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0,
     7,
     40,
     70,
     77,
     87,
     104,
     111,
     121,
     124,
     129,
     132,
     140
    ]
   },
   "outputs": [],
   "source": [
    "class Distribution:\n",
    "# Helper class of class-statc utilities for distributions.\n",
    "# A distribution is represented as a dictionary, where the keys are the \"x axis\" (the possible values\n",
    "# for for the random varible behind the distribution) and the value for each key are the \"y axis\" of the distribution. \n",
    "# Notice that distributions are not necessarily normalized, i.e., the sume of the 'y' values across all 'x''s may not \n",
    "# equal 1.0. So the 'y's are more like weights than probabilities.\n",
    "    \n",
    "    def measureDistributionDistance(dist1, dist2):\n",
    "        # First ensure that the distributions (represented by dictionaries) have the same keys, padding with 0's\n",
    "        # if needed\n",
    "        \n",
    "        prob1 = dist1 #self._normalizeDistribution(dist1)\n",
    "        prob2 = dist2 #self._normalizeDistribution(dist2)\n",
    "        \n",
    "        if (prob1 == None): # Boundary case. Treat it like it is all 0's\n",
    "            prob1 = {0:0}\n",
    "        if (prob2 == None): # Boundary case. Treat it like it is all 0's\n",
    "            prob2 = {0:0}\n",
    "        \n",
    "        keys1 = set(prob1.keys())\n",
    "        keys2 = set(prob2.keys())\n",
    "        all_keys = keys1.union(keys2)\n",
    "        for x in all_keys:\n",
    "            if x not in keys1:\n",
    "                prob1[x] = 0.0\n",
    "            if x not in keys2:\n",
    "                prob2[x] = 0.0\n",
    "        \n",
    "        # Now compute the L2 difference of the distributions\n",
    "        sum_of_squares = 0\n",
    "        for x in all_keys:\n",
    "            f1 = prob1[x]\n",
    "            f2 = prob2[x]\n",
    "            sum_of_squares += (f1-f2)*(f1-f2)\n",
    "        return math.sqrt(sum_of_squares)    \n",
    "\n",
    "    # Computes an attractiveness score for selecting x, based on the impact that selecting it\n",
    "    # would have on the runningDist in terms of whether it gets it closer or not to the targetDist. \n",
    "    # Attractiveness is higher if the 'distance' between the running and target\n",
    "    # distributions is reduced. If selecting the item ends up increasing the distance then its attractiveness is negative.\n",
    "    def calcAttractiveness(x, runningDist, targetDist):\n",
    "        \n",
    "        initial_distance = Distribution.measureDistributionDistance(runningDist, targetDist)\n",
    "        \n",
    "        updatedDist = Distribution._appendToUnnormalizedDistribution(runningDist, x)\n",
    "\n",
    "        final_distance = Distribution.measureDistributionDistance(updatedDist, targetDist)\n",
    "        \n",
    "        attractiveness = initial_distance - final_distance\n",
    "        return attractiveness\n",
    "\n",
    "    # Ramdomly selects a value in remainingDist, with random selection weighted by how much closer it\n",
    "    # brings runningDist towards targetDist using L2 measure\n",
    "    def pickUsingProximityToTarget(runningDist,  remainingDist, targetDist, modelsConfig):\n",
    "        weights = []\n",
    "        for estimate in remainingDist.keys():\n",
    "            attractiveness = Distribution.calcAttractiveness(estimate, runningDist, targetDist)\n",
    "            \n",
    "            # Must have non-negative weights, since they trigger a probability distribution. Treat negative\n",
    "            # attractiveness as a 0 weight\n",
    "            if attractiveness < 0:\n",
    "                weights.append(0)\n",
    "            else:\n",
    "                weights.append(attractiveness)\n",
    "            \n",
    "        selection = modelsConfig.random.pickOneWithWeights(list(remainingDist.keys()), weights)\n",
    "        return selection\n",
    "    \n",
    "    # Ramdomly selects a value in remainingDist, with random selection weighted by the weights in \n",
    "    # remainingDist\n",
    "    def pickUsingFrequency(remainingDist, modelsConfig):\n",
    "        #selection = modelsConfig.random.pickOneWithWeights(list(remainingDist.keys()), list(remainingDist.values()))\n",
    "        \n",
    "        sample = Distribution.dist_to_sample(remainingDist)\n",
    "        selection = modelsConfig.random.pickOne(sample)\n",
    "        return selection\n",
    "\n",
    "    def _appendToUnnormalizedDistribution(dist, estimate):\n",
    "        \n",
    "        result = dist.copy()\n",
    "        if estimate in result.keys():\n",
    "            result[estimate] =result[estimate] + 1\n",
    "        else:\n",
    "            result[estimate] = 1\n",
    "        return result    \n",
    "    # Returns a probability distribution (i.e., sum of \"y's\" is 1.0) by scaling down the y values of the given\n",
    "    # distribution\n",
    "    def _normalizeDistribution(dist):\n",
    "\n",
    "        area = 0\n",
    "        for x in dist.keys():\n",
    "            area += dist[x]\n",
    "            \n",
    "        if area == 0:\n",
    "            return None\n",
    "        \n",
    "        normalized_dist = {}\n",
    "                \n",
    "        for x in dist.keys():\n",
    "            normalized_dist[x] = dist[x]/area\n",
    "        return normalized_dist\n",
    "    \n",
    "    # Returns an array of the values of distribution, duplicating values as many times as their weight in the\n",
    "    # distribution\n",
    "    def dist_to_sample(distribution):\n",
    "        sample = []\n",
    "        for key in distribution:\n",
    "            for i in range(int(distribution[key])):\n",
    "                sample.append(key)\n",
    "        return sample\n",
    "    \n",
    "    def sample_to_dist(sample, number_of_bins):\n",
    "        distribution = {}\n",
    "        for e in sample:\n",
    "            x = Distribution.getBin(e, number_of_bins)                       \n",
    "            if x in distribution:\n",
    "                distribution[x] = distribution[x] + 1\n",
    "            else:\n",
    "                distribution[x] = 1                \n",
    "        return distribution    \n",
    "\n",
    "    def getBin(estimate, number_of_bins):        \n",
    "        return round((number_of_bins * estimate)/number_of_bins)\n",
    "    \n",
    "    def addToDist(pick, dist):\n",
    "        for k in pick.keys():\n",
    "            val = pick[k]\n",
    "            if k in dist.keys():\n",
    "                dist[k] += val\n",
    "            else:\n",
    "                dist[k] = val \n",
    "                \n",
    "    def removeFromDist(pick, dist):\n",
    "        for k in pick.keys():\n",
    "            val = pick[k]\n",
    "            if k in dist.keys():\n",
    "                dist[k] -= val\n",
    "            else:\n",
    "                dist[k] = -val\n",
    "                \n",
    "    def distIsEmpty(dist):\n",
    "        for k in dist.keys():\n",
    "            if dist[k] != 0:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CostModel:\n",
    "# Abstract class\n",
    "    \n",
    "    # Returns a cost multipier for the WorkItem 'item', i.e., a number equal to the ratio between the 'actual cost'\n",
    "    # (in man-days) of developing the 'item' and the 'estimated cost'\n",
    "    #\n",
    "    # -item: a WorkItem\n",
    "    def runModel(self, item, modelsConfig): \n",
    "        return # This is the abstract class, so this method should never be called as concrete class implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class DefaultCostModel (CostModel):\n",
    "# Default class for models that simulate how actual costs differ from estimates. Usually there might be different\n",
    "# implementations, each trying to capture a different dynamic with a different driver. This default class just assumes\n",
    "# everything takes longer than expected by a given delay\n",
    "\n",
    "    # -delay_pct: the percentage by which estimates are off. For example, a delay_pct of 0.25 means that a task\n",
    "    # estimated to take 10 man-days actually takes 12.5 man-days.\n",
    "    def __init__(self, delay_pct = 0.25):\n",
    "        self.delay_pct = delay_pct\n",
    "        return  \n",
    "    # \n",
    "    def runModel(self, item, modelsConfig):   \n",
    "        return 1 + self.delay_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def computeRealCost(item, modelsConfig):\n",
    "# Computes the real cost of delivering a work item, based on a number of 'factors', which are functions implementing a model\n",
    "# for what drives costs to differ from estimates.\n",
    "\n",
    "    cost = item.estimate;\n",
    "    for m in modelsConfig.costModels:\n",
    "        cost *= m.runModel(item, modelsConfig)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Sets the cost it takes to complete a task based on the profile of the developer completing it, as a percentage\n",
    "# of the original estimate of the task:\n",
    "class MeritocraticCostModel (CostModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        return \n",
    "    \n",
    "    # Sets deviation of real cost vs estimates depending on developer excellence\n",
    "    # Star - 100%\n",
    "    # Solid - 200%\n",
    "    # Mediocre - 400%\n",
    "    # QA: - 200%\n",
    "    #\n",
    "    # -item: a WorkItem instance\n",
    "    def runModel(self, item, modelsConfig):   \n",
    "        developer = modelsConfig.globalRepo.developersRepo.findDeveloper(item.owner)\n",
    "        if developer.profile == S_.STAR:\n",
    "            multiplier = 1.0\n",
    "        else:\n",
    "            if developer.profile == S_.SOLID:\n",
    "                multiplier = 2.0\n",
    "            else:\n",
    "                if developer.profile == S_.MEDIOCRE:\n",
    "                    multiplier = 4.0\n",
    "                else:\n",
    "                    multiplier = 3.0 # for new people and for everyone else\n",
    "            \n",
    "        return multiplier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Allocation Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class _AvailabilityCriterion:\n",
    "# Abstract parent class\n",
    "    def _getPeopleWithBandwidth(self, timeRequired, modelsConfig):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0,
     3,
     6,
     12,
     16,
     21,
     24,
     44,
     61,
     74,
     85,
     96,
     112
    ]
   },
   "outputs": [],
   "source": [
    "class AllocationModel:\n",
    "# Abstract class \n",
    "\n",
    "    def __init__(self):\n",
    "        self._resetLog()\n",
    "\n",
    "    def _resetLog(self):\n",
    "        self.log = {} # Log information of how allocation decisions are made. \n",
    "        self.log['Cycles'] = {}\n",
    "        \n",
    "    # Implemented by concrete classes.\n",
    "    # Mutates work by allocating WorkItem's to developers, depleting the workToPik\n",
    "    def _allocate_helper(self, work, workToPick, currentOrNext, modelsConfig): \n",
    "        return\n",
    "    \n",
    "    # Does any post processing after the main allocation logic, if any\n",
    "    def _post_process(self, work, modelsConfig, currentOrNext): \n",
    "        return\n",
    " \n",
    "    # Implemented by concrete classes.\n",
    "    # Picks the next \"preferred\" WorkItem to work on\n",
    "    def _pickItem(self, runningDist, remainingDist, targetDist, workToPick, modelsConfig):\n",
    "        return\n",
    "\n",
    "    def allocate(self, work, modelsConfig):\n",
    "        self._resetLog() # Log reflects a single call to allocate, so must be cleared from one call to another\n",
    "\n",
    "        workToPick = self._getWorkToPick(work)\n",
    "\n",
    "        self._allocate_helper(work, workToPick, True, modelsConfig) # mutates 'work' and 'workToPick'\n",
    "        self._post_process(work, modelsConfig, True)\n",
    "\n",
    "        # Now try again, but this time allocating any unused time to deliverables for the next sprint, i.e., use\n",
    "        # time left over from the current sprint to get a heat start on the work for the next sprint, borrowing next sprint's\n",
    "        # capacity since we only need to deliver then\n",
    "\n",
    "        #Update workToPick since we changed it in prior call to helper\n",
    "        workToPick = self._getWorkToPick(work)\n",
    "\n",
    "        self._allocate_helper(work, workToPick, False, modelsConfig) # mutates 'work' and 'workToPick'    \n",
    "        self._post_process(work, modelsConfig, False)\n",
    "        \n",
    "        return work    \n",
    "    \n",
    "    def _getWorkToPick(self, work):\n",
    "        unplanned = work.allocations[S_.UNPLANNED][S_.OWNER_TBD]\n",
    "        workToPick = []\n",
    "        workToPick.extend(unplanned[S_.PRODUCTION_BUGS])\n",
    "        workToPick.extend(unplanned[S_.DEV_TIME_BUGS])\n",
    "        workToPick.extend(unplanned[S_.UNFINISHED_STORIES])  \n",
    "        return workToPick\n",
    "        \n",
    "    # Returns an unnormalized distribution of the estimated effort required for the WorkItems in items.\n",
    "    # The distribution is represented as a dictionary, where the keys are the \"x axis\" (the possible values\n",
    "    # for estimates) and the value for each key are the \"y axis\" of the distribution (the count of how many\n",
    "    # WorkItems have such an estimate)\n",
    "    # \n",
    "    # NOTE: WorkItems that were partially progressed in prior sprints may have a residual estimate that is\n",
    "    # not a nice integer number, but a number with lots of decimal places. To avoid issues with having a distribution\n",
    "    # that is too finely cut we use bins of length 0.1 and classify each estimate in a bin. That way we limit\n",
    "    # the number of possibly values of 'x'\n",
    "    def _getUnnormalizedDistribution(self, items, context):\n",
    "        distribution = {}\n",
    "        \n",
    "        for item in items:\n",
    "            x = Distribution.getBin(item.estimate, context.sprintDuration)           \n",
    "            \n",
    "            if x in distribution:\n",
    "                distribution[x] = distribution[x] + 1\n",
    "            else:\n",
    "                distribution[x] = 1\n",
    "                \n",
    "        return distribution\n",
    "    \n",
    "    def _inferDistribution(self, work, context):\n",
    "        workAlreadyPlanned = []\n",
    "        for bucket in [S_.CURRENT_SPRINT, S_.NEXT_SPRINT]:\n",
    "            subwork = work.allocations[bucket]\n",
    "            for person in subwork.keys():\n",
    "                workAlreadyPlanned.extend(subwork[person][S_.PRODUCTION_BUGS])\n",
    "                workAlreadyPlanned.extend(subwork[person][S_.DEV_TIME_BUGS])\n",
    "                workAlreadyPlanned.extend(subwork[person][S_.UNFINISHED_STORIES])\n",
    "        \n",
    "        return self._getUnnormalizedDistribution(workAlreadyPlanned, context)\n",
    "\n",
    "    def _postLog(self, cycle, bucket, remainingDist, originalRunningDist, finalRunningDist):\n",
    "        \n",
    "        if cycle not in self.log['Cycles'].keys():\n",
    "            self.log['Cycles'][cycle] = {}\n",
    "        \n",
    "        self.log['Cycles'][cycle][bucket] = {'Remaining Dist': remainingDist, \\\n",
    "                      'Original Running Dist': originalRunningDist,\\\n",
    "                     'Final Running Dist': finalRunningDist}\n",
    "        \n",
    "\n",
    "\n",
    "    def _buildLog_df_Helper(self, targetDist, cycle, bucket, distName):\n",
    "\n",
    "        if bucket not in self.log['Cycles'][cycle].keys():\n",
    "            return 0,0,[]\n",
    "    \n",
    "        snapshotDist = self.log['Cycles'][cycle][bucket][distName]\n",
    "    \n",
    "        data = Distribution.dist_to_sample(snapshotDist)\n",
    "        distance = Distribution.measureDistributionDistance(targetDist, snapshotDist)    \n",
    "        if len(data)==0:\n",
    "            mean = 0\n",
    "        else:\n",
    "            mean = statistics.mean(data)\n",
    "        \n",
    "        return mean, distance, data\n",
    "\n",
    "    def buildLog_df(self, title, context):\n",
    "       \n",
    "        DEL = ' - '\n",
    "        logical_cols = ['Initial Size', 'Initial Mean', 'Initial Distance', 'Initial Data', \\\n",
    "               'Remaining Size', 'Remaining Mean', 'Remaining Distance', 'Remaining Data', \\\n",
    "               'Final Size', 'Final Mean', 'Final Distance', 'Final Data', \\\n",
    "                        'Bins']\n",
    "        log_dict = {}\n",
    "        actual_columns = ['Title', 'Cycle']\n",
    "        log_dict['Title'] = []\n",
    "        log_dict['Cycle'] = []\n",
    "        for bucket in [S_.CURRENT_SPRINT, S_.NEXT_SPRINT]:\n",
    "            for c in logical_cols:\n",
    "                real_col = c + DEL + bucket\n",
    "                actual_columns.append(real_col)\n",
    "                log_dict[real_col] = []\n",
    "    \n",
    "        targetDist = self.log['Target dist']\n",
    "    \n",
    "        for cycle in self.log['Cycles'].keys():\n",
    "            log_dict['Title'].                 append(title)\n",
    "            log_dict['Cycle'].                 append(cycle)\n",
    "            for bucket in [S_.CURRENT_SPRINT, S_.NEXT_SPRINT]:\n",
    "                  \n",
    "                mean, distance, data = self._buildLog_df_Helper(targetDist, cycle, bucket, 'Original Running Dist')\n",
    "\n",
    "                log_dict['Initial Size' + DEL + bucket].          append(len(data))\n",
    "                log_dict['Initial Mean' + DEL + bucket].          append(mean)\n",
    "                log_dict['Initial Distance' + DEL + bucket].      append(distance)\n",
    "                log_dict['Initial Data' + DEL + bucket].          append(data)\n",
    "        \n",
    "                mean, distance, data = self._buildLog_df_Helper(targetDist, cycle, bucket, 'Remaining Dist')\n",
    "\n",
    "                log_dict['Remaining Size' + DEL + bucket].        append(len(data))\n",
    "                log_dict['Remaining Mean' + DEL + bucket].        append(mean)\n",
    "                log_dict['Remaining Distance' + DEL + bucket].    append(distance)\n",
    "                log_dict['Remaining Data' + DEL + bucket].        append(data)\n",
    "        \n",
    "                mean, distance, data = self._buildLog_df_Helper(targetDist, cycle, bucket, 'Final Running Dist')\n",
    "\n",
    "                log_dict['Final Size' + DEL + bucket].            append(len(data))\n",
    "                log_dict['Final Mean' + DEL + bucket].            append(mean)\n",
    "                log_dict['Final Distance' + DEL + bucket].        append(distance)\n",
    "                log_dict['Final Data' + DEL + bucket].            append(data)\n",
    "                \n",
    "                #log_dict['Color' + DEL + bucket].                 append(COLOR)\n",
    "                log_dict['Bins' + DEL + bucket].                  append(context.sprintDuration)\n",
    "                \n",
    "        log_df = pd.DataFrame(log_dict, columns=actual_columns)   \n",
    "        return log_df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class _GreedyAvailabilityCriterion (_AvailabilityCriterion):  \n",
    "    \n",
    "    def __init__(self, work, currentOrNext):\n",
    "        self.work = work\n",
    "        self.currentOrNext = currentOrNext\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def _getPeopleWithBandwidth(self, timeRequired, modelsConfig):\n",
    "        ctx = modelsConfig.context\n",
    "        if self.currentOrNext:\n",
    "            available = self.work.committedTime(ctx.sprintDuration)[['Developer', 'Bandwidth']]\n",
    "            return list(available[available['Bandwidth'] >= timeRequired]['Developer'])\n",
    "            \n",
    "        else:\n",
    "            available = self.work.committedTime(ctx.sprintDuration)[['Developer', 'NEXT SPRINT Bandwidth']]\n",
    "            # Filter to only developers who have 'carry over' bandwidth from this sprint into the next one\n",
    "            haveCarryOver = available[available['NEXT SPRINT Bandwidth'] > ctx.sprintDuration] \n",
    "            return list(haveCarryOver[haveCarryOver['NEXT SPRINT Bandwidth'] >= timeRequired]['Developer'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     26,
     69
    ]
   },
   "outputs": [],
   "source": [
    "class GreedyAllocationModel (AllocationModel):\n",
    "# For a sprint, allocates work to developers by maximizing the planned tasks for each developer.\n",
    "# So as long as the developer has some bandwidth left in the sprint, the algorithm will search for a user story\n",
    "# that can be done in the remaining time.\n",
    "# As a result, this algorithm has a tendency to plan short-duration user stories early in the release cycle, so that\n",
    "# later sprints in the release cycle need to deal with comparatively coarser-sized user stories. This causes the\n",
    "# release cycle to be unbalanced: later sprints have big-ticket items for the most part.\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GreedyAllocationModel, self).__init__()\n",
    "        return\n",
    "\n",
    "    def _selectAvailabilityCriterion(self, work, currentOrNext):\n",
    "        return _GreedyAvailabilityCriterion(work, currentOrNext)\n",
    "        \n",
    "    # Mutates 'work' and 'workToPick' by allocating WorkItem's to developers and in the process depleting\n",
    "    # partially or fully the 'workToPick'\n",
    "    #\n",
    "    # -workToPick: an array of WorkItem objects, corresponding to unplanned tasks that are candidate tasks to allocate\n",
    "    # to developers\n",
    "    # -work: a WorkAssignment instance reflecting a ScrumTeam's allocations and remaining bandwidth prior to the\n",
    "    # allocation this model will conduct. This model's allocation process will then mutate 'work' by reflecting in it\n",
    "    # tasks that are no longer unplanned but rather are now allocated to a particular developer.\n",
    "    # -currentOrNext: boolean to indicate if the allocation is being done for the current sprint or the next sprint. True \n",
    "    # for current, False for next.\n",
    "    # -modelsConfig: parameters for running the model (e.g., random generators)\n",
    "    def _allocate_helper(self, work, workToPick, currentOrNext, modelsConfig): \n",
    "        availabilityCriterion   = self._selectAvailabilityCriterion(work, currentOrNext) \n",
    "        \n",
    "        ctx = modelsConfig.context\n",
    "        \n",
    "        targetDist = self._getUnnormalizedDistribution(workToPick, ctx) \n",
    "\n",
    "        self.log['Target dist'] = targetDist\n",
    "        cycle = -1\n",
    "        while len(workToPick) > 0:\n",
    "\n",
    "            cycle += 1\n",
    "            \n",
    "            runningDist = self._inferDistribution(work, ctx) # Re-compute in each loop since work changes in each loop\n",
    "            remainingDist = self._getUnnormalizedDistribution(workToPick, ctx) # Re-compute as workToPick changes\n",
    "            \n",
    "            item = self._pickItem(runningDist, remainingDist, targetDist, workToPick, modelsConfig)\n",
    "\n",
    "            # In next cycle of loop don't want to encounter this item, as it would be processed by then           \n",
    "            workToPick.remove(item) \n",
    "            \n",
    "            \n",
    "            timeRequired = item.estimate * (1-item.percentAchieved)\n",
    "        \n",
    "            peopleWithTimeToDoIt = availabilityCriterion._getPeopleWithBandwidth(timeRequired, modelsConfig)\n",
    "            \n",
    "            potentialOwner = modelsConfig.random.pickOne(peopleWithTimeToDoIt)\n",
    "            \n",
    "            if potentialOwner == None:\n",
    "                # This WorkItem can't be done in this sprint, as nobody has enough time for the effort it requires.\n",
    "                # Try with some other work item\n",
    "                 continue\n",
    "            \n",
    "            if currentOrNext:\n",
    "                work.reAssign(item, potentialOwner, S_.CURRENT_SPRINT)\n",
    "                newRunningDist = self._inferDistribution(work, ctx)\n",
    "                self._postLog(cycle, S_.CURRENT_SPRINT, remainingDist, runningDist, newRunningDist)\n",
    "            else:\n",
    "                work.reAssign(item, potentialOwner, S_.NEXT_SPRINT) \n",
    "                newRunningDist = self._inferDistribution(work, ctx)\n",
    "                self._postLog(cycle, S_.NEXT_SPRINT, remainingDist, runningDist, newRunningDist)\n",
    "\n",
    "    # Picks the next \"preferred\" WorkItem to work on\n",
    "    def _pickItem(self, runningDist, remainingDist, targetDist, workToPick, modelsConfig):\n",
    "        \n",
    "        item = modelsConfig.random.pickOne(workToPick)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     1,
     3,
     11
    ]
   },
   "outputs": [],
   "source": [
    "# Filters available developers to only those who don't have unfinished work from prior sprints\n",
    "class _NoLaggardsAvailabilityCriterion (_AvailabilityCriterion):  \n",
    "    \n",
    "    def __init__(self, work, currentOrNext):\n",
    "        self.work = work\n",
    "        self.currentOrNext = currentOrNext\n",
    "    \n",
    "        return\n",
    "    \n",
    "    # -timeRequired: a double indicating how much time we need for a task being resourced\n",
    "    # -ctx: a ReleaseCycleContext instance for the sprint for which we seek people available\n",
    "    def _getPeopleWithBandwidth(self, timeRequired, modelsConfig):\n",
    "        \n",
    "        ctx = modelsConfig.context\n",
    "        \n",
    "        # WARNING: Avoid the use of sets, even though it is tempting since set difference is more succinct\n",
    "        # than list difference (i.e., to remove laggards it is easier with a set).\n",
    "        # Reason: using sets introduces a bug whereby the return values from this method are not deterministic, so\n",
    "        # regression tests fail.\n",
    "        \n",
    "        priorCommittments = self.work.committedTasks()\n",
    "        \n",
    "        laggards, stuckWork = NoLaggardsAllocationModel._identify_laggards(self.work, modelsConfig, tolerance=2)\n",
    "                \n",
    "        #laggards = list(priorCommittments[priorCommittments['Most Recently Assigned in Sprint'] +2 <= ctx.sprint]['Owner'])\n",
    "        \n",
    "        if self.currentOrNext:\n",
    "            available = self.work.committedTime(ctx.sprintDuration)[['Developer', 'Bandwidth']]\n",
    "            potential = list(available[available['Bandwidth'] >= timeRequired]['Developer'])\n",
    "            return NoLaggardsAllocationModel._list_different(potential, laggards)\n",
    "            \n",
    "        else: \n",
    "            available = self.work.committedTime(ctx.sprintDuration)[['Developer', 'NEXT SPRINT Bandwidth']]\n",
    "            # Filter to only developers who have 'carry over' bandwidth from this sprint into the next one\n",
    "            haveCarryOver = available[available['NEXT SPRINT Bandwidth'] > ctx.sprintDuration] \n",
    "            potential = list(haveCarryOver[haveCarryOver['NEXT SPRINT Bandwidth'] >= timeRequired]['Developer'])\n",
    "            \n",
    "            # Unlike when self.currentOrNext=True, in this case we don't reduce the list of candidates by \n",
    "            # removing the laggards. It is OK for laggards\n",
    "            # to built a backlog for the next sprint - that way they stay fully utilized if we did not give them\n",
    "            # enough work in the current release due to they being a laggard\n",
    "            return potential          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [
     18,
     28,
     88,
     121
    ]
   },
   "outputs": [],
   "source": [
    "class NoLaggardsAllocationModel (GreedyAllocationModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NoLaggardsAllocationModel, self).__init__()\n",
    "        return\n",
    "    \n",
    "    def _selectAvailabilityCriterion(self, work, currentOrNext):\n",
    "        return _NoLaggardsAvailabilityCriterion(work, currentOrNext)\n",
    "\n",
    "    def _post_process(self, work, modelsConfig, currentOrNext): \n",
    "        if currentOrNext:\n",
    "            self._balanceWork(work, modelsConfig)\n",
    "            self._stealWork(work, modelsConfig, tolerance=2) # Only steal work from the current sprint's tasks    \n",
    "\n",
    "    # Returns a subset of 'list1' corresponding to elements of 'list1' that are not in 'list2'\n",
    "    # \n",
    "    # Used as a means to avoid using sets to make differences of collections, since sets have non-deterministic\n",
    "    # orderings and that leads to regression tests failures.\n",
    "    def _list_different(list1, list2):\n",
    "        result = []\n",
    "        for elt in list1:\n",
    "            if elt not in list2:\n",
    "                result.append(elt)\n",
    "        return result    \n",
    "    \n",
    "    # Returns two lists:\n",
    "    #    - A list of 'laggards', i.e., developers who are behind in their work because they have some user stories that \n",
    "    #      are less than 50% done and which were allocated to them more than 'tolerance'-many sprints ago.\n",
    "    def _identify_laggards(work, modelsConfig, tolerance):        \n",
    "        teamsRepo = modelsConfig.globalRepo.teamsRepo\n",
    "        stuckWork = []\n",
    "        laggards = [] # Developers from whom work might be stolen\n",
    "        for person in work.allocations[S_.CURRENT_SPRINT].keys():\n",
    "            items = work.allocations[S_.CURRENT_SPRINT][person][S_.UNFINISHED_STORIES]\n",
    "            for item in items:\n",
    "                uss = modelsConfig.globalRepo.teamsRepo.getUserStoryStatus(item.userStoryId)\n",
    "                sprint_assigned = uss.retrieveMostRecentAssignment()\n",
    "#                if item.sprintPlanned + tolerance >= modelsConfig.context.sprint:\n",
    "                if sprint_assigned + tolerance >= modelsConfig.context.sprint:\n",
    "                    continue # item is not that far behind yet to be stolen, as it is within tolerance\n",
    "                uss = teamsRepo.getUserStoryStatus(item.userStoryId)\n",
    "                if uss.percentAchieved > 0.5:\n",
    "                    continue # Current developer has done at least 50% of this old story. Allow the dude to finish it up\n",
    "\n",
    "                #If we get this far, we have an old story that is not getting enough action. Think of giving it to someone\n",
    "                #else\n",
    "                stuckWork.append(item)\n",
    "                laggards.append(person)\n",
    "        return laggards, stuckWork\n",
    "\n",
    "    # In the event that some developer has no user story to implement at all, this function will search for\n",
    "    # other developers with multipe user stories to implement, and if so will take the one that is most incomplete\n",
    "    # and try to re-assign it to the unutilized developers\n",
    "    def _balanceWork(self, work, modelsConfig):\n",
    "        resourcing          = work.committedTime(modelsConfig.context.sprintDuration)\n",
    "        unemployed          = list(resourcing[resourcing['Implementation (#)']==0]['Developer'])\n",
    "        if (S_.OWNER_TBD in unemployed):\n",
    "            unemployed.remove(S_.OWNER_TBD)\n",
    "        \n",
    "        bandwidths          = resourcing['Bandwidth']\n",
    "        utilisation_cutoff  = bandwidths.mean() + bandwidths.std()\n",
    "        under_utilized      = list(resourcing[resourcing['Bandwidth'] > utilisation_cutoff]['Developer'])\n",
    "        if (S_.OWNER_TBD in under_utilized):\n",
    "            under_utilized.remove(S_.OWNER_TBD)\n",
    "            \n",
    "        # Merge the unemployed and the underemployed, without duplicates\n",
    "        candidates = unemployed\n",
    "        for person in under_utilized:\n",
    "            if person not in candidates:\n",
    "                candidates.append(person)\n",
    "        \n",
    "        steal_from          = list(resourcing[resourcing['Implementation (#)'] > 1]['Developer'])\n",
    "        if (S_.OWNER_TBD in steal_from):\n",
    "            steal_from.remove(S_.OWNER_TBD)\n",
    "\n",
    "        items_to_steal      = []\n",
    "        for person in steal_from:\n",
    "            wis = work.allocations[S_.CURRENT_SPRINT][person][S_.UNFINISHED_STORIES]\n",
    "            most_incomplete_item = wis[0]\n",
    "            most_incomplete_uss  = modelsConfig.globalRepo.teamsRepo.getUserStoryStatus(most_incomplete_item.userStoryId)\n",
    "            for item in wis:\n",
    "                uss = modelsConfig.globalRepo.teamsRepo.getUserStoryStatus(item.userStoryId)\n",
    "                if (uss.percentAchieved < most_incomplete_uss.percentAchieved):\n",
    "                    most_incomplete_item = item\n",
    "                    most_incomplete_uss  = uss\n",
    "            items_to_steal.append(most_incomplete_item)\n",
    "        \n",
    "        for person in candidates: # Give 1 story to work on to each person who is unemployed or under utilised\n",
    "            if len(items_to_steal) > 0:\n",
    "                item = items_to_steal[0]\n",
    "                items_to_steal.remove(item)\n",
    "                work.reAssign(item, person, S_.CURRENT_SPRINT)\n",
    "\n",
    "\n",
    "    # Re-allocates work from one developer to another to developers who have no other work to do \n",
    "    #\n",
    "    # -work: a WorkAssignment instance. Normally this method is called when 'work' is filled using the normal\n",
    "    # greedy algorithm, i.e., any backlog work has been assigned to someone if bandwidth exists. If indeed bandwidth\n",
    "    # has been totally used up then this method will do nothing. But if there is extra bandwidth, this method\n",
    "    # will re-allocate work from laggard developers to those with the extra bandwidth.\n",
    "    # -modelsConfig: overall configuration for release simulation\n",
    "    # -tolerance: maximum number of sprints that a WorkItem can be behind before being a candidate for stealing\n",
    "    def _stealWork(self, work, modelsConfig, tolerance):\n",
    "                \n",
    "        laggards, stuckWork = NoLaggardsAllocationModel._identify_laggards(work, modelsConfig, tolerance)\n",
    "        \n",
    "        # Now get all the future work for the laggards. If they struggle with the current work, most likely they\n",
    "        # won't get to the future work either, so that future work is ripe for stealing\n",
    "        laggardsBacklog = []\n",
    "        for person in laggards:\n",
    "            items = work.allocations[S_.NEXT_SPRINT][person][S_.UNFINISHED_STORIES]\n",
    "            laggardsBacklog.extend(items)\n",
    "        \n",
    "        # Now steal the work, first from the laggards' backlog, and then if there is still bandwidth,\n",
    "        # from the stuck work. First steal for completion in the current sprint, and later for the next sprint\n",
    "        #self._stealFromList(laggardsBacklog, laggards, work, modelsConfig, False)\n",
    "        laggardsBacklog_remaining = self._stealFromList(laggardsBacklog,           \n",
    "                                                        laggards, work, modelsConfig,\n",
    "                                                        S_.NEXT_SPRINT,    \n",
    "                                                        S_.CURRENT_SPRINT)\n",
    "        stuckWork_remaining       = self._stealFromList(stuckWork,                 \n",
    "                                                        laggards, work, modelsConfig,\n",
    "                                                        S_.CURRENT_SPRINT, \n",
    "                                                        S_.CURRENT_SPRINT)\n",
    "        self                            ._stealFromList(laggardsBacklog_remaining, \n",
    "                                                        laggards, \n",
    "                                                        work, modelsConfig,\n",
    "                                                        S_.NEXT_SPRINT,    \n",
    "                                                        S_.NEXT_SPRINT)\n",
    "        self                            ._stealFromList(stuckWork_remaining,       \n",
    "                                                        laggards, work, modelsConfig,\n",
    "                                                        S_.CURRENT_SPRINT, \n",
    "                                                        S_.NEXT_SPRINT)\n",
    "        \n",
    "            \n",
    "    def _stealFromList(self, workToSteal, laggards, work, modelsConfig, fromBucket, toBucket):\n",
    "        teamsRepo = modelsConfig.globalRepo.teamsRepo\n",
    "        remaining = workToSteal\n",
    "        if (toBucket == S_.CURRENT_SPRINT):\n",
    "            currentOrNext = True\n",
    "        else:\n",
    "            currentOrNext = False\n",
    "        availabilityCriterion = self._selectAvailabilityCriterion(work, currentOrNext)\n",
    "        for item in workToSteal:\n",
    "            timeRequired = item.estimate * (1-item.percentAchieved)\n",
    "        \n",
    "            peopleWithTimeToDoIt = availabilityCriterion._getPeopleWithBandwidth(timeRequired, modelsConfig)\n",
    "            candidates = NoLaggardsAllocationModel._list_different(peopleWithTimeToDoIt, laggards)\n",
    "            potentialOwner = modelsConfig.random.pickOne(candidates)\n",
    "            \n",
    "            if potentialOwner == None:\n",
    "                # This WorkItem can't be done in this sprint, as nobody has enough time for the effort it requires.\n",
    "                # Try with some other work item\n",
    "                 continue\n",
    "            uss = teamsRepo.getUserStoryStatus(item.userStoryId) \n",
    "            work.reAssign(item, potentialOwner, toBucket, fromBucket)\n",
    "            remaining.remove(item)\n",
    "        return remaining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0,
     21,
     72
    ]
   },
   "outputs": [],
   "source": [
    "class BalancedAllocationModel (AllocationModel):\n",
    "# For a sprint, allocates work to developers by trying to keep a roughly average user story size across all sprints\n",
    "# in the release.\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BalancedAllocationModel, self).__init__()\n",
    "        return\n",
    "\n",
    "    # Mutates 'work' and 'workToPick' by allocating WorkItem's to developers and in the process depleting\n",
    "    # partially or fully the 'workToPick'\n",
    "    #\n",
    "    # -workToPick: an array of WorkItem objects, corresponding to unplanned tasks that are candidate tasks to allocate\n",
    "    # to developers\n",
    "    # -work: a WorkAssignment instance reflecting a ScrumTeam's allocations and remaining bandwidth prior to the\n",
    "    # allocation this model will conduct. This model's allocation process will then mutate 'work' by reflecting in it\n",
    "    # tasks that are no longer unplanned but rather are now allocated to a particular developer.\n",
    "    # -currentOrNext: boolean to indicate if the allocation is being done for the current sprint or the next sprint. True \n",
    "    # for current, False for next.\n",
    "    # -modelsConfig: parameters for running the model (e.g., random generators)\n",
    "    def _allocate_helper(self, work, workToPick, currentOrNext, modelsConfig): \n",
    "        \n",
    "        if (len(workToPick) == 0):\n",
    "            return # Nothing to do, and if we don't return may get an assertion below as we assume there is work to pick\n",
    "        \n",
    "        ctx = modelsConfig.context\n",
    "        \n",
    "        availabilityCriterion   = _GreedyAvailabilityCriterion(work, currentOrNext)  \n",
    "        \n",
    "        # For debugging - we want to make sure that after the while loop we did allocate at least something, so\n",
    "        # keep track of when we allocate stuff\n",
    "        something_was_allocated = False\n",
    "        assertion_info = {}\n",
    "        assertion_info['modelsConfig context'] = modelsConfig.context\n",
    "        assertion_info['len(workToPick) at start'] = len(workToPick)\n",
    "        \n",
    "        targetDist = self._getUnnormalizedDistribution(workToPick, ctx) \n",
    "        while len(workToPick) > 0:\n",
    "            runningDist = self._inferDistribution(work, ctx) # Re-compute in each loop since work changes in each loop\n",
    "            remainingDist = self._getUnnormalizedDistribution(workToPick, ctx)    \n",
    "                        \n",
    "            chosenItem = self._pickItem(runningDist, remainingDist, targetDist, workToPick, modelsConfig)\n",
    "            \n",
    "            # In next cycle of loop don't want to encounter this item, as it would be processed by then\n",
    "            workToPick.remove(chosenItem)\n",
    "            itemAttractiveness = Distribution.calcAttractiveness(chosenItem.estimate, runningDist, targetDist)\n",
    "            if (itemAttractiveness <= 0):\n",
    "                continue\n",
    "            \n",
    "            timeRequired = chosenItem.estimate * (1-chosenItem.percentAchieved)\n",
    "        \n",
    "            peopleWithTimeToDoIt = availabilityCriterion._getPeopleWithBandwidth(timeRequired, modelsConfig)\n",
    "            \n",
    "            potentialOwner = modelsConfig.random.pickOne(peopleWithTimeToDoIt)\n",
    "            \n",
    "            if potentialOwner == None:\n",
    "                # This WorkItem can't be done in this sprint, as nobody has enough time for the effort it requires.\n",
    "                # Try with some other work item\n",
    "                 continue\n",
    "            \n",
    "            if currentOrNext:\n",
    "                work.reAssign(chosenItem, potentialOwner, S_.CURRENT_SPRINT)\n",
    "                something_was_allocated = True\n",
    "            else:\n",
    "                work.reAssign(chosenItem, potentialOwner, S_.NEXT_SPRINT) \n",
    "                something_was_allocated = True\n",
    "\n",
    "        # For debugging, confirm that we at least allocated something for the current release\n",
    "        assertion_info['len(workToPick) at end'] = len(workToPick)\n",
    "        if currentOrNext:\n",
    "            assert something_was_allocated, assertion_info\n",
    "        \n",
    "    # Picks the next \"preferred\" WorkItem to work on\n",
    "    def _pickItem(self, runningDist, remainingDist, targetDist, workToPick, modelsConfig):\n",
    " \n",
    "        chosenEstimate = Distribution.pickUsingProximityToTarget(runningDist, remainingDist, targetDist, modelsConfig)\n",
    "            \n",
    "        chosenItem = None\n",
    "        #find an item for such a chosenEstimate\n",
    "        for item in workToPick:\n",
    "            if item.estimate == chosenEstimate:\n",
    "                chosenItem = item\n",
    "        # Should never get here - should found an item \n",
    "        assert(chosenItem != None)\n",
    "        \n",
    "        return chosenItem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quality Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class QualityModel:\n",
    "# Abstract class \n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    # Implemented by concrete classes. Returns a list of Ticket instances and persists them to the TicketsRepo in\n",
    "    # modelsConfig.context.\n",
    "    # -modelsConfig: a ModelsConfig instance\n",
    "    def findBugs(self, modelsConfig): \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0,
     2,
     8,
     22,
     41,
     68
    ]
   },
   "outputs": [],
   "source": [
    "class DistributedLagQualityModel(QualityModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistributedLagQualityModel, self).__init__()\n",
    "        return\n",
    "    \n",
    "    # Returns a list of Ticket instances.\n",
    "    # -modelsConfig: a ModelsConfig instance\n",
    "    def findBugs(self, modelsConfig): \n",
    "        uss_list = DistributedLagQualityModel._findFinishedStories(modelsConfig.context, modelsConfig.globalRepo)\n",
    "        \n",
    "        bugs = []\n",
    "        current_sprint = modelsConfig.context.sprint\n",
    "        for uss in uss_list:\n",
    "            delivery_sprint = uss.sprintDelivered\n",
    "            lag = current_sprint - delivery_sprint\n",
    "            story = modelsConfig.globalRepo.storiesRepo.findStory(uss.userStoryId)\n",
    "            story_bugs = DistributedLagQualityModel._findDefectsInStory(lag, story, uss, modelsConfig)\n",
    "            bugs.extend(story_bugs)\n",
    "        return bugs\n",
    "\n",
    "    # Returns a list of UserStoryStatus instances, corresponding to all user stories that have been finished.\n",
    "    def _findFinishedStories(context, globalRepo):\n",
    "        uss_list = []\n",
    "        ids = globalRepo.storiesRepo.findIds()\n",
    "        for userStoryId in ids:\n",
    "            teamId = globalRepo.teamsRepo.getTeamId(userStoryId)\n",
    "            if (teamId != context.teamId):\n",
    "                # We only want the finished stories owned by the context.teamId to avoid a bug whereby we generate \n",
    "                # bugs for the stories of another team, whilst still in the same sprint as the user story\n",
    "                # that the bug is for, which is an assertion violation (since bugs should be found after\n",
    "                # a story is delivered, not in the same sprint, as might happen if a different team Y who is closing\n",
    "                # a sprint after another team X finds X's completed story and generates a bug for X's story\n",
    "                # in the same sprint)\n",
    "                continue \n",
    "            uss = globalRepo.teamsRepo.getUserStoryStatus(userStoryId)\n",
    "            if (uss.percentAchieved == 1.0):\n",
    "                uss_list.append(uss)\n",
    "        return uss_list\n",
    "    \n",
    "    # Returns a list of Ticket instances\n",
    "    def _findDefectsInStory(lag, userStory, uss, modelsConfig):\n",
    "        if lag < 1 or lag > 3: # No bugs for stories just finished or which were finished a while ago\n",
    "            return []\n",
    "        # Exposure is the probability of finding a bug. For now hardcode a 50% exposure distributed over \n",
    "        # 3 sprints with the surge in the middle one\n",
    "        if lag == 1:\n",
    "            exposure = 0.125\n",
    "        if lag == 2:\n",
    "            exposure = 0.25\n",
    "        if lag == 3:\n",
    "            exposure = 0.125\n",
    "        possible_defect_count  = [0, 1] # Possible values for number of bugs found\n",
    "        likelihoods            = [1-exposure, exposure]\n",
    "        defect_count           = modelsConfig.random.pickOneWithWeights(possible_defect_count, likelihoods)\n",
    "        \n",
    "        # Issue defect Tickets\n",
    "        defects = []\n",
    "        repo = modelsConfig.globalRepo.ticketsRepo\n",
    "        for i in range(defect_count):\n",
    "            costToFix = DistributedLagQualityModel._estimateCostToFix(userStory, modelsConfig)\n",
    "            ticketId = repo._nextTicketId()\n",
    "            ticket = Ticket(ticketId, userStory.userStoryId, costToFix, modelsConfig.context.sprint)\n",
    "            repo.addTicket(ticket)\n",
    "            defects.append(ticket)\n",
    "        return defects\n",
    "    \n",
    "        \n",
    "    def _estimateCostToFix(userStory, modelsConfig):\n",
    "    # For now hard-code a simplistic cost to fix: each bug costs 20% of the original estimate of the story.\n",
    "    # Better would be a percentage of the actual cost to develop.\n",
    "         return 0.20 * userStory.originalEstimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
