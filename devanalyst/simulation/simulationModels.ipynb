{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from random import choices\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\alex\\code\\labs\\devanalyst\\devanalyst\\simulation\\statics.ipynb\n",
      "importing Jupyter notebook from c:\\alex\\code\\labs\\devanalyst\\devanalyst\\simulation\\businessObjects.ipynb\n"
     ]
    }
   ],
   "source": [
    "import devanalyst.simulation.statics as S_\n",
    "from devanalyst.simulation.businessObjects import Ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stochastic Utilities</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     4,
     8,
     13,
     19,
     23
    ]
   },
   "outputs": [],
   "source": [
    "class Random():\n",
    "# Helper class to make random choices, but with a consistent generator instance across all calling sequences \n",
    "# so that if required a deterministic output is produced system-wide from a single seed.\n",
    "\n",
    "    def __init__(self):\n",
    "        self.seed = None\n",
    "        self.random = np.random.RandomState()\n",
    "        \n",
    "    def reset(self, seed):\n",
    "        self.seed = seed\n",
    "        self.random = np.random.RandomState(self.seed)\n",
    "        \n",
    "    # Returns a random element from an array. Returns None if array is empty\n",
    "    def pickOne(self, array):\n",
    "        if len(array)==0:\n",
    "            return None\n",
    "        return array[self.random.randint(0, len(array))]\n",
    "\n",
    "    # Returns a random index from a Pandas Series\n",
    "    def pickOneIdx(self, series):\n",
    "        return series.index[self.random.randint(0, len(series))]   \n",
    "\n",
    "    # Returns an integer corresponding to a random duration between 1 day and the maxDuration. \n",
    "    def pickHowLong(self, maxDuration):\n",
    "        return self.random.randint(1, maxDuration +1) \n",
    "    \n",
    "    # Returns a random member of the population, selected with a likelihood given by the weights\n",
    "    #\n",
    "    # -population: a list of possible values over which to take a random selection\n",
    "    # -weights: a list of equal size to population. The probability of selecting a particular item \n",
    "    # population[x] is equal to weights[x] divided by the sum of all weights.\n",
    "    # If the sum of all weights is 0, or its length different than that of population, it returns None\n",
    "    def pickOneWithWeights(self, population, weights):\n",
    "        if len(population) != len(weights):\n",
    "            return none\n",
    "        total = sum(weights)\n",
    "        if total == 0:\n",
    "            return None\n",
    "\n",
    "        probalityDist = []\n",
    "        for w in weights:\n",
    "            probalityDist.append(w/total)\n",
    "        return self.random.choice(population, 1, replace=False, p=probalityDist)[0] # Pick 1 selection only, without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ModelsConfig:\n",
    "    \n",
    "    # -costModels: array of CostModel instances, each representing an independent driver for how actual costs deviate from\n",
    "    # estimates. Thus the real cost is obtained by applying all the models in succession to the estimate.\n",
    "    # -qualityModels: TBD\n",
    "    # -allocationModel: an instance of an AllocationModel\n",
    "    # -random: a Random instance, used for all stochastic-related calculations.\n",
    "    # -context: a ReleaseCycleContext instance. Should be updated in each cycle of a release to reflect \n",
    "    # that cycle's environment.\n",
    "    def __init__(self, costModels, qualityModels, allocationModel):\n",
    "        self.costModels        = costModels\n",
    "        self.qualityModels     = qualityModels\n",
    "        self.allocationModel  = allocationModel\n",
    "        \n",
    "        self.random = Random()\n",
    "        self.context = None #Should be set in each cycle of the release (changes per cycle), not at instance construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     7,
     40,
     70,
     77,
     87,
     104,
     111,
     121,
     124,
     129,
     132,
     140
    ]
   },
   "outputs": [],
   "source": [
    "class Distribution:\n",
    "# Helper class of class-statc utilities for distributions.\n",
    "# A distribution is represented as a dictionary, where the keys are the \"x axis\" (the possible values\n",
    "# for for the random varible behind the distribution) and the value for each key are the \"y axis\" of the distribution. \n",
    "# Notice that distributions are not necessarily normalized, i.e., the sume of the 'y' values across all 'x''s may not \n",
    "# equal 1.0. So the 'y's are more like weights than probabilities.\n",
    "    \n",
    "    def measureDistributionDistance(dist1, dist2):\n",
    "        # First ensure that the distributions (represented by dictionaries) have the same keys, padding with 0's\n",
    "        # if needed\n",
    "        \n",
    "        prob1 = dist1 #self._normalizeDistribution(dist1)\n",
    "        prob2 = dist2 #self._normalizeDistribution(dist2)\n",
    "        \n",
    "        if (prob1 == None): # Boundary case. Treat it like it is all 0's\n",
    "            prob1 = {0:0}\n",
    "        if (prob2 == None): # Boundary case. Treat it like it is all 0's\n",
    "            prob2 = {0:0}\n",
    "        \n",
    "        keys1 = set(prob1.keys())\n",
    "        keys2 = set(prob2.keys())\n",
    "        all_keys = keys1.union(keys2)\n",
    "        for x in all_keys:\n",
    "            if x not in keys1:\n",
    "                prob1[x] = 0.0\n",
    "            if x not in keys2:\n",
    "                prob2[x] = 0.0\n",
    "        \n",
    "        # Now compute the L2 difference of the distributions\n",
    "        sum_of_squares = 0\n",
    "        for x in all_keys:\n",
    "            f1 = prob1[x]\n",
    "            f2 = prob2[x]\n",
    "            sum_of_squares += (f1-f2)*(f1-f2)\n",
    "        return math.sqrt(sum_of_squares)    \n",
    "\n",
    "    # Computes an attractiveness score for selecting x, based on the impact that selecting it\n",
    "    # would have on the runningDist in terms of whether it gets it closer or not to the targetDist. \n",
    "    # Attractiveness is higher if the 'distance' between the running and target\n",
    "    # distributions is reduced. If selecting the item ends up increasing the distance then its attractiveness is negative.\n",
    "    def calcAttractiveness(x, runningDist, targetDist):\n",
    "        \n",
    "        initial_distance = Distribution.measureDistributionDistance(runningDist, targetDist)\n",
    "        \n",
    "        updatedDist = Distribution._appendToUnnormalizedDistribution(runningDist, x)\n",
    "\n",
    "        final_distance = Distribution.measureDistributionDistance(updatedDist, targetDist)\n",
    "        \n",
    "        attractiveness = initial_distance - final_distance\n",
    "        return attractiveness\n",
    "\n",
    "    # Ramdomly selects a value in remainingDist, with random selection weighted by how much closer it\n",
    "    # brings runningDist towards targetDist using L2 measure\n",
    "    def pickUsingProximityToTarget(runningDist,  remainingDist, targetDist, modelsConfig):\n",
    "        weights = []\n",
    "        for estimate in remainingDist.keys():\n",
    "            attractiveness = Distribution.calcAttractiveness(estimate, runningDist, targetDist)\n",
    "            \n",
    "            # Must have non-negative weights, since they trigger a probability distribution. Treat negative\n",
    "            # attractiveness as a 0 weight\n",
    "            if attractiveness < 0:\n",
    "                weights.append(0)\n",
    "            else:\n",
    "                weights.append(attractiveness)\n",
    "            \n",
    "        selection = modelsConfig.random.pickOneWithWeights(list(remainingDist.keys()), weights)\n",
    "        return selection\n",
    "    \n",
    "    # Ramdomly selects a value in remainingDist, with random selection weighted by the weights in \n",
    "    # remainingDist\n",
    "    def pickUsingFrequency(remainingDist, modelsConfig):\n",
    "        #selection = modelsConfig.random.pickOneWithWeights(list(remainingDist.keys()), list(remainingDist.values()))\n",
    "        \n",
    "        sample = Distribution.dist_to_sample(remainingDist)\n",
    "        selection = modelsConfig.random.pickOne(sample)\n",
    "        return selection\n",
    "\n",
    "    def _appendToUnnormalizedDistribution(dist, estimate):\n",
    "        \n",
    "        result = dist.copy()\n",
    "        if estimate in result.keys():\n",
    "            result[estimate] =result[estimate] + 1\n",
    "        else:\n",
    "            result[estimate] = 1\n",
    "        return result    \n",
    "    # Returns a probability distribution (i.e., sum of \"y's\" is 1.0) by scaling down the y values of the given\n",
    "    # distribution\n",
    "    def _normalizeDistribution(dist):\n",
    "\n",
    "        area = 0\n",
    "        for x in dist.keys():\n",
    "            area += dist[x]\n",
    "            \n",
    "        if area == 0:\n",
    "            return None\n",
    "        \n",
    "        normalized_dist = {}\n",
    "                \n",
    "        for x in dist.keys():\n",
    "            normalized_dist[x] = dist[x]/area\n",
    "        return normalized_dist\n",
    "    \n",
    "    # Returns an array of the values of distribution, duplicating values as many times as their weight in the\n",
    "    # distribution\n",
    "    def dist_to_sample(distribution):\n",
    "        sample = []\n",
    "        for key in distribution:\n",
    "            for i in range(int(distribution[key])):\n",
    "                sample.append(key)\n",
    "        return sample\n",
    "    \n",
    "    def sample_to_dist(sample, number_of_bins):\n",
    "        distribution = {}\n",
    "        for e in sample:\n",
    "            x = Distribution.getBin(e, number_of_bins)                       \n",
    "            if x in distribution:\n",
    "                distribution[x] = distribution[x] + 1\n",
    "            else:\n",
    "                distribution[x] = 1                \n",
    "        return distribution    \n",
    "\n",
    "    def getBin(estimate, number_of_bins):        \n",
    "        return round((number_of_bins * estimate)/number_of_bins)\n",
    "    \n",
    "    def addToDist(pick, dist):\n",
    "        for k in pick.keys():\n",
    "            val = pick[k]\n",
    "            if k in dist.keys():\n",
    "                dist[k] += val\n",
    "            else:\n",
    "                dist[k] = val \n",
    "                \n",
    "    def removeFromDist(pick, dist):\n",
    "        for k in pick.keys():\n",
    "            val = pick[k]\n",
    "            if k in dist.keys():\n",
    "                dist[k] -= val\n",
    "            else:\n",
    "                dist[k] = -val\n",
    "                \n",
    "    def distIsEmpty(dist):\n",
    "        for k in dist.keys():\n",
    "            if dist[k] != 0:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CostModel:\n",
    "# Abstract class\n",
    "    \n",
    "    # Returns a cost multipier for the WorkItem 'item', i.e., a number equal to the ratio between the 'actual cost'\n",
    "    # (in man-days) of developing the 'item' and the 'estimated cost'\n",
    "    #\n",
    "    # -item: a WorkItem\n",
    "    def runModel(self, item): \n",
    "        return # This is the abstract class, so this method should never be called as concrete class implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class DefaultCostModel (CostModel):\n",
    "# Default class for models that simulate how actual costs differ from estimates. Usually there might be different\n",
    "# implementations, each trying to capture a different dynamic with a different driver. This default class just assumes\n",
    "# everything takes longer than expected by a given delay\n",
    "\n",
    "    # -delay_pct: the percentage by which estimates are off. For example, a delay_pct of 0.25 means that a task\n",
    "    # estimated to take 10 man-days actually takes 12.5 man-days.\n",
    "    def __init__(self, delay_pct = 0.25):\n",
    "        self.delay_pct = delay_pct\n",
    "        return  \n",
    "    # \n",
    "    def runModel(self, item):   \n",
    "        return 1 + self.delay_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def computeRealCost(item, costModels):\n",
    "# Computes the real cost of delivering a work item, based on a number of 'factors', which are functions implementing a model\n",
    "# for what drives costs to differ from estimates.\n",
    "\n",
    "    cost = item.estimate;\n",
    "    for m in costModels:\n",
    "        cost *= m.runModel(item)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Allocation Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class _AvailabilityCriterion:\n",
    "# Abstract parent class\n",
    "    def _getPeopleWithBandwidth(self, timeRequired, sprintDuration):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class _GreedyAvailabilityCriterion (_AvailabilityCriterion):  \n",
    "    \n",
    "    def __init__(self, work, currentOrNext):\n",
    "        self.work = work\n",
    "        self.currentOrNext = currentOrNext\n",
    "    \n",
    "        return\n",
    "    \n",
    "    def _getPeopleWithBandwidth(self, timeRequired, sprintDuration):\n",
    "        if self.currentOrNext:\n",
    "            available = self.work.committedTime(sprintDuration)[['Developer', 'Bandwidth']]\n",
    "            return list(available[available['Bandwidth'] >= timeRequired]['Developer'])\n",
    "            \n",
    "        else:\n",
    "            available = self.work.committedTime(sprintDuration)[['Developer', 'NEXT SPRINT Bandwidth']]\n",
    "            # Filter to only developers who have 'carry over' bandwidth from this spring into the next one\n",
    "            haveCarryOver = available[available['NEXT SPRINT Bandwidth'] > sprintDuration] \n",
    "            return list(haveCarryOver[haveCarryOver['NEXT SPRINT Bandwidth'] >= timeRequired]['Developer'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0,
     6,
     12,
     17,
     54,
     67,
     78,
     89,
     105
    ]
   },
   "outputs": [],
   "source": [
    "class AllocationModel:\n",
    "# Abstract class \n",
    "\n",
    "    def __init__(self):\n",
    "        self._resetLog()\n",
    "\n",
    "    def _resetLog(self):\n",
    "        self.log = {} # Log information of how allocation decisions are made. \n",
    "        self.log['Cycles'] = {}\n",
    "        \n",
    "    # Implemented by concrete classes.\n",
    "    # Mutates work by allocating WorkItem's to developers, depleting the workToPik\n",
    "    def _allocate_helper(self, work, workToPick, currentOrNext, modelsConfig): \n",
    "        return\n",
    " \n",
    "    # Implemented by concrete classes.\n",
    "    # Picks the next \"preferred\" WorkItem to work on\n",
    "    def _pickItem(self, runningDist, remainingDist, targetDist, workToPick, modelsConfig):\n",
    "        return\n",
    "\n",
    "    def allocate(self, work, modelsConfig):\n",
    "        self._resetLog() # Log reflects a single call to allocate, so must be cleared from one call to another\n",
    "        unplanned = work.allocations[S_.UNPLANNED][S_.OWNER_TBD]\n",
    "        workToPick = []\n",
    "        workToPick.extend(unplanned[S_.PRODUCTION_BUGS])\n",
    "        workToPick.extend(unplanned[S_.DEV_TIME_BUGS])\n",
    "        workToPick.extend(unplanned[S_.UNFINISHED_STORIES])   \n",
    "\n",
    "        self._allocate_helper(work, workToPick, True, modelsConfig) # mutates 'work' and 'workToPick'\n",
    "\n",
    "        # Now try again, but this time allocating any unused time to deliverables for the next sprint, i.e., use\n",
    "        # time left over from the current sprint to get a heat start on the work for the next sprint, borrowing next sprint's\n",
    "        # capacity since we only need to deliver then\n",
    "\n",
    "        #Update unplanned, workToPick since we changed it in prior call to helper\n",
    "        unplanned = work.allocations[S_.UNPLANNED][S_.OWNER_TBD] \n",
    "        workToPick = []\n",
    "        workToPick.extend(unplanned[S_.PRODUCTION_BUGS])\n",
    "        workToPick.extend(unplanned[S_.DEV_TIME_BUGS])\n",
    "        workToPick.extend(unplanned[S_.UNFINISHED_STORIES]) \n",
    "\n",
    "        self._allocate_helper(work, workToPick, False, modelsConfig) # mutates 'work' and 'workToPick'    \n",
    "        \n",
    "        return work\n",
    "    \n",
    "    # Returns an unnormalized distribution of the estimated effort required for the WorkItems in items.\n",
    "    # The distribution is represented as a dictionary, where the keys are the \"x axis\" (the possible values\n",
    "    # for estimates) and the value for each key are the \"y axis\" of the distribution (the count of how many\n",
    "    # WorkItems have such an estimate)\n",
    "    # \n",
    "    # NOTE: WorkItems that were partially progressed in prior sprints may have a residual estimate that is\n",
    "    # not a nice integer number, but a number with lots of decimal places. To avoid issues with having a distribution\n",
    "    # that is too finely cut we use bins of length 0.1 and classify each estimate in a bin. That way we limit\n",
    "    # the number of possibly values of 'x'\n",
    "    def _getUnnormalizedDistribution(self, items, context):\n",
    "        distribution = {}\n",
    "        \n",
    "        for item in items:\n",
    "            x = Distribution.getBin(item.estimate, context.sprintDuration)           \n",
    "            \n",
    "            if x in distribution:\n",
    "                distribution[x] = distribution[x] + 1\n",
    "            else:\n",
    "                distribution[x] = 1\n",
    "                \n",
    "        return distribution\n",
    "    \n",
    "    def _inferDistribution(self, work, context):\n",
    "        workAlreadyPlanned = []\n",
    "        for bucket in [S_.CURRENT_SPRINT, S_.NEXT_SPRINT]:\n",
    "            subwork = work.allocations[bucket]\n",
    "            for person in subwork.keys():\n",
    "                workAlreadyPlanned.extend(subwork[person][S_.PRODUCTION_BUGS])\n",
    "                workAlreadyPlanned.extend(subwork[person][S_.DEV_TIME_BUGS])\n",
    "                workAlreadyPlanned.extend(subwork[person][S_.UNFINISHED_STORIES])\n",
    "        \n",
    "        return self._getUnnormalizedDistribution(workAlreadyPlanned, context)\n",
    "\n",
    "    def _postLog(self, cycle, bucket, remainingDist, originalRunningDist, finalRunningDist):\n",
    "        \n",
    "        if cycle not in self.log['Cycles'].keys():\n",
    "            self.log['Cycles'][cycle] = {}\n",
    "        \n",
    "        self.log['Cycles'][cycle][bucket] = {'Remaining Dist': remainingDist, \\\n",
    "                      'Original Running Dist': originalRunningDist,\\\n",
    "                     'Final Running Dist': finalRunningDist}\n",
    "        \n",
    "\n",
    "\n",
    "    def _buildLog_df_Helper(self, targetDist, cycle, bucket, distName):\n",
    "\n",
    "        if bucket not in self.log['Cycles'][cycle].keys():\n",
    "            return 0,0,[]\n",
    "    \n",
    "        snapshotDist = self.log['Cycles'][cycle][bucket][distName]\n",
    "    \n",
    "        data = Distribution.dist_to_sample(snapshotDist)\n",
    "        distance = Distribution.measureDistributionDistance(targetDist, snapshotDist)    \n",
    "        if len(data)==0:\n",
    "            mean = 0\n",
    "        else:\n",
    "            mean = statistics.mean(data)\n",
    "        \n",
    "        return mean, distance, data\n",
    "\n",
    "    def buildLog_df(self, title, context):\n",
    "       \n",
    "        DEL = ' - '\n",
    "        logical_cols = ['Initial Size', 'Initial Mean', 'Initial Distance', 'Initial Data', \\\n",
    "               'Remaining Size', 'Remaining Mean', 'Remaining Distance', 'Remaining Data', \\\n",
    "               'Final Size', 'Final Mean', 'Final Distance', 'Final Data', \\\n",
    "                        'Bins']\n",
    "        log_dict = {}\n",
    "        actual_columns = ['Title', 'Cycle']\n",
    "        log_dict['Title'] = []\n",
    "        log_dict['Cycle'] = []\n",
    "        for bucket in [S_.CURRENT_SPRINT, S_.NEXT_SPRINT]:\n",
    "            for c in logical_cols:\n",
    "                real_col = c + DEL + bucket\n",
    "                actual_columns.append(real_col)\n",
    "                log_dict[real_col] = []\n",
    "    \n",
    "        targetDist = self.log['Target dist']\n",
    "    \n",
    "        for cycle in self.log['Cycles'].keys():\n",
    "            log_dict['Title'].                 append(title)\n",
    "            log_dict['Cycle'].                 append(cycle)\n",
    "            for bucket in [S_.CURRENT_SPRINT, S_.NEXT_SPRINT]:\n",
    "                  \n",
    "                mean, distance, data = self._buildLog_df_Helper(targetDist, cycle, bucket, 'Original Running Dist')\n",
    "\n",
    "                log_dict['Initial Size' + DEL + bucket].          append(len(data))\n",
    "                log_dict['Initial Mean' + DEL + bucket].          append(mean)\n",
    "                log_dict['Initial Distance' + DEL + bucket].      append(distance)\n",
    "                log_dict['Initial Data' + DEL + bucket].          append(data)\n",
    "        \n",
    "                mean, distance, data = self._buildLog_df_Helper(targetDist, cycle, bucket, 'Remaining Dist')\n",
    "\n",
    "                log_dict['Remaining Size' + DEL + bucket].        append(len(data))\n",
    "                log_dict['Remaining Mean' + DEL + bucket].        append(mean)\n",
    "                log_dict['Remaining Distance' + DEL + bucket].    append(distance)\n",
    "                log_dict['Remaining Data' + DEL + bucket].        append(data)\n",
    "        \n",
    "                mean, distance, data = self._buildLog_df_Helper(targetDist, cycle, bucket, 'Final Running Dist')\n",
    "\n",
    "                log_dict['Final Size' + DEL + bucket].            append(len(data))\n",
    "                log_dict['Final Mean' + DEL + bucket].            append(mean)\n",
    "                log_dict['Final Distance' + DEL + bucket].        append(distance)\n",
    "                log_dict['Final Data' + DEL + bucket].            append(data)\n",
    "                \n",
    "                #log_dict['Color' + DEL + bucket].                 append(COLOR)\n",
    "                log_dict['Bins' + DEL + bucket].                  append(context.sprintDuration)\n",
    "                \n",
    "        log_df = pd.DataFrame(log_dict, columns=actual_columns)   \n",
    "        return log_df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0,
     8,
     66
    ]
   },
   "outputs": [],
   "source": [
    "class GreedyAllocationModel (AllocationModel):\n",
    "# For a sprint, allocates work to developers by maximizing the planned tasks for each developer.\n",
    "# So as long as the developer has some bandwidth left in the sprint, the algorithm will search for a user story\n",
    "# that can be done in the remaining time.\n",
    "# As a result, this algorithm has a tendency to plan short-duration user stories early in the release cycle, so that\n",
    "# later sprints in the release cycle need to deal with comparatively coarser-sized user stories. This causes the\n",
    "# release cycle to be unbalanced: later sprints have big-ticket items for the most part.\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GreedyAllocationModel, self).__init__()\n",
    "        return\n",
    "\n",
    "    # Mutates 'work' and 'workToPick' by allocating WorkItem's to developers and in the process depleting\n",
    "    # partially or fully the 'workToPick'\n",
    "    #\n",
    "    # -workToPick: an array of WorkItem objects, corresponding to unplanned tasks that are candidate tasks to allocate\n",
    "    # to developers\n",
    "    # -work: a WorkAssignment instance reflecting a ScrumTeam's allocations and remaining bandwidth prior to the\n",
    "    # allocation this model will conduct. This model's allocation process will then mutate 'work' by reflecting in it\n",
    "    # tasks that are no longer unplanned but rather are now allocated to a particular developer.\n",
    "    # -currentOrNext: boolean to indicate if the allocation is being done for the current sprint or the next sprint. True \n",
    "    # for current, False for next.\n",
    "    # -modelsConfig: parameters for running the model (e.g., random generators)\n",
    "    def _allocate_helper(self, work, workToPick, currentOrNext, modelsConfig): \n",
    "        availabilityCriterion   = _GreedyAvailabilityCriterion(work, currentOrNext) \n",
    "        \n",
    "        ctx = modelsConfig.context\n",
    "        \n",
    "        targetDist = self._getUnnormalizedDistribution(workToPick, ctx) \n",
    "\n",
    "        self.log['Target dist'] = targetDist\n",
    "        cycle = -1\n",
    "        while len(workToPick) > 0:\n",
    "\n",
    "            cycle += 1\n",
    "            \n",
    "            runningDist = self._inferDistribution(work, ctx) # Re-compute in each loop since work changes in each loop\n",
    "            remainingDist = self._getUnnormalizedDistribution(workToPick, ctx) # Re-compute as workToPick changes\n",
    "            \n",
    "            item = self._pickItem(runningDist, remainingDist, targetDist, workToPick, modelsConfig)\n",
    "\n",
    "            # In next cycle of loop don't want to encounter this item, as it would be processed by then           \n",
    "            workToPick.remove(item) \n",
    "            \n",
    "            \n",
    "            timeRequired = item.estimate * (1-item.percentAchieved)\n",
    "        \n",
    "            peopleWithTimeToDoIt = availabilityCriterion._getPeopleWithBandwidth(timeRequired, ctx.sprintDuration)\n",
    "            \n",
    "            potentialOwner = modelsConfig.random.pickOne(peopleWithTimeToDoIt)\n",
    "            \n",
    "            if potentialOwner == None:\n",
    "                # This WorkItem can't be done in this sprint, as nobody has enough time for the effort it requires.\n",
    "                # Try with some other work item\n",
    "                 continue\n",
    "            \n",
    "            if currentOrNext:\n",
    "                work.reAssign(item, potentialOwner, S_.CURRENT_SPRINT)\n",
    "                newRunningDist = self._inferDistribution(work, ctx)\n",
    "                self._postLog(cycle, S_.CURRENT_SPRINT, remainingDist, runningDist, newRunningDist)\n",
    "            else:\n",
    "                work.reAssign(item, potentialOwner, S_.NEXT_SPRINT) \n",
    "                newRunningDist = self._inferDistribution(work, ctx)\n",
    "                self._postLog(cycle, S_.NEXT_SPRINT, remainingDist, runningDist, newRunningDist)\n",
    "\n",
    "    # Picks the next \"preferred\" WorkItem to work on\n",
    "    def _pickItem(self, runningDist, remainingDist, targetDist, workToPick, modelsConfig):\n",
    "        \n",
    "        item = modelsConfig.random.pickOne(workToPick)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0,
     21,
     72
    ]
   },
   "outputs": [],
   "source": [
    "class BalancedAllocationModel (AllocationModel):\n",
    "# For a sprint, allocates work to developers by trying to keep a roughly average user story size across all sprints\n",
    "# in the release.\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BalancedAllocationModel, self).__init__()\n",
    "        return\n",
    "\n",
    "    # Mutates 'work' and 'workToPick' by allocating WorkItem's to developers and in the process depleting\n",
    "    # partially or fully the 'workToPick'\n",
    "    #\n",
    "    # -workToPick: an array of WorkItem objects, corresponding to unplanned tasks that are candidate tasks to allocate\n",
    "    # to developers\n",
    "    # -work: a WorkAssignment instance reflecting a ScrumTeam's allocations and remaining bandwidth prior to the\n",
    "    # allocation this model will conduct. This model's allocation process will then mutate 'work' by reflecting in it\n",
    "    # tasks that are no longer unplanned but rather are now allocated to a particular developer.\n",
    "    # -currentOrNext: boolean to indicate if the allocation is being done for the current sprint or the next sprint. True \n",
    "    # for current, False for next.\n",
    "    # -modelsConfig: parameters for running the model (e.g., random generators)\n",
    "    def _allocate_helper(self, work, workToPick, currentOrNext, modelsConfig): \n",
    "        \n",
    "        if (len(workToPick) == 0):\n",
    "            return # Nothing to do, and if we don't return may get an assertion below as we assume there is work to pick\n",
    "        \n",
    "        ctx = modelsConfig.context\n",
    "        \n",
    "        availabilityCriterion   = _GreedyAvailabilityCriterion(work, currentOrNext)  \n",
    "        \n",
    "        # For debugging - we want to make sure that after the while loop we did allocate at least something, so\n",
    "        # keep track of when we allocate stuff\n",
    "        something_was_allocated = False\n",
    "        assertion_info = {}\n",
    "        assertion_info['modelsConfig context'] = modelsConfig.context\n",
    "        assertion_info['len(workToPick) at start'] = len(workToPick)\n",
    "        \n",
    "        targetDist = self._getUnnormalizedDistribution(workToPick, ctx) \n",
    "        while len(workToPick) > 0:\n",
    "            runningDist = self._inferDistribution(work, ctx) # Re-compute in each loop since work changes in each loop\n",
    "            remainingDist = self._getUnnormalizedDistribution(workToPick, ctx)    \n",
    "                        \n",
    "            chosenItem = self._pickItem(runningDist, remainingDist, targetDist, workToPick, modelsConfig)\n",
    "            \n",
    "            # In next cycle of loop don't want to encounter this item, as it would be processed by then\n",
    "            workToPick.remove(chosenItem)\n",
    "            itemAttractiveness = Distribution.calcAttractiveness(chosenItem.estimate, runningDist, targetDist)\n",
    "            if (itemAttractiveness <= 0):\n",
    "                continue\n",
    "            \n",
    "            timeRequired = chosenItem.estimate * (1-chosenItem.percentAchieved)\n",
    "        \n",
    "            peopleWithTimeToDoIt = availabilityCriterion._getPeopleWithBandwidth(timeRequired, ctx.sprintDuration)\n",
    "            \n",
    "            potentialOwner = modelsConfig.random.pickOne(peopleWithTimeToDoIt)\n",
    "            \n",
    "            if potentialOwner == None:\n",
    "                # This WorkItem can't be done in this sprint, as nobody has enough time for the effort it requires.\n",
    "                # Try with some other work item\n",
    "                 continue\n",
    "            \n",
    "            if currentOrNext:\n",
    "                work.reAssign(chosenItem, potentialOwner, S_.CURRENT_SPRINT)\n",
    "                something_was_allocated = True\n",
    "            else:\n",
    "                work.reAssign(chosenItem, potentialOwner, S_.NEXT_SPRINT) \n",
    "                something_was_allocated = True\n",
    "\n",
    "        # For debugging, confirm that we at least allocated something for the current release\n",
    "        assertion_info['len(workToPick) at end'] = len(workToPick)\n",
    "        if currentOrNext:\n",
    "            assert something_was_allocated, assertion_info\n",
    "        \n",
    "    # Picks the next \"preferred\" WorkItem to work on\n",
    "    def _pickItem(self, runningDist, remainingDist, targetDist, workToPick, modelsConfig):\n",
    " \n",
    "        chosenEstimate = Distribution.pickUsingProximityToTarget(runningDist, remainingDist, targetDist, modelsConfig)\n",
    "            \n",
    "        chosenItem = None\n",
    "        #find an item for such a chosenEstimate\n",
    "        for item in workToPick:\n",
    "            if item.estimate == chosenEstimate:\n",
    "                chosenItem = item\n",
    "        # Should never get here - should found an item \n",
    "        assert(chosenItem != None)\n",
    "        \n",
    "        return chosenItem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quality Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class QualityModel:\n",
    "# Abstract class \n",
    "\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    # Implemented by concrete classes. Returns a list of Ticket instances and persists them to the TicketsRepo in\n",
    "    # modelsConfig.context.\n",
    "    # -modelsConfig: a ModelsConfig instance\n",
    "    def findBugs(self, modelsConfig): \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     8,
     22,
     41,
     68
    ]
   },
   "outputs": [],
   "source": [
    "class DistributedLagQualityModel(QualityModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistributedLagQualityModel, self).__init__()\n",
    "        return\n",
    "    \n",
    "    # Returns a list of Ticket instances.\n",
    "    # -modelsConfig: a ModelsConfig instance\n",
    "    def findBugs(self, modelsConfig): \n",
    "        uss_list = DistributedLagQualityModel._findFinishedStories(modelsConfig.context)\n",
    "        \n",
    "        bugs = []\n",
    "        current_sprint = modelsConfig.context.sprint\n",
    "        for uss in uss_list:\n",
    "            delivery_sprint = uss.sprintDelivered\n",
    "            lag = current_sprint - delivery_sprint\n",
    "            story = modelsConfig.context.storiesRepo.findStory(uss.userStoryId)\n",
    "            story_bugs = DistributedLagQualityModel._findDefectsInStory(lag, story, uss, modelsConfig)\n",
    "            bugs.extend(story_bugs)\n",
    "        return bugs\n",
    "\n",
    "    # Returns a list of UserStoryStatus instances, corresponding to all user stories that have been finished.\n",
    "    def _findFinishedStories(context):\n",
    "        uss_list = []\n",
    "        ids = context.storiesRepo.findIds()\n",
    "        for userStoryId in ids:\n",
    "            teamId = context.teamsRepo.getTeamId(userStoryId)\n",
    "            if (teamId != context.teamId):\n",
    "                # We only want the finished stories owned by the context.teamId to avoid a bug whereby we generate \n",
    "                # bugs for the stories of another team, whilst still in the same sprint as the user story\n",
    "                # that the bug is for, which is an assertion violation (since bugs should be found after\n",
    "                # a story is delivered, not in the same sprint, as might happen if a different team Y who is closing\n",
    "                # a sprint after another team X finds X's completed story and generates a bug for X's story\n",
    "                # in the same sprint)\n",
    "                continue \n",
    "            uss = context.teamsRepo.getUserStoryStatus(userStoryId)\n",
    "            if (uss.percentAchieved == 1.0):\n",
    "                uss_list.append(uss)\n",
    "        return uss_list\n",
    "    \n",
    "    # Returns a list of Ticket instances\n",
    "    def _findDefectsInStory(lag, userStory, uss, modelsConfig):\n",
    "        if lag < 1 or lag > 3: # No bugs for stories just finished or which were finished a while ago\n",
    "            return []\n",
    "        # Exposure is the probability of finding a bug. For now hardcode a 50% exposure distributed over \n",
    "        # 3 sprints with the surge in the middle one\n",
    "        if lag == 1:\n",
    "            exposure = 0.125\n",
    "        if lag == 2:\n",
    "            exposure = 0.25\n",
    "        if lag == 3:\n",
    "            exposure = 0.125\n",
    "        possible_defect_count  = [0, 1] # Possible values for number of bugs found\n",
    "        likelihoods            = [1-exposure, exposure]\n",
    "        defect_count           = modelsConfig.random.pickOneWithWeights(possible_defect_count, likelihoods)\n",
    "        \n",
    "        # Issue defect Tickets\n",
    "        defects = []\n",
    "        repo = modelsConfig.context.ticketsRepo\n",
    "        for i in range(defect_count):\n",
    "            costToFix = DistributedLagQualityModel._estimateCostToFix(userStory, modelsConfig)\n",
    "            ticketId = repo._nextTicketId()\n",
    "            ticket = Ticket(ticketId, userStory.userStoryId, costToFix, modelsConfig.context.sprint)\n",
    "            repo.addTicket(ticket)\n",
    "            defects.append(ticket)\n",
    "        return defects\n",
    "    \n",
    "        \n",
    "    def _estimateCostToFix(userStory, modelsConfig):\n",
    "    # For now hard-code a simplistic cost to fix: each bug costs 20% of the original estimate of the story.\n",
    "    # Better would be a percentage of the actual cost to develop.\n",
    "         return 0.20 * userStory.originalEstimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
