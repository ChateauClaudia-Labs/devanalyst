{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\alejandro\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\statics.ipynb\n",
      "importing Jupyter notebook from c:\\alejandro\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\simulationModels.ipynb\n",
      "importing Jupyter notebook from c:\\alejandro\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\businessObjects.ipynb\n",
      "importing Jupyter notebook from c:\\alejandro\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\generateTimecards.ipynb\n"
     ]
    }
   ],
   "source": [
    "import devanalyst.simulation.statics as S_\n",
    "from devanalyst.simulation.simulationModels import Distribution\n",
    "from devanalyst.simulation.generateTimecards import ReleaseLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Timecard Visualizations</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualize runReleaseCycle's log</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     47
    ]
   },
   "outputs": [],
   "source": [
    "class VisualizeWork:\n",
    "    \n",
    "    def render(start_df, end_df, ax, target, include_legend):\n",
    "        # RGB\n",
    "        lime        = [0/256, 255/256, 0/256,1]\n",
    "        light_green = [0/256, 220/256, 0/256,1]\n",
    "        green       = [0/256, 128/256, 0/256,1]\n",
    "        \n",
    "        amber       = [255/256,191/256,0/256,1]\n",
    "        dark_amber  = [255/256,100/256,0/256,1]\n",
    "        red         = [255/256, 0/256, 0/256,1]\n",
    "        dark_red    = [102/256, 3/256, 8/256,1]\n",
    "        \n",
    "        aqua        = [0/256,255/256,255/256, 1]\n",
    "        blue        = [0/256,0/256,255/256, 1]\n",
    "        purple      = [128/256, 0/256, 255/256, 1]\n",
    "        \n",
    "        light_blue  = [0/256,200/256,255/256, 1]\n",
    "        \n",
    "        # Log categories in backlog_df appear in this order:\n",
    "        # prior_progressed, prior_remaining, new_work, regressed\n",
    "        start_colors = np.array([blue, light_blue, aqua, dark_red])\n",
    "        start_cmp = ListedColormap(start_colors)\n",
    "        start_ax = start_df.set_index('Breakout').T.plot(kind='bar', stacked=True, ax=ax,  legend=include_legend,\\\n",
    "                                                           colormap = start_cmp, position = 1.0, width=0.35)\n",
    "        start_ax.set(xlabel = 'Estimate', ylabel = '# of stories')\n",
    "        \n",
    "        # Log categories in backlog_df appear in this order:\n",
    "        # completed, progressed, to_finish, not_started, over_budget, regressed\n",
    "        end_colors = np.array([green, dark_amber, amber, purple, red, dark_red])\n",
    "        end_cmp = ListedColormap(end_colors)\n",
    "        end_ax = end_df.set_index('Breakout').T.plot(kind='bar', stacked=True, ax=start_ax,   legend=include_legend,\\\n",
    "                                                           colormap = end_cmp, position = 0.0, width=0.35)\n",
    "        end_ax.set(xlabel = 'Estimate', ylabel = '# of stories')\n",
    "\n",
    "        started, finished, mean, distance = VisualizeWork._calc_stats(start_df, end_df, target) \n",
    "        \n",
    "        end_ax.set_xlabel('planned=' + str(round(started,2)) + '; mean=' + str(round(mean, 2)) + \n",
    "                          '; dist=' + str(round(distance,2)) + '; did=' + str(round(finished, 2)))\n",
    "\n",
    "        max_val = math.ceil(end_df.drop(columns = ['Breakout']).sum().max())       \n",
    "        end_ax.set_yticks(range(1,max_val+1), minor=True)\n",
    "        end_ax.grid(b=True, which='minor', axis='y', linestyle=':', linewidth=0.75)\n",
    "        \n",
    "        if (include_legend):\n",
    "            end_ax.legend(loc='center left', bbox_to_anchor=(0.0, 1.4), ncol=3)\n",
    "                \n",
    "    def render_backlog(backlog_df, ax, target, include_legend):\n",
    "        # RGB\n",
    "        lime        = [0/256, 255/256, 0/256,1]\n",
    "        light_green = [0/256, 220/256, 0/256,1]\n",
    "        green       = [0/256, 128/256, 0/256,1]\n",
    "        \n",
    "        amber       = [255/256,191/256,0/256,1]\n",
    "        dark_amber  = [255/256,100/256,0/256,1]\n",
    "        red         = [255/256, 0/256, 0/256,1]\n",
    "        dark_red    = [102/256, 3/256, 8/256,1]\n",
    "        gray        = [128/256, 128/256, 128/256,1]\n",
    "        \n",
    "        aqua        = [0/256,255/256,255/256, 1]\n",
    "        blue        = [0/256,0/256,255/256, 1]\n",
    "        purple      = [128/256, 0/256, 255/256, 1]\n",
    "        \n",
    "        light_blue = [0/256,200/256,255/256, 1]\n",
    "        \n",
    "        # WATCH OUT:\n",
    "        # backlog colors should be listed in the order corresponding to the log category they correspond to.\n",
    "        # Log categories in backlog_df appear in this order:\n",
    "        # unplanned, completed, planned_progressed, planned_remaining, not_started, regressed\n",
    "        backlog_colors = np.array([gray, green, dark_amber, amber, purple, dark_red])\n",
    "        \n",
    "        backlog_cmp = ListedColormap(backlog_colors)\n",
    "        backlog_ax = backlog_df.set_index('Breakout').T.plot(kind='bar', stacked=True, ax=ax, legend=include_legend, \\\n",
    "                                                           colormap = backlog_cmp, position = 0.0, width=0.35)\n",
    "        backlog_ax.set(xlabel = 'Estimate', ylabel = '# of stories')\n",
    "        \n",
    "        target_dist, total, mean = VisualizeWork._getTargetDist(backlog_df)    \n",
    "        distance = Distribution.measureDistributionDistance(target_dist, target)\n",
    "        backlog_ax.set_xlabel('total=' + str(round(total,2)) + '; mean=' + str(round(mean, 2)) + '; distance=' + str(round(distance,2)))\n",
    "\n",
    "        max_val = math.ceil(backlog_df.drop(columns = ['Breakout']).sum().max())       \n",
    "        backlog_ax.set_yticks(range(1,max_val+1), minor=True)\n",
    "        backlog_ax.grid(b=True, which='minor', axis='y', linestyle=':', linewidth=0.75)\n",
    "\n",
    "        if (include_legend):\n",
    "            backlog_ax.legend(loc='center left', bbox_to_anchor=(0.0, 1.4), ncol=2)\n",
    "    \n",
    "    def _calc_stats(start_df, end_df, target):\n",
    "        dist_df = start_df[start_df[ReleaseLog.BREAKOUT].isin([ReleaseLog.PRIOR_TO_FINISH, \n",
    "                                                               ReleaseLog.NEW_WORK,\n",
    "                                                              ReleaseLog.REGRESSED])].sum().drop(ReleaseLog.BREAKOUT)\n",
    "        dist, total_start, mean = VisualizeWork._df_to_dist(dist_df) #dist is a dictionary representing a distribution\n",
    "                \n",
    "        distance = Distribution.measureDistributionDistance(dist, target)\n",
    "\n",
    "        dist_df = end_df[end_df[ReleaseLog.BREAKOUT].isin([ReleaseLog.COMPLETED, \n",
    "                                                           ReleaseLog.PROGRESSED])].sum().drop(ReleaseLog.BREAKOUT)\n",
    "        x, acc_end, y = VisualizeWork._df_to_dist(dist_df) #dist is a dictionary representing a distribution\n",
    "\n",
    "        dist_df = start_df[start_df[ReleaseLog.BREAKOUT].isin([ReleaseLog.PRIOR_PROGRESSED])].sum().drop(ReleaseLog.BREAKOUT)\n",
    "        x, prior_end, y = VisualizeWork._df_to_dist(dist_df) #dist is a dictionary representing a distribution\n",
    "        \n",
    "        total_end = acc_end - prior_end\n",
    "\n",
    "        return total_start, total_end, mean, distance\n",
    "\n",
    "    def _getTargetDist(backlog_df):\n",
    "        target_df = backlog_df[backlog_df[ReleaseLog.BREAKOUT].isin([ReleaseLog.UNPLANNED, \n",
    "                                                                     ReleaseLog.TO_FINISH, \n",
    "                                                                     ReleaseLog.NOT_STARTED,\n",
    "                                                                    ReleaseLog.REGRESSED])].sum().drop(ReleaseLog.BREAKOUT)\n",
    "        target, total_stories, mean = VisualizeWork._df_to_dist(target_df) #target is a dictionary representing a distribution\n",
    "\n",
    "        return target, total_stories, mean \n",
    "        \n",
    "    def _df_to_dist(dist_df):\n",
    "        dist = {}\n",
    "        total_stories = 0.0\n",
    "        weighted_stories = 0.0\n",
    "        for e in dist_df.index:\n",
    "            assert(type(e)==int) #If e is not an int, then it is a spurious columns that should have been removed earlier\n",
    "            #if type(e) != int:\n",
    "            #    continue # Fixes a bug. This colums is not really an estimate, possibly an added label/description\n",
    "            stories = dist_df[e]\n",
    "            dist[e] = stories\n",
    "            total_stories += stories\n",
    "            weighted_stories += e * stories\n",
    "        if total_stories != 0:\n",
    "            mean = weighted_stories/total_stories\n",
    "        else:\n",
    "            mean = 0\n",
    "        return dist, total_stories, mean\n",
    "    \n",
    "    def _remove_spurious_colums(df, spurious_cols):\n",
    "        cols_to_drop = []\n",
    "        for c in spurious_cols:\n",
    "            if c in df.columns:\n",
    "                cols_to_drop.append(c)\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def renderReleaseCycleLog(teamId, release_log, first, last, spurious_columns=[]):\n",
    "# -release_log: a ReleaseLog instance.\n",
    "    \n",
    "    team_log = release_log.log[teamId] # release_log is a ReleaseLog instance, and 'team_log' is a dict\n",
    "    sprints = list(team_log.keys())\n",
    "    \n",
    "    for sprint in sprints:\n",
    "        if sprint < first or sprint > last: # Only run for the chosen sprints\n",
    "            continue\n",
    "            \n",
    "        if sprint==first:\n",
    "            include_legend = True\n",
    "        else:\n",
    "            include_legend = False\n",
    "            \n",
    "        fig, axs = plt.subplots(1, 3)   \n",
    "\n",
    "        fig.suptitle('----------------------------------------------------- SPRINT '+ str(sprint) + \n",
    "                     ' -----------------------------------------------------', fontsize=16, y=0.95, x=1)\n",
    "\n",
    "        backlog_df                              = team_log[sprint]['backlog']\n",
    "        backlog_df                              = VisualizeWork._remove_spurious_colums(backlog_df, spurious_columns)\n",
    "        target, target_total, target_mean       = VisualizeWork._getTargetDist(backlog_df)\n",
    "        VisualizeWork.render_backlog(backlog_df, axs[0], target, include_legend)\n",
    "\n",
    "        start_df                                = team_log[sprint]['planned_Start_CURRENT_SPRINT']\n",
    "        start_df                                = VisualizeWork._remove_spurious_colums(start_df, spurious_columns)\n",
    "        end_df                                  = team_log[sprint]['planned_End_CURRENT_SPRINT']\n",
    "        end_df                                  = VisualizeWork._remove_spurious_colums(end_df, spurious_columns)\n",
    "        VisualizeWork.render(start_df, end_df, axs[1], target, include_legend)\n",
    "\n",
    "        start_next_df                           = team_log[sprint]['planned_Start_NEXT_SPRINT']\n",
    "        start_next_df                           = VisualizeWork._remove_spurious_colums(start_next_df, spurious_columns)\n",
    "        end_next_df                             = team_log[sprint]['planned_End_NEXT_SPRINT']\n",
    "        end_next_df                             = VisualizeWork._remove_spurious_colums(end_next_df, spurious_columns)\n",
    "        VisualizeWork.render(start_next_df, end_next_df, axs[2], target, False)\n",
    "\n",
    "        plt.subplots_adjust(top=0.8, right=2.3, wspace=0.3, hspace=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
