{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\users\\aleja\\documents\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\statics.ipynb\n",
      "importing Jupyter notebook from c:\\users\\aleja\\documents\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\simulationModels.ipynb\n",
      "importing Jupyter notebook from c:\\users\\aleja\\documents\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\businessObjects.ipynb\n",
      "importing Jupyter notebook from c:\\users\\aleja\\documents\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\Engine.ipynb\n",
      "importing Jupyter notebook from c:\\users\\aleja\\documents\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\generateTimecards.ipynb\n",
      "importing Jupyter notebook from c:\\users\\aleja\\documents\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\metrics\\ProductivityMetrics.ipynb\n"
     ]
    }
   ],
   "source": [
    "import devanalyst.simulation.statics as S_\n",
    "\n",
    "from devanalyst.simulation.simulationModels import ModelsConfig, DefaultCostModel, MeritocraticCostModel, \\\n",
    "DistributedLagQualityModel, GreedyAllocationModel, NoLaggardsAllocationModel\n",
    "from devanalyst.simulation.businessObjects import TicketsRepo, Backlog, UserStoryStatus\n",
    "from devanalyst.simulation.Engine import ReleaseSimulationEngine\n",
    "\n",
    "from devanalyst.metrics.ProductivityMetrics import CommitsAnalysis, DragAnalyzer\n",
    "import devanalyst.simulation.generateTimecards as timecard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\users\\aleja\\documents\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\test_utils\\test_utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import devanalyst.test_utils.test_utils as tu_\n",
    "from devanalyst.test_utils.test_utils import ExpectedOutputCleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test Simple Productivity</h1>\n",
    "Tests commits productivity under multiple scenarios, but in all cases assumes no interference. Therefore what differs\n",
    "across scenarios is how work loads are partitioned among developers. There is no 'systemic waste' to eliminate in any of\n",
    "these scenarios since there is no interference assumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10,
     25
    ]
   },
   "outputs": [],
   "source": [
    "# Implement test logic, and run it\n",
    "\n",
    "#Helper function. Returns the time entries (as a dataframe) and logs for the release cycle. Also mutates 'modelsConfig'\n",
    "# \n",
    "# -modelsConfig: configuration of what models to use to simulate a release cycle. It is expected to be passed in \n",
    "# 'minimal form', i.e., only the models should be set. Everything else in 'modelsConfig' is likely to be mutated by \n",
    "# this function in the process of generating the release cycle. In particular, these are mutated: \n",
    "#      a) the repositories that 'modelsConfig' refers to, and \n",
    "#      b) the random seed used by 'modelsConfig'.\n",
    "#\n",
    "def run_release(modelsConfig):\n",
    "    RELEASE_DURATION = 60\n",
    "    SPRINT_DURATION = 10\n",
    "    NUMBER_OF_SPRINTS = 30\n",
    "\n",
    "    modelsConfig.random.reset(271)\n",
    "\n",
    "    teams_df, stories_dfDUMMY, globalRepo = tu_.initTestData(tu_.DEV_DF, tu_.PM_DF, \\\n",
    "                                                        RELEASE_DURATION, SPRINT_DURATION, modelsConfig)\n",
    "    modelsConfig.globalRepo = globalRepo\n",
    "    NUMBER_OF_SPRINTS = 30\n",
    "    entries_df, log = timecard.runReleaseCycle(datetime(2018, 1, 15), SPRINT_DURATION, NUMBER_OF_SPRINTS, modelsConfig)\n",
    "    return entries_df, log\n",
    "\n",
    "#Test logic\n",
    "def test_simple_productivity():\n",
    "    output = {}\n",
    "\n",
    "    # Case 1: no delays\n",
    "    modelsConfig1 = ModelsConfig([DefaultCostModel(0.0)], [DistributedLagQualityModel()], GreedyAllocationModel())\n",
    "    entries1_df, log1                          = run_release(modelsConfig1)\n",
    "    commits1_impl, commits1_bugs, commits1_all = CommitsAnalysis.tabulateCommits(modelsConfig1)\n",
    "    \n",
    "    # Case 2: Meritocratic delays without work stealing\n",
    "    modelsConfig2 = ModelsConfig([MeritocraticCostModel()], [DistributedLagQualityModel()], GreedyAllocationModel())\n",
    "    entries2_df, log2                          = run_release(modelsConfig2)\n",
    "    commits2_impl, commits2_bugs, commits2_all = CommitsAnalysis.tabulateCommits(modelsConfig2)\n",
    "\n",
    "    # Case 3: Meritocratic delays with work stealing\n",
    "    modelsConfig3 = ModelsConfig([MeritocraticCostModel()], [DistributedLagQualityModel()], NoLaggardsAllocationModel())\n",
    "    entries3_df, log3                          = run_release(modelsConfig3)\n",
    "    commits3_impl, commits3_bugs, commits3_all = CommitsAnalysis.tabulateCommits(modelsConfig3)\n",
    "    \n",
    "    \n",
    "    output['no_delay']                 = commits1_impl\n",
    "    output['meritocratic']             = commits2_impl\n",
    "    output['work_stealing']            = commits3_impl\n",
    "\n",
    "    return output\n",
    "\n",
    "# Run the test\n",
    "test_simple_ACTUAL = test_simple_productivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Uncomment to update expected output to match the actual one\n",
    "\n",
    "# Helper method\n",
    "def create_test_simple_EXPECTED():\n",
    "    tu_.createExpectedOutput(test_simple_ACTUAL['no_delay'],     'productivity.test_simple.no_delay',\n",
    "                                                                           module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_simple_ACTUAL['meritocratic'], 'productivity.test_simple.meritocratic',\n",
    "                                                                           module = 'metrics')    \n",
    "    tu_.createExpectedOutput(test_simple_ACTUAL['work_stealing'],'productivity.test_simple.work_stealing',\n",
    "                                                                           module = 'metrics')\n",
    "\n",
    "# Uncomment to update expected output to match the actual one, and then put the comment back\n",
    "#create_test_simple_EXPECTED()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load expected output, update the EXPECTED and ACTUAL dictionaries, and check test is OK\n",
    "list_cols = [] # Lists are loaded as strings, so require special processing on load\n",
    "\n",
    "test_simple_EXPECTED = {}\n",
    "\n",
    "\n",
    "# When loading the CSV files for expected output, they will introduce a spurious integer index. So replace that\n",
    "# by using the 'Developer' column as the index, which is how the actuals are indexed, so that expected matches actuals.\n",
    "test_simple_EXPECTED['no_delay']      = tu_.loadExpectedOutput('productivity.test_simple.no_delay', \n",
    "                                                                            list_cols,\n",
    "                                                                           module = 'metrics').set_index('Developer')\n",
    "                                                                            \n",
    "test_simple_EXPECTED['meritocratic']  = tu_.loadExpectedOutput('productivity.test_simple.meritocratic', \n",
    "                                                                            list_cols,\n",
    "                                                                           module = 'metrics').set_index('Developer')\n",
    "\n",
    "test_simple_EXPECTED['work_stealing'] = tu_.loadExpectedOutput('productivity.test_simple.work_stealing', \n",
    "                                                                            list_cols,\n",
    "                                                                           module = 'metrics').set_index('Developer')\n",
    "\n",
    "# Sort the results of loading work stealing. For some example it loads in a different order.\n",
    "test_simple_EXPECTED['work_stealing'].sort_values(by=['Developer'], inplace=True)\n",
    "\n",
    "\n",
    "tu_.EXPECTED['productivity.test_simple.no_delay']      = test_simple_EXPECTED['no_delay']\n",
    "tu_.EXPECTED['productivity.test_simple.meritocratic']  = test_simple_EXPECTED['meritocratic']\n",
    "tu_.EXPECTED['productivity.test_simple.work_stealing'] = test_simple_EXPECTED['work_stealing']\n",
    "\n",
    "tu_.ACTUAL['productivity.test_simple.no_delay']        = test_simple_ACTUAL['no_delay']\n",
    "tu_.ACTUAL['productivity.test_simple.meritocratic']    = test_simple_ACTUAL['meritocratic']\n",
    "tu_.ACTUAL['productivity.test_simple.work_stealing']   = test_simple_ACTUAL['work_stealing']\n",
    "\n",
    "tu_.testOK('productivity.test_simple.no_delay'), \\\n",
    "tu_.testOK('productivity.test_simple.meritocratic'), \\\n",
    "tu_.testOK('productivity.test_simple.work_stealing'), \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to interactively visualize the logs, and then comment again once interactive analysis is done. Commenting these\n",
    "# lines after interactive analysis is completed is required as test harness can't load these visualiations\n",
    "# libraries so leaving this uncommented will crash the entire test harness.\n",
    "# NOTE: MAY NEED TO RUN TWICE, as there seems to be a bug in Jupyter Notebook so on the first run there is no output\n",
    "#CommitsAnalysis.chartCommits(test_simple_ACTUAL['no_delay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to interactively visualize the logs, and then comment again once interactive analysis is done. Commenting these\n",
    "# lines after interactive analysis is completed is required as test harness can't load these visualiations\n",
    "# libraries so leaving this uncommented will crash the entire test harness.\n",
    "# NOTE: MAY NEED TO RUN TWICE, as there seems to be a bug in Jupyter Notebook so on the first run there is no output\n",
    "#CommitsAnalysis.chartCommits(test_simple_ACTUAL['meritocratic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to interactively visualize the logs, and then comment again once interactive analysis is done. Commenting these\n",
    "# lines after interactive analysis is completed is required as test harness can't load these visualiations\n",
    "# libraries so leaving this uncommented will crash the entire test harness.\n",
    "# NOTE: MAY NEED TO RUN TWICE, as there seems to be a bug in Jupyter Notebook so on the first run there is no output\n",
    "#CommitsAnalysis.chartCommits(test_simple_ACTUAL['work_stealing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_simple_ACTUAL['no_delay'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_simple_EXPECTED['no_delay'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_simple_ACTUAL['meritocratic'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_simple_EXPECTED['meritocratic'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_simple_ACTUAL['work_stealing'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_simple_EXPECTED['work_stealing'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test drag removal</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "# Implement test logic, and run it\n",
    "\n",
    "#Test logic\n",
    "def test_drag():\n",
    "    output = {}\n",
    "    RELEASE_DURATION = 60\n",
    "    SPRINT_DURATION = 10\n",
    "    NUMBER_OF_SPRINTS = 30\n",
    "\n",
    "    # Look at full team, with anyone able to work in anybody else's area.\n",
    "    singleTeam_df = tu_.DEV_DF.copy()\n",
    "    singleTeam_df['Scrum Team'] = 'Entire R&D'\n",
    "\n",
    "    # Configure models\n",
    "    modelsConfig = ModelsConfig([MeritocraticCostModel()], [DistributedLagQualityModel()], NoLaggardsAllocationModel())\n",
    "    modelsConfig.random.reset(271)\n",
    "    teams_df, stories_dfDUMMY, globalRepo = tu_.initTestData(singleTeam_df, tu_.PM_DF, \\\n",
    "                                                             RELEASE_DURATION, SPRINT_DURATION, modelsConfig)\n",
    "    modelsConfig.globalRepo = globalRepo\n",
    "    \n",
    "    # Run simulations\n",
    "    engine = ReleaseSimulationEngine(modelsConfig)\n",
    "    analyzer = DragAnalyzer(engine, NUMBER_OF_SPRINTS, SPRINT_DURATION, datetime(2018, 1, 15), 0.9)\n",
    "    analyzer.runSimulations(3)\n",
    "    impact = analyzer.tabulateDragImpact()\n",
    "    \n",
    "\n",
    "    output['Burnout_with_drag']         = analyzer.stats['With_drag']       .burnout\n",
    "    output['Burnout_without_drag']      = analyzer.stats['Without_drag'][0] .burnout\n",
    "    output['Entries_with_drag']         = analyzer.stats['With_drag']       .entries_df\n",
    "    output['Entries_without_drag']      = analyzer.stats['Without_drag'][0] .entries_df\n",
    "    output['Commits_impl_with_drag']    = analyzer.stats['With_drag']       .commits_impl\n",
    "    output['Commits_impl_without_drag'] = analyzer.stats['Without_drag'][0] .commits_impl\n",
    "    output['Commits_bugs_with_drag']    = analyzer.stats['With_drag']       .commits_bugs\n",
    "    output['Commits_bugs_without_drag'] = analyzer.stats['Without_drag'][0] .commits_bugs\n",
    "    output['Commits_all_with_drag']     = analyzer.stats['With_drag']       .commits_all\n",
    "    output['Commits_all_without_drag']  = analyzer.stats['Without_drag'][0] .commits_all\n",
    "    output['Impact']                    = impact    \n",
    "\n",
    "    return output, analyzer\n",
    "\n",
    "# Run the test\n",
    "test_drag_ACTUAL, analyzer = test_drag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Uncomment to update expected output to match the actual one\n",
    "\n",
    "# Helper method\n",
    "def create_drag_EXPECTED():\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Burnout_with_drag'],    \n",
    "                             'productivity.test_drag.Burnout_with_drag', module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Burnout_without_drag'],    \n",
    "                             'productivity.test_drag.Burnout_without_drag', module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Entries_with_drag'],    \n",
    "                             'productivity.test_drag.Entries_with_drag', module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Entries_without_drag'],     \n",
    "                             'productivity.test_drag.Entries_without_drag', module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Commits_impl_with_drag'],    \n",
    "                             'productivity.test_drag.Commits_impl_with_drag', module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Commits_impl_without_drag'], \n",
    "                             'productivity.test_drag.Commits_impl_without_drag', module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Commits_bugs_with_drag'],    \n",
    "                             'productivity.test_drag.Commits_bugs_with_drag', module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Commits_bugs_without_drag'],    \n",
    "                             'productivity.test_drag.Commits_bugs_without_drag', module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Commits_all_with_drag'],    \n",
    "                             'productivity.test_drag.Commits_all_with_drag', module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Commits_all_without_drag'],    \n",
    "                             'productivity.test_drag.Commits_all_without_drag', module = 'metrics')\n",
    "    tu_.createExpectedOutput(test_drag_ACTUAL['Impact'],    \n",
    "                             'productivity.test_drag.Impact', module = 'metrics')\n",
    "\n",
    "# Uncomment to update expected output to match the actual one, and then put the comment back\n",
    "#create_drag_EXPECTED()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, True, True, True, True, True, True, True, True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load expected output, update the EXPECTED and ACTUAL dictionaries, and check test is OK\n",
    "list_cols = [] # Lists are loaded as strings, so require special processing on load\n",
    "\n",
    "test_drag_EXPECTED = {}\n",
    "\n",
    "test_drag_EXPECTED['Burnout_with_drag']         = tu_.loadExpectedOutput('productivity.test_drag.Burnout_with_drag', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics')\n",
    "test_drag_EXPECTED['Burnout_without_drag']      = tu_.loadExpectedOutput('productivity.test_drag.Burnout_without_drag', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics')\n",
    "test_drag_EXPECTED['Entries_with_drag']         = tu_.loadExpectedOutput('productivity.test_drag.Entries_with_drag', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics')\n",
    "test_drag_EXPECTED['Entries_without_drag']      = tu_.loadExpectedOutput('productivity.test_drag.Entries_without_drag', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics')\n",
    "test_drag_EXPECTED['Commits_impl_with_drag']    = tu_.loadExpectedOutput('productivity.test_drag.Commits_impl_with_drag', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics').set_index('Developer')\n",
    "test_drag_EXPECTED['Commits_impl_without_drag'] = tu_.loadExpectedOutput('productivity.test_drag.Commits_impl_without_drag', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics').set_index('Developer')\n",
    "test_drag_EXPECTED['Commits_bugs_with_drag']    = tu_.loadExpectedOutput('productivity.test_drag.Commits_bugs_with_drag', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics').set_index('Developer')\n",
    "test_drag_EXPECTED['Commits_bugs_without_drag'] = tu_.loadExpectedOutput('productivity.test_drag.Commits_bugs_without_drag', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics').set_index('Developer')\n",
    "test_drag_EXPECTED['Commits_all_with_drag']     = tu_.loadExpectedOutput('productivity.test_drag.Commits_all_with_drag', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics').set_index('Developer')\n",
    "test_drag_EXPECTED['Commits_all_without_drag']  = tu_.loadExpectedOutput('productivity.test_drag.Commits_all_without_drag', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics').set_index('Developer')\n",
    "test_drag_EXPECTED['Impact']                    = tu_.loadExpectedOutput('productivity.test_drag.Impact', \n",
    "                                                                         list_cols,\n",
    "                                                                         module = 'metrics')\n",
    "\n",
    "# Rounding inaccuracies in saving and loading CSV will create an artificial mismatch between ACTUAL and EXPECTED\n",
    "# So round EXPECTED and ACTUAL to 6 decimal places for sensitive fields (any float)\n",
    "ExpectedOutputCleaner.cleanRoundingNoise(['Time Spent'],\n",
    "                                        ['Entries_with_drag', 'Entries_without_drag'],\n",
    "                                        test_drag_EXPECTED,\n",
    "                                        test_drag_ACTUAL)\n",
    "ExpectedOutputCleaner.cleanRoundingNoise(['Effort', 'Implementation Effort', 'Debugging Effort', 'Cum % Completion'],\n",
    "                                        ['Burnout_with_drag', 'Burnout_without_drag'],\n",
    "                                        test_drag_EXPECTED,\n",
    "                                        test_drag_ACTUAL)\n",
    "\n",
    "# Dates are loaded as strings, not pd.Timestamps, so to avoid spurious mismatches between ACTUAL (which \n",
    "# represents dates as pd.Timestamps) and EXPECTED, convert the EXPECTED dates into pd.Timestamps\n",
    "ExpectedOutputCleaner.standardizeDates(['Date'],\n",
    "                                      ['Entries_with_drag', 'Entries_without_drag'],\n",
    "                                      test_drag_EXPECTED)\n",
    "\n",
    "# Align columns\n",
    "ExpectedOutputCleaner.alignColumns(['Commits_all_with_drag', 'Commits_all_without_drag'],\n",
    "                                   test_drag_EXPECTED,\n",
    "                                  test_drag_ACTUAL)\n",
    "\n",
    "tu_.EXPECTED['productivity.test_drag.Burnout_with_drag']             = test_drag_EXPECTED['Burnout_with_drag']\n",
    "tu_.EXPECTED['productivity.test_drag.Burnout_without_drag']          = test_drag_EXPECTED['Burnout_without_drag']\n",
    "tu_.EXPECTED['productivity.test_drag.Entries_with_drag']             = test_drag_EXPECTED['Entries_with_drag']\n",
    "tu_.EXPECTED['productivity.test_drag.Entries_without_drag']          = test_drag_EXPECTED['Entries_without_drag']\n",
    "tu_.EXPECTED['productivity.test_drag.Commits_impl_with_drag']        = test_drag_EXPECTED['Commits_impl_with_drag']\n",
    "tu_.EXPECTED['productivity.test_drag.Commits_impl_without_drag']     = test_drag_EXPECTED['Commits_impl_without_drag']\n",
    "tu_.EXPECTED['productivity.test_drag.Commits_bugs_with_drag']        = test_drag_EXPECTED['Commits_bugs_with_drag']\n",
    "tu_.EXPECTED['productivity.test_drag.Commits_bugs_without_drag']     = test_drag_EXPECTED['Commits_bugs_without_drag']\n",
    "tu_.EXPECTED['productivity.test_drag.Commits_all_with_drag']         = test_drag_EXPECTED['Commits_all_with_drag']\n",
    "tu_.EXPECTED['productivity.test_drag.Commits_all_without_drag']      = test_drag_EXPECTED['Commits_all_without_drag']\n",
    "tu_.EXPECTED['productivity.test_drag.Impact']                        = test_drag_EXPECTED['Impact']\n",
    "\n",
    "tu_.ACTUAL['productivity.test_drag.Burnout_with_drag']             = test_drag_ACTUAL['Burnout_with_drag']\n",
    "tu_.ACTUAL['productivity.test_drag.Burnout_without_drag']          = test_drag_ACTUAL['Burnout_without_drag']\n",
    "tu_.ACTUAL['productivity.test_drag.Entries_with_drag']             = test_drag_ACTUAL['Entries_with_drag']\n",
    "tu_.ACTUAL['productivity.test_drag.Entries_without_drag']          = test_drag_ACTUAL['Entries_without_drag']\n",
    "tu_.ACTUAL['productivity.test_drag.Commits_impl_with_drag']        = test_drag_ACTUAL['Commits_impl_with_drag']\n",
    "tu_.ACTUAL['productivity.test_drag.Commits_impl_without_drag']     = test_drag_ACTUAL['Commits_impl_without_drag']\n",
    "tu_.ACTUAL['productivity.test_drag.Commits_bugs_with_drag']        = test_drag_ACTUAL['Commits_bugs_with_drag']\n",
    "tu_.ACTUAL['productivity.test_drag.Commits_bugs_without_drag']     = test_drag_ACTUAL['Commits_bugs_without_drag']\n",
    "tu_.ACTUAL['productivity.test_drag.Commits_all_with_drag']         = test_drag_ACTUAL['Commits_all_with_drag']\n",
    "tu_.ACTUAL['productivity.test_drag.Commits_all_without_drag']      = test_drag_ACTUAL['Commits_all_without_drag']\n",
    "tu_.ACTUAL['productivity.test_drag.Impact']                        = test_drag_ACTUAL['Impact']\n",
    "\n",
    "tu_.testOK('productivity.test_drag.Burnout_with_drag'), \\\n",
    "tu_.testOK('productivity.test_drag.Burnout_without_drag'), \\\n",
    "tu_.testOK('productivity.test_drag.Entries_with_drag'), \\\n",
    "tu_.testOK('productivity.test_drag.Entries_without_drag'), \\\n",
    "tu_.testOK('productivity.test_drag.Commits_impl_with_drag'), \\\n",
    "tu_.testOK('productivity.test_drag.Commits_impl_without_drag'), \\\n",
    "tu_.testOK('productivity.test_drag.Commits_bugs_with_drag'), \\\n",
    "tu_.testOK('productivity.test_drag.Commits_bugs_without_drag'), \\\n",
    "tu_.testOK('productivity.test_drag.Commits_all_with_drag'), \\\n",
    "tu_.testOK('productivity.test_drag.Commits_all_without_drag'), \\\n",
    "tu_.testOK('productivity.test_drag.Impact'), \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see chart. Then comment it again, as test harness will fail if it is not commented since it can't\n",
    "# load graphic libraries. Also, you may need to run this twice (some Jupyter bug apparently blocks rendering on\n",
    "# a first call)\n",
    "#CommitsAnalysis.chartCommits(analyzer.stats['With_drag'].commits_impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see chart. Then comment it again, as test harness will fail if it is not commented since it can't\n",
    "# load graphic libraries. Also, you may need to run this twice (some Jupyter bug apparently blocks rendering on\n",
    "# a first call)\n",
    "#CommitsAnalysis.chartCommits(analyzer.stats['Without_drag'].commits_impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_ACTUAL['Burnout_with_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_EXPECTED['Burnout_with_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_ACTUAL['Burnout_without_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_EXPECTED['Burnout_without_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_ACTUAL['Entries_with_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_EXPECTED['Entries_with_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_ACTUAL['Entries_without_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_EXPECTED['Entries_without_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_ACTUAL['Commits_impl_with_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_EXPECTED['Commits_impl_with_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_ACTUAL['Commits_impl_without_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_EXPECTED['Commits_impl_without_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_ACTUAL['Commits_bugs_with_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_EXPECTED['Commits_bugs_with_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_ACTUAL['Commits_bugs_without_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_EXPECTED['Commits_bugs_without_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_ACTUAL['Commits_all_with_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_EXPECTED['Commits_all_with_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_ACTUAL['Commits_all_without_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drag_EXPECTED['Commits_all_without_drag'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Full R&amp;D Team</th>\n",
       "      <th>Without drag (run #0)</th>\n",
       "      <th>% difference (run #0)</th>\n",
       "      <th>Without drag (run #1)</th>\n",
       "      <th>% difference (run #1)</th>\n",
       "      <th>Without drag (run #2)</th>\n",
       "      <th>% difference (run #2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Headcount</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-20.83</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-21.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Implementation Effort (days)</td>\n",
       "      <td>4692.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>-7.44</td>\n",
       "      <td>3948.0</td>\n",
       "      <td>-9.10</td>\n",
       "      <td>3588.0</td>\n",
       "      <td>-9.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Debugging Effort (days)</td>\n",
       "      <td>460.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>394.0</td>\n",
       "      <td>-4.83</td>\n",
       "      <td>314.0</td>\n",
       "      <td>-20.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total Effort (days)</td>\n",
       "      <td>5151.0</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>-7.65</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>-8.72</td>\n",
       "      <td>3903.0</td>\n",
       "      <td>-10.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cost ($)</td>\n",
       "      <td>477814.0</td>\n",
       "      <td>454002.0</td>\n",
       "      <td>-4.98</td>\n",
       "      <td>427520.0</td>\n",
       "      <td>-5.83</td>\n",
       "      <td>407009.0</td>\n",
       "      <td>-4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stories completed (#)</td>\n",
       "      <td>320.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When implementation is completed (sprint #)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.18</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.69</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When implementation is 90.0% completed (sprint #)</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.11</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Metric  Full R&D Team  \\\n",
       "0                                          Headcount           30.0   \n",
       "1                       Implementation Effort (days)         4692.0   \n",
       "2                            Debugging Effort (days)          460.0   \n",
       "3                                Total Effort (days)         5151.0   \n",
       "4                                           Cost ($)       477814.0   \n",
       "5                              Stories completed (#)          320.0   \n",
       "6        When implementation is completed (sprint #)           22.0   \n",
       "7  When implementation is 90.0% completed (sprint #)           18.0   \n",
       "\n",
       "   Without drag (run #0)  % difference (run #0)  Without drag (run #1)  \\\n",
       "0                   24.0                 -20.00                   19.0   \n",
       "1                 4343.0                  -7.44                 3948.0   \n",
       "2                  414.0                 -10.00                  394.0   \n",
       "3                 4757.0                  -7.65                 4342.0   \n",
       "4               454002.0                  -4.98               427520.0   \n",
       "5                  320.0                   0.00                  320.0   \n",
       "6                   26.0                  18.18                   28.0   \n",
       "7                   20.0                  11.11                   22.0   \n",
       "\n",
       "   % difference (run #1)  Without drag (run #2)  % difference (run #2)  \n",
       "0                 -20.83                   15.0                 -21.05  \n",
       "1                  -9.10                 3588.0                  -9.12  \n",
       "2                  -4.83                  314.0                 -20.30  \n",
       "3                  -8.72                 3903.0                 -10.11  \n",
       "4                  -5.83               407009.0                  -4.80  \n",
       "5                   0.00                  320.0                   0.00  \n",
       "6                   7.69                   30.0                   7.14  \n",
       "7                  10.00                   25.0                  13.64  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_drag_ACTUAL['Impact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Full R&amp;D Team</th>\n",
       "      <th>Without drag (run #0)</th>\n",
       "      <th>% difference (run #0)</th>\n",
       "      <th>Without drag (run #1)</th>\n",
       "      <th>% difference (run #1)</th>\n",
       "      <th>Without drag (run #2)</th>\n",
       "      <th>% difference (run #2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Headcount</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-20.83</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-21.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Implementation Effort (days)</td>\n",
       "      <td>4692.0</td>\n",
       "      <td>4343.0</td>\n",
       "      <td>-7.44</td>\n",
       "      <td>3948.0</td>\n",
       "      <td>-9.10</td>\n",
       "      <td>3588.0</td>\n",
       "      <td>-9.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Debugging Effort (days)</td>\n",
       "      <td>460.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>394.0</td>\n",
       "      <td>-4.83</td>\n",
       "      <td>314.0</td>\n",
       "      <td>-20.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total Effort (days)</td>\n",
       "      <td>5151.0</td>\n",
       "      <td>4757.0</td>\n",
       "      <td>-7.65</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>-8.72</td>\n",
       "      <td>3903.0</td>\n",
       "      <td>-10.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cost ($)</td>\n",
       "      <td>477814.0</td>\n",
       "      <td>454002.0</td>\n",
       "      <td>-4.98</td>\n",
       "      <td>427520.0</td>\n",
       "      <td>-5.83</td>\n",
       "      <td>407009.0</td>\n",
       "      <td>-4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stories completed (#)</td>\n",
       "      <td>320.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When implementation is completed (sprint #)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.18</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.69</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When implementation is 90.0% completed (sprint #)</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.11</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Metric  Full R&D Team  \\\n",
       "0                                          Headcount           30.0   \n",
       "1                       Implementation Effort (days)         4692.0   \n",
       "2                            Debugging Effort (days)          460.0   \n",
       "3                                Total Effort (days)         5151.0   \n",
       "4                                           Cost ($)       477814.0   \n",
       "5                              Stories completed (#)          320.0   \n",
       "6        When implementation is completed (sprint #)           22.0   \n",
       "7  When implementation is 90.0% completed (sprint #)           18.0   \n",
       "\n",
       "   Without drag (run #0)  % difference (run #0)  Without drag (run #1)  \\\n",
       "0                   24.0                 -20.00                   19.0   \n",
       "1                 4343.0                  -7.44                 3948.0   \n",
       "2                  414.0                 -10.00                  394.0   \n",
       "3                 4757.0                  -7.65                 4342.0   \n",
       "4               454002.0                  -4.98               427520.0   \n",
       "5                  320.0                   0.00                  320.0   \n",
       "6                   26.0                  18.18                   28.0   \n",
       "7                   20.0                  11.11                   22.0   \n",
       "\n",
       "   % difference (run #1)  Without drag (run #2)  % difference (run #2)  \n",
       "0                 -20.83                   15.0                 -21.05  \n",
       "1                  -9.10                 3588.0                  -9.12  \n",
       "2                  -4.83                  314.0                 -20.30  \n",
       "3                  -8.72                 3903.0                 -10.11  \n",
       "4                  -5.83               407009.0                  -4.80  \n",
       "5                   0.00                  320.0                   0.00  \n",
       "6                   7.69                   30.0                   7.14  \n",
       "7                  10.00                   25.0                  13.64  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_drag_EXPECTED['Impact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
