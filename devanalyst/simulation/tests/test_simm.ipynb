{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 15,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from random import choices\n",
    "from datetime import datetime\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 16,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {},
   "outputs": [],
   "source": [
    "import devanalyst.simulation.statics as S_\n",
<<<<<<< HEAD
    "from devanalyst.simulation.businessObjects import WorkAssignments, ReleaseCycleContext, UserStory, Ticket\n",
    "from devanalyst.simulation.simulationModels import BalancedAllocationModel, GreedyAllocationModel, ModelsConfig, \\\n",
    "DefaultCostModel, DistributedLagQualityModel\n"
=======
    "from devanalyst.simulation.businessObjects import WorkAssignments, ReleaseCycleContext\n",
    "from devanalyst.simulation.simulationModels import BalancedAllocationModel, GreedyAllocationModel, ModelsConfig, \\\n",
    "DefaultCostModel\n"
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\alejandro\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\tests\\test_utils.ipynb\n",
      "importing Jupyter notebook from c:\\alejandro\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\generateTimecards.ipynb\n"
     ]
    }
   ],
=======
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "source": [
    "import devanalyst.simulation.tests.test_utils as tu_\n",
    "from devanalyst.simulation.tests.test_utils import ExpectedOutputCleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>test_greedyAllocationLogs</h2>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 18,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Implement test logic, and run it\n",
    "\n",
    "#Test logic\n",
    "def test_greedyAllocationLogs():    \n",
    "    output = {}\n",
    "    RELEASE_DURATION = 125\n",
    "    SPRINT_DURATION = 10\n",
    "    SPRINT = 1\n",
    "\n",
    "    # Configure models\n",
    "    model = GreedyAllocationModel() \n",
    "    modelsConfig = ModelsConfig([], [], model)\n",
    "    modelsConfig.random.reset(271)\n",
    "\n",
    "    teams_df, stories_df, teamsRepo, storiesRepo, ticketsRepo = tu_.initTestData(tu_.DEV_DF, tu_.PM_DF, \\\n",
    "                                                                             RELEASE_DURATION, SPRINT_DURATION, modelsConfig)\n",
    "\n",
    "    \n",
    "    # Select a team\n",
    "    teamId = teams_df['Scrum Team'][0].teamId\n",
    "    \n",
    "    modelsConfig.context = ReleaseCycleContext(teamId, teamsRepo, storiesRepo, ticketsRepo, SPRINT, SPRINT_DURATION)\n",
    "       \n",
    "    work = WorkAssignments(modelsConfig.context)\n",
    "    work = model.allocate(work, modelsConfig)\n",
    "    \n",
    "    log_df = model.buildLog_df('Sprint 1 QA', modelsConfig.context)\n",
    "        \n",
    "    output['Logs'] = log_df\n",
    "    return output\n",
    "\n",
    "# Run the test\n",
    "test_greedyAllocationLogs_ACTUAL = test_greedyAllocationLogs()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 19,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Uncomment to update expected output to match the actual one\n",
    "\n",
    "# Helper method\n",
    "def create_greedyAllocationLogs_EXPECTED():\n",
    "    tu_.createExpectedOutput(test_greedyAllocationLogs_ACTUAL['Logs'],    'simm.test_greedyAllocationLogs')\n",
    "\n",
    "# Uncomment to update expected output to match the actual one, and then put the comment back\n",
    "#create_greedyAllocationLogs_EXPECTED()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 20,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {
    "code_folding": [
     0
    ]
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "source": [
    "# Load expected output, update the EXPECTED and ACTUAL dictionaries, and check test is OK\n",
    "list_cols = ['Initial Data - CURRENT_SPRINT', 'Final Data - CURRENT_SPRINT', 'Remaining Data - CURRENT_SPRINT',\\\n",
    "             'Initial Data - NEXT_SPRINT', 'Final Data - NEXT_SPRINT', 'Remaining Data - NEXT_SPRINT'\n",
    "            ]\n",
    "\n",
    "test_greedyAllocationLogs_EXPECTED = {}\n",
    "\n",
    "test_greedyAllocationLogs_EXPECTED['Logs']      = tu_.loadExpectedOutput('simm.test_greedyAllocationLogs', list_cols)\n",
    "\n",
    "# Rounding inaccuracies in saving and loading CSV will create an artificial mismatch between ACTUAL and EXPECTED\n",
    "# So round EXPECTED and ACTUAL to 6 decimal places for sensitive fields (any float)\n",
    "ExpectedOutputCleaner.cleanRoundingNoise(['Initial Mean - CURRENT_SPRINT', 'Final Mean - CURRENT_SPRINT', \\\n",
    "                                          'Remaining Mean - CURRENT_SPRINT', 'Initial Distance - CURRENT_SPRINT', \\\n",
    "                                          'Final Distance - CURRENT_SPRINT', 'Remaining Distance - CURRENT_SPRINT',\\\n",
    "                                          'Initial Mean - NEXT_SPRINT', 'Final Mean - NEXT_SPRINT', \\\n",
    "                                          'Remaining Mean - NEXT_SPRINT', 'Initial Distance - NEXT_SPRINT', \\\n",
    "                                          'Final Distance - NEXT_SPRINT', 'Remaining Distance - NEXT_SPRINT'],\n",
    "                                        ['Logs'],\n",
    "                                        test_greedyAllocationLogs_EXPECTED,\n",
    "                                        test_greedyAllocationLogs_ACTUAL)\n",
    "\n",
    "tu_.EXPECTED['simm.test_greedyAllocationLogs']      = test_greedyAllocationLogs_EXPECTED['Logs']\n",
    "\n",
    "tu_.ACTUAL['simm.test_greedyAllocationLogs']        = test_greedyAllocationLogs_ACTUAL['Logs']\n",
    "\n",
    "tu_.testOK('simm.test_greedyAllocationLogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_greedyAllocationLogs_ACTUAL['Logs'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_greedyAllocationLogs_EXPECTED['Logs'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Uncomment to interactively visualize the logs, and then comment again once interactive analysis is done. Commenting these\n",
    "# lines after interactive analysis is completed is required as test harness can't load these visualiations\n",
    "# libraries so leaving this uncommented will crash the entire test harness.\n",
    "# NOTE: MAY NEED TO RUN TWICE, as there seems to be a bug in Jupyter Notebook so on the first run there is no output\n",
    "#import devanalyst.simulation.visualizations.simm_visuals as simm_visuals\n",
    "#simm_visuals.renderLog(test_greedyAllocationLogs_ACTUAL['Logs'],'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Uncomment to interactively visualize the logs, and then comment again once interactive analysis is done. Commenting these\n",
    "# lines after interactive analysis is completed is required as test harness can't load these visualiations\n",
    "# libraries so leaving this uncommented will crash the entire test harness.\n",
    "# NOTE: MAY NEED TO RUN TWICE, as there seems to be a bug in Jupyter Notebook so on the first run there is no output\n",
    "#import devanalyst.simulation.visualizations.simm_visuals as simm_visuals\n",
    "#simm_visuals.renderLog(test_greedyAllocationLogs_EXPECTED['Logs'],'g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>test_greedyAllocation</h1>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 21,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Implement test logic, and run it\n",
    "\n",
    "#Test logic\n",
    "def test_greedyAllocation():    \n",
    "    output = {}\n",
    "    RELEASE_DURATION = 125\n",
    "    SPRINT_DURATION = 10\n",
    "\n",
    "    # Configure models\n",
    "    model = GreedyAllocationModel() \n",
    "    modelsConfig = ModelsConfig([], [], model)\n",
    "    modelsConfig.random.reset(271)\n",
    "\n",
    "    teams_df, stories_df, teamsRepo, storiesRepo, ticketsRepo = tu_.initTestData(tu_.DEV_DF, tu_.PM_DF, \\\n",
    "                                                                             RELEASE_DURATION, SPRINT_DURATION, modelsConfig)\n",
    "\n",
    "    # Select a team\n",
    "    teamId = teams_df['Scrum Team'][0].teamId\n",
    "    \n",
    "    # Choose what to work on at the start of a sprint.\n",
    "    SPRINT_DURATION = 10\n",
    "    SPRINT = 1\n",
    "    modelsConfig.context = ReleaseCycleContext(teamId, teamsRepo, storiesRepo, ticketsRepo, SPRINT, SPRINT_DURATION)\n",
    "   \n",
    "    work = WorkAssignments(modelsConfig.context)\n",
    "\n",
    "    work = model.allocate(work, modelsConfig)\n",
    "    \n",
    "    committed_df = work.committedTime(SPRINT_DURATION)\n",
    "    tasks_df = work.committedTasks()\n",
    "        \n",
    "    output['Committed'] = committed_df\n",
    "    output['Tasks'] = tasks_df\n",
    "    return output\n",
    "\n",
    "# Run the test\n",
    "test_greedyAllocation_ACTUAL = test_greedyAllocation()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 22,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Uncomment to update expected output to match the actual one\n",
    "\n",
    "# Helper method\n",
    "def create_greedyAllocation_EXPECTED():\n",
    "    tu_.createExpectedOutput(test_greedyAllocation_ACTUAL['Committed'],    'simm.test_greedyAllocation.Committed')\n",
    "    tu_.createExpectedOutput(test_greedyAllocation_ACTUAL['Tasks'],        'simm.test_greedyAllocation.Tasks')\n",
    "\n",
    "# Uncomment to update expected output to match the actual one, and then put the comment back\n",
    "#create_greedyAllocation_EXPECTED()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 23,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {
    "code_folding": [
     0
    ]
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "source": [
    "# Load expected output, update the EXPECTED and ACTUAL dictionaries, and check test is OK\n",
    "test_greedyAllocation_EXPECTED = {}\n",
    "\n",
    "test_greedyAllocation_EXPECTED['Committed']      = tu_.loadExpectedOutput('simm.test_greedyAllocation.Committed')\n",
    "test_greedyAllocation_EXPECTED['Tasks']          = tu_.loadExpectedOutput('simm.test_greedyAllocation.Tasks')\n",
    "\n",
    "# Rounding inaccuracies in saving and loading CSV will create an artificial mismatch between ACTUAL and EXPECTED\n",
    "# So round EXPECTED and ACTUAL to 6 decimal places for sensitive fields (any float)\n",
    "ExpectedOutputCleaner.cleanRoundingNoise(['Rejects (days)', 'Debugging (days)', 'Implementation (days)', 'Bandwidth',\\\n",
    "                                          'NEXT SPRINT (days)', 'NEXT SPRINT Bandwidth'],\n",
    "                                        ['Committed'],\n",
    "                                        test_greedyAllocation_EXPECTED,\n",
    "                                        test_greedyAllocation_ACTUAL)\n",
    "\n",
    "ExpectedOutputCleaner.cleanRoundingNoise(['Original Estimate', 'Effort Spent', 'Effort Remaining', 'Percent Achieved'],\n",
    "                                        ['Tasks'],\n",
    "                                        test_greedyAllocation_EXPECTED,\n",
    "                                        test_greedyAllocation_ACTUAL)\n",
    "\n",
    "tu_.EXPECTED['simm.test_greedyAllocation.Committed']      = test_greedyAllocation_EXPECTED['Committed']\n",
    "tu_.EXPECTED['simm.test_greedyAllocation.Tasks']          = test_greedyAllocation_EXPECTED['Tasks']\n",
    "\n",
    "tu_.ACTUAL['simm.test_greedyAllocation.Committed']        = test_greedyAllocation_ACTUAL['Committed']\n",
    "tu_.ACTUAL['simm.test_greedyAllocation.Tasks']            = test_greedyAllocation_ACTUAL['Tasks']\n",
    "\n",
    "tu_.testOK('simm.test_greedyAllocation.Committed'), \\\n",
    "tu_.testOK('simm.test_greedyAllocation.Tasks'), \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_greedyAllocation_ACTUAL['Committed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_greedyAllocation_EXPECTED['Committed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_greedyAllocation_ACTUAL['Tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_greedyAllocation_EXPECTED['Tasks']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>test_balancedAllocation</h1>"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 24,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Implement test logic, and run it\n",
    "\n",
    "#Test logic\n",
    "def test_balancedAllocation():    \n",
    "    output = {}\n",
    "    RELEASE_DURATION = 125\n",
    "    SPRINT_DURATION = 10\n",
    "\n",
    "    # Configure models\n",
    "    model = BalancedAllocationModel() \n",
    "    modelsConfig = ModelsConfig([], [], model)\n",
    "    modelsConfig.random.reset(271)\n",
    "\n",
    "    teams_df, stories_df, teamsRepo, storiesRepo, ticketsRepo = tu_.initTestData(tu_.DEV_DF, tu_.PM_DF, \\\n",
    "                                                                             RELEASE_DURATION, SPRINT_DURATION, modelsConfig)\n",
    "\n",
    "    # Select a team\n",
    "    teamId = teams_df['Scrum Team'][0].teamId\n",
    "    \n",
    "    # Choose what to work on at the start of a sprint.\n",
    "    SPRINT_DURATION = 10\n",
    "    SPRINT = 1\n",
    "    modelsConfig.context = ReleaseCycleContext(teamId, teamsRepo, storiesRepo, ticketsRepo, SPRINT, SPRINT_DURATION)\n",
    "   \n",
    "    work = WorkAssignments(modelsConfig.context)\n",
    "\n",
    "    work = model.allocate(work, modelsConfig)\n",
    "    \n",
    "    committed_df = work.committedTime(SPRINT_DURATION)\n",
    "    tasks_df = work.committedTasks()\n",
    "        \n",
    "    output['Committed'] = committed_df\n",
    "    output['Tasks'] = tasks_df\n",
    "    return output, work\n",
    "\n",
    "# Run the test\n",
    "test_balancedAllocation_ACTUAL, work = test_balancedAllocation()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 25,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Uncomment to update expected output to match the actual one\n",
    "\n",
    "# Helper method\n",
    "def create_balancedAllocation_EXPECTED():\n",
    "    tu_.createExpectedOutput(test_balancedAllocation_ACTUAL['Committed'],    'simm.test_balancedAllocation.Committed')\n",
    "    tu_.createExpectedOutput(test_balancedAllocation_ACTUAL['Tasks'],        'simm.test_balancedAllocation.Tasks')\n",
    "\n",
    "# Uncomment to update expected output to match the actual one, and then put the comment back\n",
    "#create_balancedAllocation_EXPECTED()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 26,
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "metadata": {
    "code_folding": [
     0
    ]
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
   "source": [
    "# Load expected output, update the EXPECTED and ACTUAL dictionaries, and check test is OK\n",
    "test_balancedAllocation_EXPECTED = {}\n",
    "\n",
    "test_balancedAllocation_EXPECTED['Committed']      = tu_.loadExpectedOutput('simm.test_balancedAllocation.Committed')\n",
    "test_balancedAllocation_EXPECTED['Tasks']          = tu_.loadExpectedOutput('simm.test_balancedAllocation.Tasks')\n",
    "\n",
    "# Rounding inaccuracies in saving and loading CSV will create an artificial mismatch between ACTUAL and EXPECTED\n",
    "# So round EXPECTED and ACTUAL to 6 decimal places for sensitive fields (any float)\n",
    "ExpectedOutputCleaner.cleanRoundingNoise(['Rejects (days)', 'Debugging (days)', 'Implementation (days)', 'Bandwidth',\\\n",
    "                                          'NEXT SPRINT (days)', 'NEXT SPRINT Bandwidth'],\n",
    "                                        ['Committed'],\n",
    "                                        test_balancedAllocation_EXPECTED,\n",
    "                                        test_balancedAllocation_ACTUAL)\n",
    "ExpectedOutputCleaner.cleanRoundingNoise(['Original Estimate', 'Effort Spent', 'Effort Remaining', 'Percent Achieved'],\n",
    "                                        ['Tasks'],\n",
    "                                        test_balancedAllocation_EXPECTED,\n",
    "                                        test_balancedAllocation_ACTUAL)\n",
    "\n",
    "tu_.EXPECTED['simm.test_balancedAllocation.Committed']      = test_balancedAllocation_EXPECTED['Committed']\n",
    "tu_.EXPECTED['simm.test_balancedAllocation.Tasks']          = test_balancedAllocation_EXPECTED['Tasks']\n",
    "\n",
    "tu_.ACTUAL['simm.test_balancedAllocation.Committed']        = test_balancedAllocation_ACTUAL['Committed']\n",
    "tu_.ACTUAL['simm.test_balancedAllocation.Tasks']            = test_balancedAllocation_ACTUAL['Tasks']\n",
    "\n",
    "tu_.testOK('simm.test_balancedAllocation.Committed'), \\\n",
    "tu_.testOK('simm.test_balancedAllocation.Tasks'), \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "test_balancedAllocation_ACTUAL['Committed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_balancedAllocation_EXPECTED['Committed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "test_balancedAllocation_ACTUAL['Tasks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_balancedAllocation_EXPECTED['Tasks']"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>test_distributedLagQualityModel</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Implement test logic, and run it\n",
    "\n",
    "#Test logic\n",
    "def test_distributedLagQualityModel():\n",
    "    output = {}\n",
    "    RELEASE_DURATION = 125\n",
    "    SPRINT_DURATION = 10\n",
    "\n",
    "    # Configure models\n",
    "    modelsConfig = ModelsConfig([DefaultCostModel()], [DistributedLagQualityModel()], GreedyAllocationModel()) \n",
    "    modelsConfig.random.reset(271)\n",
    "\n",
    "    teams_df, stories_df, teamsRepo, storiesRepo, ticketsRepo = tu_.initTestData(tu_.DEV_DF, tu_.PM_DF, \\\n",
    "                                                                             RELEASE_DURATION, SPRINT_DURATION, modelsConfig)\n",
    "    TEAM_ID = 'Team A'\n",
    "    SPRINT = 1\n",
    "    ctx = ReleaseCycleContext(TEAM_ID, teamsRepo, storiesRepo, ticketsRepo, SPRINT, SPRINT_DURATION)\n",
    "    modelsConfig.context = ctx\n",
    "    \n",
    "    # Pretend all stories have been completed on the first sprint\n",
    "    uss_list = []\n",
    "    ids = ctx.storiesRepo.findIds()\n",
    "    for userStoryId in ids:\n",
    "        uss = ctx.teamsRepo.getUserStoryStatus(userStoryId)\n",
    "        uss.percentAchieved = 1.0\n",
    "        uss.planned = True\n",
    "        uss.sprintPlanned = 1\n",
    "        uss.sprintDelivered = 1\n",
    "    \n",
    "    # Now pretend we raverse the next 5 sprints, generating bugs\n",
    "    bugs = []\n",
    "    for i in range(5):\n",
    "        ctx.sprint = SPRINT + i + 1\n",
    "        qualityModel = modelsConfig.qualityModels[0]\n",
    "        bugs.extend(qualityModel.findBugs(modelsConfig))\n",
    "    \n",
    "    bugs_df = Ticket.build_bugs_df(bugs)\n",
    "    \n",
    "    stories_df = UserStory.build_stories_df(modelsConfig.context)\n",
    "    \n",
    "    output['bugs'] = bugs_df\n",
    "    output['stories'] = stories_df\n",
    "\n",
    "    return output\n",
    "\n",
    "# Run the test\n",
    "test_distributedLagQualityModel_ACTUAL = test_distributedLagQualityModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Uncomment to update expected output to match the actual one\n",
    "\n",
    "# Helper method\n",
    "def create_distributedLagQualityModel_EXPECTED():\n",
    "    tu_.createExpectedOutput(test_distributedLagQualityModel_ACTUAL['bugs'],    'simm.test_distributedLagQualityModel.bugs')\n",
    "    tu_.createExpectedOutput(test_distributedLagQualityModel_ACTUAL['stories'], 'simm.test_distributedLagQualityModel.stories')\n",
    "\n",
    "# Uncomment to update expected output to match the actual one, and then put the comment back\n",
    "#create_distributedLagQualityModel_EXPECTED()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load expected output, update the EXPECTED and ACTUAL dictionaries, and check test is OK\n",
    "list_cols_bugs = [] # Lists are loaded as strings, so require special processing on load\n",
    "list_cols_stories = ['Open Bugs', 'Closed Bugs']\n",
    "test_distributedLagQualityModel_EXPECTED = {}\n",
    "\n",
    "test_distributedLagQualityModel_EXPECTED['bugs']     = tu_.loadExpectedOutput('simm.test_distributedLagQualityModel.bugs', \n",
    "                                                                              list_cols_bugs)\n",
    "test_distributedLagQualityModel_EXPECTED['stories']  = tu_.loadExpectedOutput('simm.test_distributedLagQualityModel.stories', \n",
    "                                                                              list_cols_stories)\n",
    "\n",
    "# Rounding inaccuracies in saving and loading CSV will create an artificial mismatch between ACTUAL and EXPECTED\n",
    "# So round EXPECTED and ACTUAL to 6 decimal places for sensitive fields (any float)\n",
    "\n",
    "ExpectedOutputCleaner.cleanRoundingNoise(['Estimated Cost', 'Effort to Date', 'Percent Achieved'],\n",
    "                                        ['bugs'],\n",
    "                                        test_distributedLagQualityModel_EXPECTED,\n",
    "                                        test_distributedLagQualityModel_ACTUAL)\n",
    "\n",
    "tu_.EXPECTED['simm.test_distributedLagQualityModel.bugs']        = test_distributedLagQualityModel_EXPECTED['bugs']\n",
    "tu_.EXPECTED['simm.test_distributedLagQualityModel.stories']     = test_distributedLagQualityModel_EXPECTED['stories']\n",
    "\n",
    "tu_.ACTUAL['simm.test_distributedLagQualityModel.bugs']          = test_distributedLagQualityModel_ACTUAL['bugs']\n",
    "tu_.ACTUAL['simm.test_distributedLagQualityModel.stories']       = test_distributedLagQualityModel_ACTUAL['stories']\n",
    "\n",
    "tu_.testOK('simm.test_distributedLagQualityModel.bugs'), \\\n",
    "tu_.testOK('simm.test_distributedLagQualityModel.stories'), \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket Id</th>\n",
       "      <th>User Story Id</th>\n",
       "      <th>Estimated Cost</th>\n",
       "      <th>Effort to Date</th>\n",
       "      <th>Percent Achieved</th>\n",
       "      <th>Sprint Reported</th>\n",
       "      <th>Sprint Fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ticket #1</td>\n",
       "      <td>UserStory #26</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ticket #2</td>\n",
       "      <td>UserStory #29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticket #3</td>\n",
       "      <td>UserStory #40</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ticket #4</td>\n",
       "      <td>UserStory #44</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket #5</td>\n",
       "      <td>UserStory #46</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ticket #6</td>\n",
       "      <td>UserStory #50</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ticket #7</td>\n",
       "      <td>UserStory #56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ticket #8</td>\n",
       "      <td>UserStory #58</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticket Id  User Story Id  Estimated Cost  Effort to Date  Percent Achieved  \\\n",
       "0  Ticket #1  UserStory #26             1.4             0.0               0.0   \n",
       "1  Ticket #2  UserStory #29             1.6             0.0               0.0   \n",
       "2  Ticket #3  UserStory #40             1.2             0.0               0.0   \n",
       "3  Ticket #4  UserStory #44             0.2             0.0               0.0   \n",
       "4  Ticket #5  UserStory #46             0.6             0.0               0.0   \n",
       "5  Ticket #6  UserStory #50             1.2             0.0               0.0   \n",
       "6  Ticket #7  UserStory #56             2.0             0.0               0.0   \n",
       "7  Ticket #8  UserStory #58             0.8             0.0               0.0   \n",
       "\n",
       "   Sprint Reported Sprint Fixed  \n",
       "0                2      NOT_SET  \n",
       "1                2      NOT_SET  \n",
       "2                2      NOT_SET  \n",
       "3                2      NOT_SET  \n",
       "4                2      NOT_SET  \n",
       "5                2      NOT_SET  \n",
       "6                2      NOT_SET  \n",
       "7                2      NOT_SET  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_distributedLagQualityModel_ACTUAL['bugs'][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket Id</th>\n",
       "      <th>User Story Id</th>\n",
       "      <th>Estimated Cost</th>\n",
       "      <th>Effort to Date</th>\n",
       "      <th>Percent Achieved</th>\n",
       "      <th>Sprint Reported</th>\n",
       "      <th>Sprint Fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ticket #1</td>\n",
       "      <td>UserStory #26</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ticket #2</td>\n",
       "      <td>UserStory #29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticket #3</td>\n",
       "      <td>UserStory #40</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ticket #4</td>\n",
       "      <td>UserStory #44</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket #5</td>\n",
       "      <td>UserStory #46</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ticket #6</td>\n",
       "      <td>UserStory #50</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ticket #7</td>\n",
       "      <td>UserStory #56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ticket #8</td>\n",
       "      <td>UserStory #58</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NOT_SET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticket Id  User Story Id  Estimated Cost  Effort to Date  Percent Achieved  \\\n",
       "0  Ticket #1  UserStory #26             1.4             0.0               0.0   \n",
       "1  Ticket #2  UserStory #29             1.6             0.0               0.0   \n",
       "2  Ticket #3  UserStory #40             1.2             0.0               0.0   \n",
       "3  Ticket #4  UserStory #44             0.2             0.0               0.0   \n",
       "4  Ticket #5  UserStory #46             0.6             0.0               0.0   \n",
       "5  Ticket #6  UserStory #50             1.2             0.0               0.0   \n",
       "6  Ticket #7  UserStory #56             2.0             0.0               0.0   \n",
       "7  Ticket #8  UserStory #58             0.8             0.0               0.0   \n",
       "\n",
       "   Sprint Reported Sprint Fixed  \n",
       "0                2      NOT_SET  \n",
       "1                2      NOT_SET  \n",
       "2                2      NOT_SET  \n",
       "3                2      NOT_SET  \n",
       "4                2      NOT_SET  \n",
       "5                2      NOT_SET  \n",
       "6                2      NOT_SET  \n",
       "7                2      NOT_SET  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_distributedLagQualityModel_EXPECTED['bugs'][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Story Id</th>\n",
       "      <th>Original Estimate</th>\n",
       "      <th>Team Id</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Product Manager</th>\n",
       "      <th>Percent Achieved</th>\n",
       "      <th>Planned</th>\n",
       "      <th>Sprint Planned</th>\n",
       "      <th>Sprint Delivered</th>\n",
       "      <th>Nb Open Bugs</th>\n",
       "      <th>Open Bugs</th>\n",
       "      <th>Nb Closed Bugs</th>\n",
       "      <th>Closed Bugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UserStory #1</td>\n",
       "      <td>10</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Beau Hockensmith</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[Ticket #23, Ticket #68]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UserStory #2</td>\n",
       "      <td>10</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Glenna Mcghie</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UserStory #3</td>\n",
       "      <td>4</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Francisco Hoppe</td>\n",
       "      <td>Edgar Hibbler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UserStory #4</td>\n",
       "      <td>7</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Beau Hockensmith</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UserStory #5</td>\n",
       "      <td>3</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Gregorio Darr</td>\n",
       "      <td>Edgar Hibbler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UserStory #6</td>\n",
       "      <td>3</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Beau Hockensmith</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Ticket #24]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UserStory #7</td>\n",
       "      <td>8</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Anton Easterday</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UserStory #8</td>\n",
       "      <td>9</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Anton Easterday</td>\n",
       "      <td>Edgar Hibbler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Ticket #25]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User Story Id  Original Estimate Team Id         Developer Product Manager  \\\n",
       "0  UserStory #1                 10  Team A  Beau Hockensmith  Sherlyn Cordle   \n",
       "1  UserStory #2                 10  Team A     Glenna Mcghie  Sherlyn Cordle   \n",
       "2  UserStory #3                  4  Team A   Francisco Hoppe   Edgar Hibbler   \n",
       "3  UserStory #4                  7  Team A  Beau Hockensmith  Sherlyn Cordle   \n",
       "4  UserStory #5                  3  Team A     Gregorio Darr   Edgar Hibbler   \n",
       "5  UserStory #6                  3  Team A  Beau Hockensmith  Sherlyn Cordle   \n",
       "6  UserStory #7                  8  Team A   Anton Easterday  Sherlyn Cordle   \n",
       "7  UserStory #8                  9  Team A   Anton Easterday   Edgar Hibbler   \n",
       "\n",
       "   Percent Achieved  Planned  Sprint Planned  Sprint Delivered  Nb Open Bugs  \\\n",
       "0               1.0     True               1                 1             2   \n",
       "1               1.0     True               1                 1             0   \n",
       "2               1.0     True               1                 1             0   \n",
       "3               1.0     True               1                 1             0   \n",
       "4               1.0     True               1                 1             0   \n",
       "5               1.0     True               1                 1             1   \n",
       "6               1.0     True               1                 1             0   \n",
       "7               1.0     True               1                 1             1   \n",
       "\n",
       "                  Open Bugs  Nb Closed Bugs Closed Bugs  \n",
       "0  [Ticket #23, Ticket #68]               0          []  \n",
       "1                        []               0          []  \n",
       "2                        []               0          []  \n",
       "3                        []               0          []  \n",
       "4                        []               0          []  \n",
       "5              [Ticket #24]               0          []  \n",
       "6                        []               0          []  \n",
       "7              [Ticket #25]               0          []  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_distributedLagQualityModel_ACTUAL['stories'][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Story Id</th>\n",
       "      <th>Original Estimate</th>\n",
       "      <th>Team Id</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Product Manager</th>\n",
       "      <th>Percent Achieved</th>\n",
       "      <th>Planned</th>\n",
       "      <th>Sprint Planned</th>\n",
       "      <th>Sprint Delivered</th>\n",
       "      <th>Nb Open Bugs</th>\n",
       "      <th>Open Bugs</th>\n",
       "      <th>Nb Closed Bugs</th>\n",
       "      <th>Closed Bugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UserStory #1</td>\n",
       "      <td>10</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Beau Hockensmith</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[Ticket #23, Ticket #68]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UserStory #2</td>\n",
       "      <td>10</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Glenna Mcghie</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UserStory #3</td>\n",
       "      <td>4</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Francisco Hoppe</td>\n",
       "      <td>Edgar Hibbler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UserStory #4</td>\n",
       "      <td>7</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Beau Hockensmith</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UserStory #5</td>\n",
       "      <td>3</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Gregorio Darr</td>\n",
       "      <td>Edgar Hibbler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UserStory #6</td>\n",
       "      <td>3</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Beau Hockensmith</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Ticket #24]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UserStory #7</td>\n",
       "      <td>8</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Anton Easterday</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UserStory #8</td>\n",
       "      <td>9</td>\n",
       "      <td>Team A</td>\n",
       "      <td>Anton Easterday</td>\n",
       "      <td>Edgar Hibbler</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Ticket #25]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User Story Id  Original Estimate Team Id         Developer Product Manager  \\\n",
       "0  UserStory #1                 10  Team A  Beau Hockensmith  Sherlyn Cordle   \n",
       "1  UserStory #2                 10  Team A     Glenna Mcghie  Sherlyn Cordle   \n",
       "2  UserStory #3                  4  Team A   Francisco Hoppe   Edgar Hibbler   \n",
       "3  UserStory #4                  7  Team A  Beau Hockensmith  Sherlyn Cordle   \n",
       "4  UserStory #5                  3  Team A     Gregorio Darr   Edgar Hibbler   \n",
       "5  UserStory #6                  3  Team A  Beau Hockensmith  Sherlyn Cordle   \n",
       "6  UserStory #7                  8  Team A   Anton Easterday  Sherlyn Cordle   \n",
       "7  UserStory #8                  9  Team A   Anton Easterday   Edgar Hibbler   \n",
       "\n",
       "   Percent Achieved  Planned  Sprint Planned  Sprint Delivered  Nb Open Bugs  \\\n",
       "0               1.0     True               1                 1             2   \n",
       "1               1.0     True               1                 1             0   \n",
       "2               1.0     True               1                 1             0   \n",
       "3               1.0     True               1                 1             0   \n",
       "4               1.0     True               1                 1             0   \n",
       "5               1.0     True               1                 1             1   \n",
       "6               1.0     True               1                 1             0   \n",
       "7               1.0     True               1                 1             1   \n",
       "\n",
       "                  Open Bugs  Nb Closed Bugs Closed Bugs  \n",
       "0  [Ticket #23, Ticket #68]               0          []  \n",
       "1                        []               0          []  \n",
       "2                        []               0          []  \n",
       "3                        []               0          []  \n",
       "4                        []               0          []  \n",
       "5              [Ticket #24]               0          []  \n",
       "6                        []               0          []  \n",
       "7              [Ticket #25]               0          []  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_distributedLagQualityModel_EXPECTED['stories'][:8]"
   ]
=======
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> dd7ee8957c40d843eb0d7a6b9f46f3dd33c43076
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
