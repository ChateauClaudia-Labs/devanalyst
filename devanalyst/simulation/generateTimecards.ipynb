{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-72cf8f10fece>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\alejandro\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\statics.ipynb\n",
      "importing Jupyter notebook from c:\\alejandro\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\businessObjects.ipynb\n",
      "importing Jupyter notebook from c:\\alejandro\\code\\chateauclaudia-labs\\devanalyst\\devanalyst\\simulation\\simulationModels.ipynb\n"
     ]
    }
   ],
   "source": [
    "import devanalyst.simulation.statics as S_\n",
    "from devanalyst.simulation.businessObjects import UserStory, UserStoriesRepo, Ticket, TicketsRepo, WorkItem, \\\n",
    "UserStoryStatus, Backlog, ScrumTeam, ScrumTeamsRepo, WorkAssignments, ReleaseCycleContext\n",
    "import devanalyst.simulation.simulationModels as simm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>User Stories</h1>\n",
    "<p>Capacity planning for the release: we create a backlog of stories. Initial resource allocations are made, but they might change in a sprint if needed</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class IdCounter:\n",
    "    def __init__(self):\n",
    "        self.counter = 1\n",
    "        \n",
    "    def increment(self):\n",
    "        self.counter += 1\n",
    "        \n",
    "    def next_id(self):\n",
    "        return self.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def generateNextUserStory(nextId, team, bandwidth, sprintDuration, modelsConfig):\n",
    "# Returns a UserStory, randomly choosing the amount of effort the UserStory might take (while fitting withing a sprint),\n",
    "# and assigning to a random developer in the team with enough time to do it, to a spec written by a randomly chosen \n",
    "# product manager from the team.\n",
    "#\n",
    "# Random choices are made using the random generator in the modelsConfig parameter.\n",
    "#\n",
    "# Depletes the time this UserStory would take from the bandwidth for the developer in question.\n",
    "#\n",
    "# If no developer in the team has time to do such a UserStory, returns 'None'\n",
    "\n",
    "    estimate = modelsConfig.random.pickHowLong(sprintDuration)\n",
    "\n",
    "    available = bandwidth[bandwidth >= estimate] # Subset of developers with enough time to do this user story\n",
    "    if (len(available) == 0):\n",
    "        return None\n",
    "    \n",
    "    developer = modelsConfig.random.pickOneIdx(available)\n",
    "    bandwidth[developer] -= estimate # deplete capacity now earmarked for this user story\n",
    "\n",
    "    productManager = modelsConfig.random.pickOne(team.productManagers)\n",
    "    \n",
    "    return UserStory('UserStory #' + str(nextId), estimate, developer, productManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def canResourceMoreWork(bandwidth, sprintDuration):\n",
    "# Helper function used in createUserStoryBacklog.\n",
    "# Returns a boolen on whether the team has enough capacity left in 'bandwidth' to resource one more user story\n",
    "#\n",
    "# -bandwidth: Pandas Series indexed on developers' names, with the values being the amount of unallocated days\n",
    "# for that developer.\n",
    "# -sprintDuration: integer representing duration of a sprint, in number of days \n",
    "\n",
    "    # If over half the developers in the team have at least half a sprint left, still can resource more work\n",
    "    numberOfDevelopers = bandwidth.size\n",
    "    condition1 = bandwidth[bandwidth > sprintDuration/2.0].size > numberOfDevelopers / 2.0\n",
    "    \n",
    "    # If any developer in the team has more than 150% of a sprint left, then can still resource more work\n",
    "    condition2 = bandwidth.max() >= 1.5 * sprintDuration\n",
    "    \n",
    "    return condition1 or condition2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def createUserStoryBacklog(team, releaseDuration, sprintDuration, counter, modelsConfig):\n",
    "#Creates user stories that a scrum team should work on for a release. Algorithm basically determines how much time \n",
    "# there is in a planned duration for a release, and based on that randomly creates user stories associated with the\n",
    "# areas of responsibility of the scrum team in question, until capacity is filled to between 90% and 100%. Each user story \n",
    "# is supposed to be completed in a sprint, so a user story's estimated duration is ramdomly generated to be between\n",
    "# 10% and 100% of the sprint's duration period.\n",
    "#\n",
    "# -team: the ScrumTeam for which the backlog is being created\n",
    "# -releaseDuration: integer number of business days to the intended release date. Defaults to around 6 months\n",
    "# -sprintDuration: integer number of business days that a sprint lasts. Defaults to 2 weeks. \n",
    "# -counter: an IdCounter, to tell us what is the id for the next user story to create. This method increments the counter\n",
    "# -modelsConfig: a ModelsConfig instance with a random generator used in the creation of user stories.\n",
    "# with each user story that is created.\n",
    "\n",
    "    numberOfDevelopers = len(team.developers)\n",
    "    initialCapacity = numberOfDevelopers *releaseDuration # number of work-days available for the release\n",
    "    bandwidth = pd.Series(releaseDuration, team.developers) # initialize bandwidth to all the time left in the release\n",
    "\n",
    "    #numberOfSprints = releaseDuration/sprintDuration\n",
    "    stories = []\n",
    "    backlog = Backlog()     \n",
    "    \n",
    "    # We allocate as much of the team as practical, with user stories ranging in estimated duration from 1 day\n",
    "    # to the number of days in a sprint. To avoid artificial situations, don't aim to fill every single day,\n",
    "    # so will stop when we have allocated at least 10% and there is no developer left with enough bandwidth\n",
    "    # to resource a medium-size user story.\n",
    "    # To avoid infinite loops, we force a stop after 1000 tries, though most likely we will exit well before then.\n",
    "    next_id = counter.next_id()\n",
    "    while (canResourceMoreWork(bandwidth, sprintDuration) and next_id < 10000): #To avoid infinite loops, cap number of user stories\n",
    "        story = generateNextUserStory(next_id, team, bandwidth, sprintDuration, modelsConfig) #this call mutates bandwidth\n",
    "        if (story == None):\n",
    "            continue #Try again, maybe we tried for a very large estimate but a smaller user story can still be resourced\n",
    "        stories.append(story)\n",
    "        \n",
    "        counter.increment()\n",
    "        next_id = counter.next_id()\n",
    "        backlog.pendingUserStories.append(UserStoryStatus(story.userStoryId))       \n",
    "    \n",
    "    return stories, backlog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Do a sprint</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def chooseWhatToDoInSprint(modelsConfig):\n",
    "# At the start of a sprint, elects what items a team will do in a sprint\n",
    "#\n",
    "# -teamId: string identifier of team for which we are choosing work for this sprint\n",
    "# sprintDuration: length of the sprint for which work needs to be chosen, in man-days\n",
    "# -modelsConfig: a ModelsConfig instance with parameters for making the choice of work to do in the sprint\n",
    "# -sprint: integer representing which sprint we are in\n",
    "\n",
    "    \n",
    "    allocationModel = modelsConfig.allocationModel\n",
    "    work = WorkAssignments(modelsConfig.context, modelsConfig.globalRepo)\n",
    "    \n",
    "    return allocationModel.allocate(work, modelsConfig) # Mutates work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def inflowOfTickets(modelsConfig):\n",
    "# Returns an array of newly generated tickets against the work done by the team\n",
    "    bugs = []\n",
    "    for qualityModel in modelsConfig.qualityModels:\n",
    "        bugs.extend(qualityModel.findBugs(modelsConfig))\n",
    "    return bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def bookDeveloperEffort(items, budget, modelsConfig):\n",
    "# Helper class, used as part of the book keeping involved in delivering a sprint.\n",
    "#\n",
    "# Returns what portion of the budget, if any, was left over after booking the work done by the developer\n",
    "#\n",
    "# -items: a list of WorkItem objects that record work that should be done in a sprint by a single developer. \n",
    "# It will be mutated by this fundtion by recording what were the actual number of man-days spent on each WorkItem, and to what degree it was completed\n",
    "# -budget: number of man-days that the developer was given to try to complete the WorkItems\n",
    "# -modelsConfig: a ModelsConfig instance to model how real costs differ from estimates\n",
    "\n",
    "    for task in items:\n",
    "        if budget <= 0:\n",
    "            break # No more tasks progressed during this sprint\n",
    "        realCost = simm.computeRealCost(task, modelsConfig)\n",
    "        if realCost == 0:\n",
    "            continue # Boundary base. Shouldn't happen, but if someone entered an estimate of 0 don't want to divide by 0\n",
    "        if realCost <= budget:\n",
    "            task.percentAchieved = 1\n",
    "            task.actual = realCost\n",
    "            budget -= realCost\n",
    "        else:\n",
    "            # Can only complete part of the item\n",
    "            task.percentAchieved = budget/realCost\n",
    "            task.actual = budget\n",
    "            budget = 0\n",
    "    return budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def deliverSprint(work, modelsConfig):\n",
    "# Based on the team's productivy during the sprint, record how much of the work initially planned for the sprint\n",
    "# actually gets done\n",
    "#\n",
    "# -work: a WorkAssignment as it was at the start of the sprint. It is mutated by this method by recording, for each\n",
    "# WorkItem in the WorkAssignment, what percentage of it got accomplished\n",
    "# -sprintDuration: number of man-days that sprint lasted\n",
    "# -modelsConfig: a ModelsConfig instance to model how real costs differ from estimates\n",
    "\n",
    "    teamId                 = modelsConfig.context.teamId\n",
    "    sprintDuration         = modelsConfig.context.sprintDuration\n",
    "    sprint                 = modelsConfig.context.sprint\n",
    "\n",
    "    teamsRepo              = modelsConfig.globalRepo.teamsRepo\n",
    "    storiesRepo            = modelsConfig.globalRepo.storiesRepo\n",
    "    ticketsRepo            = modelsConfig.globalRepo.ticketsRepo\n",
    "\n",
    "    team = teamsRepo.findTeam(teamId)\n",
    "    for person in team.developers:\n",
    "        budget = sprintDuration # Developer has up to these many days to complete work in the sprint\n",
    "        \n",
    "        # First, deliver the work from the current sprint\n",
    "        budget = bookDeveloperEffort(work.getWorkItems(person, S_.CURRENT_SPRINT), budget, modelsConfig)\n",
    "                \n",
    "        # Second, developer still has some time in his/her budget for this sprint, then he/she might have started to work\n",
    "        # on things for the next sprint, in which case record that progress\n",
    "        budget = bookDeveloperEffort(work.getWorkItems(person, S_.NEXT_SPRINT), budget, modelsConfig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def updateBacklogAfterSprint(work, modelsConfig):\n",
    "# At the end of a sprint, updates the backlog of a team based on the work completed in this sprint\n",
    "#\n",
    "# -work: a WorkAssignment, which reflects what was accomplished during the sprint through the field percentAchieved\n",
    "# in each of the WorkItems in the various arrays within the work.allocations dictionary\n",
    "\n",
    "    teamId                 = modelsConfig.context.teamId\n",
    "    teamsRepo              = modelsConfig.globalRepo.teamsRepo\n",
    "\n",
    "    team = teamsRepo.findTeam(teamId)\n",
    "    completedWork = []\n",
    "    for person in team.developers:\n",
    "        completedWork.extend(work.getWorkItems(person, S_.CURRENT_SPRINT))\n",
    "        completedWork.extend(work.getWorkItems(person, S_.NEXT_SPRINT))\n",
    "    \n",
    "    team.backlog.updateStatus(completedWork, modelsConfig.context, modelsConfig.globalRepo) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Functions to Generate Timecards</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0,
     12
    ]
   },
   "outputs": [],
   "source": [
    "def addBusinessDays(start, duration):\n",
    "# Returns a datetime.date object which is several business days after the input 'start'\n",
    "    remainsToAdd = duration\n",
    "    current = start\n",
    "    while remainsToAdd > 0:\n",
    "        current = current + timedelta(1)\n",
    "        weekday = current.weekday()\n",
    "        if weekday >= 5: # sunday = 6\n",
    "            continue\n",
    "        remainsToAdd -= 1\n",
    "    return current\n",
    "\n",
    "def subtractBusinessDays(start, duration):\n",
    "# Returns a datetime.date object which is several business days before the input 'start'\n",
    "    remainsToSubtract = duration\n",
    "    current = start\n",
    "    while remainsToSubtract > 0:\n",
    "        current = current - timedelta(1)\n",
    "        weekday = current.weekday()\n",
    "        if weekday >= 5: # sunday = 6\n",
    "            continue\n",
    "        remainsToSubtract -= 1\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     18,
     22,
     45,
     57,
     84,
     110,
     114,
     181,
     276,
     327,
     351
    ]
   },
   "outputs": [],
   "source": [
    "class ReleaseLog:\n",
    "    \n",
    "    BREAKOUT = 'Breakout'\n",
    "    COMPLETED = 'Completed'\n",
    "    REGRESSED = 'Regressed' # Used for user stories considered \"completed\" but which have open Tickets against them\n",
    "    NEW_WORK = 'New Work'\n",
    "    NOT_STARTED = 'Not Started'\n",
    "    OVER_BUDGET = 'Over Budget'\n",
    "    PRIOR_PROGRESSED = 'Prior Progressed'\n",
    "    PRIOR_TO_FINISH = 'Prior to Finish'\n",
    "    PROGRESSED = 'Progressed'\n",
    "    TO_FINISH = 'To Finish'\n",
    "    UNPLANNED = 'Unplanned'\n",
    "    \n",
    "    SNAPSHOTS = ['planned_Start_CURRENT_SPRINT', 'planned_End_CURRENT_SPRINT', \n",
    "                      'planned_Start_NEXT_SPRINT', 'planned_End_NEXT_SPRINT', \n",
    "                      'backlog', 'Resourcing', 'Outcome']  \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.log = {}\n",
    "        \n",
    "    \n",
    "    def _getPlans(self, work):\n",
    "        unassigned = work.allocations[S_.UNPLANNED][S_.OWNER_TBD]\n",
    "        unplanned = []\n",
    "        unplanned.extend(unassigned[S_.PRODUCTION_BUGS])\n",
    "        unplanned.extend(unassigned[S_.DEV_TIME_BUGS])\n",
    "        unplanned.extend(unassigned[S_.UNFINISHED_STORIES])\n",
    "    \n",
    "        planned_CURRENT_SPRINT = []\n",
    "        subwork = work.allocations[S_.CURRENT_SPRINT]\n",
    "        for person in subwork.keys():\n",
    "            planned_CURRENT_SPRINT.extend(subwork[person][S_.PRODUCTION_BUGS])\n",
    "            planned_CURRENT_SPRINT.extend(subwork[person][S_.DEV_TIME_BUGS])\n",
    "            planned_CURRENT_SPRINT.extend(subwork[person][S_.UNFINISHED_STORIES])\n",
    "\n",
    "        planned_NEXT_SPRINT = []\n",
    "        subwork = work.allocations[S_.NEXT_SPRINT]\n",
    "        for person in subwork.keys():\n",
    "            planned_NEXT_SPRINT.extend(subwork[person][S_.PRODUCTION_BUGS])\n",
    "            planned_NEXT_SPRINT.extend(subwork[person][S_.DEV_TIME_BUGS])\n",
    "            planned_NEXT_SPRINT.extend(subwork[person][S_.UNFINISHED_STORIES])\n",
    "            \n",
    "        return planned_CURRENT_SPRINT, planned_NEXT_SPRINT, unplanned\n",
    "        \n",
    "    def snapshotSprintBacklog(self, modelsConfig):\n",
    "\n",
    "        teamId                 = modelsConfig.context.teamId\n",
    "        sprint                 = modelsConfig.context.sprint\n",
    "\n",
    "        if (teamId not in self.log.keys()):\n",
    "            self.log[teamId] = {}\n",
    "        if (sprint not in self.log[teamId].keys()):\n",
    "            self.log[teamId][sprint] = {}\n",
    "    \n",
    "        self.log[teamId][sprint]['backlog']             = ReleaseLog._build_backlog_df(modelsConfig.context,\n",
    "                                                                                       modelsConfig.globalRepo)\n",
    "    def snapshotSprintPlan(self, work, modelsConfig):\n",
    "\n",
    "        teamId                 = modelsConfig.context.teamId\n",
    "        sprintDuration         = modelsConfig.context.sprintDuration\n",
    "        sprint                 = modelsConfig.context.sprint\n",
    "\n",
    "        teamsRepo              = modelsConfig.globalRepo.teamsRepo\n",
    "        storiesRepo            = modelsConfig.globalRepo.storiesRepo\n",
    "        ticketsRepo            = modelsConfig.globalRepo.ticketsRepo\n",
    "\n",
    "        if (teamId not in self.log.keys()):\n",
    "            self.log[teamId] = {}\n",
    "        if (sprint not in self.log[teamId].keys()):\n",
    "            self.log[teamId][sprint] = {}\n",
    "    \n",
    "        planned_CURRENT_SPRINT, planned_NEXT_SPRINT, unplanned = self._getPlans(work)\n",
    "        \n",
    "        phase = 'Start'\n",
    "        self.log[teamId][sprint]['planned_' + phase + '_CURRENT_SPRINT'] = ReleaseLog._build_plan_df(planned_CURRENT_SPRINT,\n",
    "                                                                                                     modelsConfig.context,\n",
    "                                                                                                    modelsConfig.globalRepo)\n",
    "        self.log[teamId][sprint]['planned_' + phase + '_NEXT_SPRINT']    = ReleaseLog._build_plan_df(planned_NEXT_SPRINT,\n",
    "                                                                                                      modelsConfig.context,\n",
    "                                                                                                    modelsConfig.globalRepo)\n",
    "        self.log[teamId][sprint]['Resourcing'] = work.committedTime(modelsConfig.context.sprintDuration)\n",
    "\n",
    "        \n",
    "    def snapshotSprintOutcome(self, work, modelsConfig):\n",
    "\n",
    "        teamId                 = modelsConfig.context.teamId        \n",
    "        sprintDuration         = modelsConfig.context.sprintDuration\n",
    "        sprint                 = modelsConfig.context.sprint\n",
    "\n",
    "        teamsRepo              = modelsConfig.globalRepo.teamsRepo\n",
    "        storiesRepo            = modelsConfig.globalRepo.storiesRepo\n",
    "        ticketsRepo            = modelsConfig.globalRepo.ticketsRepo\n",
    "\n",
    "        if (teamId not in self.log.keys()):\n",
    "            self.log[teamId] = {}\n",
    "        if (sprint not in self.log[teamId].keys()):\n",
    "            self.log[teamId][sprint] = {}\n",
    "    \n",
    "        planned_CURRENT_SPRINT, planned_NEXT_SPRINT, unplanned = self._getPlans(work)\n",
    "        \n",
    "        phase = 'End'\n",
    "        self.log[teamId][sprint]['planned_' + phase + '_CURRENT_SPRINT'] = ReleaseLog._build_outcome_df(planned_CURRENT_SPRINT,\n",
    "                                                                                                        modelsConfig.context,\n",
    "                                                                                                        modelsConfig.globalRepo)\n",
    "        self.log[teamId][sprint]['planned_' + phase + '_NEXT_SPRINT']    = ReleaseLog._build_outcome_df(planned_NEXT_SPRINT,\n",
    "                                                                                                     modelsConfig.context,\n",
    "                                                                                                        modelsConfig.globalRepo)\n",
    "        self.log[teamId][sprint]['Outcome'] = work.committedTasks()\n",
    "        \n",
    "    def _getCategory(estimate):\n",
    "        cat = int(estimate)\n",
    "        return cat\n",
    "        \n",
    "    def _build_plan_df(allocations, context, globalRepo):\n",
    "\n",
    "        sprintDuration         = context.sprintDuration\n",
    "\n",
    "        teamsRepo              = globalRepo.teamsRepo\n",
    "        storiesRepo            = globalRepo.storiesRepo\n",
    "        ticketsRepo            = globalRepo.ticketsRepo\n",
    "\n",
    "        cols = [ReleaseLog.BREAKOUT]\n",
    "        categories = []\n",
    "        # Used categories go 1, 2, ..., sprintDuration, corresponding to the original estimates for user stories. \n",
    "        # Spurious category 0 will be never used, but no harm in having it.\n",
    "        for x in range(sprintDuration + 1): \n",
    "            \n",
    "            category = x\n",
    "            categories.append(category)\n",
    "        cols.extend(categories)\n",
    "\n",
    "        prior_progressed = [ReleaseLog.PRIOR_PROGRESSED]\n",
    "        prior_remaining = [ReleaseLog.PRIOR_TO_FINISH]\n",
    "        new_work = [ReleaseLog.NEW_WORK] \n",
    "        regressed = [ReleaseLog.REGRESSED]\n",
    "\n",
    "        for cat in categories:\n",
    "            prior_progressed.append(0.0)\n",
    "            prior_remaining.append(0.0)\n",
    "            new_work.append(0.0)\n",
    "            regressed.append(0.0)\n",
    "        \n",
    "        bugs_per_story = {} # Dictionary where keys are user story ids and values are the bugs associated with it\n",
    "        for item in allocations:\n",
    "            story = storiesRepo.findStory(item.userStoryId)\n",
    "            uss = teamsRepo.getUserStoryStatus(item.userStoryId)\n",
    "            cat = ReleaseLog._getCategory(story.originalEstimate)\n",
    "            idx = categories.index(cat) + 1 # offset by 1 since first element in arrays is the layer\n",
    "        \n",
    "            if (uss.percentAchieved == 0.0):\n",
    "                new_work[idx] += 1\n",
    "            else:\n",
    "                if (uss.percentAchieved < 1.0):\n",
    "                    prior_progressed[idx] += (story.originalEstimate * uss.percentAchieved)/story.originalEstimate\n",
    "                    prior_remaining[idx] += (story.originalEstimate * (1-uss.percentAchieved))/story.originalEstimate\n",
    "                else: \n",
    "                # Must be a bug on a story already completed. So we need to increment the 'regressed' counter, but this\n",
    "                # is tricky: even if there\n",
    "                # are multiple bugs on a user story we want to increment it only once. Therefore we do so only if the \n",
    "                # 'bugs_per_story' records no prior bugs for this story in this loop, i.e. for the first bug\n",
    "                    ticket = ticketsRepo.findTicket(item.ticketId)\n",
    "                    assert(ticket != None)\n",
    "                    if item.userStoryId not in bugs_per_story.keys(): # First bug we see on this user story\n",
    "                        regressed[idx] += 1\n",
    "                        bugs_per_story[item.userStoryId] = [ticket]\n",
    "                    else:\n",
    "                        bugs_per_story[item.userStoryId].append(ticket)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "         \n",
    "        data = []\n",
    "        data.append(prior_progressed)\n",
    "        data.append(prior_remaining)\n",
    "        data.append(new_work)\n",
    "        data.append(regressed)\n",
    "        data_df = pd.DataFrame(data, columns=cols)\n",
    "        return data_df\n",
    "    \n",
    "    def _build_outcome_df(allocations, context, globalRepo):\n",
    "\n",
    "        sprintDuration         = context.sprintDuration\n",
    "\n",
    "        teamsRepo              = globalRepo.teamsRepo\n",
    "        storiesRepo            = globalRepo.storiesRepo\n",
    "        ticketsRepo            = globalRepo.ticketsRepo\n",
    "        \n",
    "        cols = [ReleaseLog.BREAKOUT]\n",
    "        categories = []\n",
    "        for x in range(sprintDuration + 1): # inlude 0 as a category for tasks with less than 1 person-day to go\n",
    "            category = x\n",
    "            categories.append(category)\n",
    "        cols.extend(categories)\n",
    "\n",
    "        completed = [ReleaseLog.COMPLETED]\n",
    "        progressed = [ReleaseLog.PROGRESSED]\n",
    "        to_finish = [ReleaseLog.TO_FINISH] \n",
    "        not_started = [ReleaseLog.NOT_STARTED] \n",
    "        over_budget = [ReleaseLog.OVER_BUDGET] \n",
    "        regressed = [ReleaseLog.REGRESSED]\n",
    "\n",
    "        for cat in categories:\n",
    "            completed.append(0.0)\n",
    "            progressed.append(0.0)\n",
    "            to_finish.append(0.0)\n",
    "            not_started.append(0.0)\n",
    "            over_budget.append(0.0)\n",
    "            regressed.append(0.0)\n",
    "        \n",
    "        # Dictionary where keys are user story ids and values are two dictionaries: one for open bugs and one for\n",
    "        # closed bugs associated with it\n",
    "        bugs_per_story = {} \n",
    "        OPEN_BUGS    = 'OPEN_BUGS'\n",
    "        CLOSED_BUGS  = 'CLOSED_BUGS'\n",
    "        \n",
    "        for item in allocations:\n",
    "            story = storiesRepo.findStory(item.userStoryId)\n",
    "            uss = teamsRepo.getUserStoryStatus(item.userStoryId)\n",
    "            cat = ReleaseLog._getCategory(story.originalEstimate)\n",
    "            idx = categories.index(cat) + 1 # offset by 1 since first element in arrays is the layer\n",
    "        \n",
    "            if (uss.percentAchieved == 1.0):\n",
    "                # Two possibilities: either we 1) completed the story in this sprint, or 2) completed it in a prior\n",
    "                # sprint and this WorkItem is for a bug on that story. In case 1) we increment the 'completed' counter,\n",
    "                # and in case 2) we need to increment the 'regressed' counter, but the latter is tricky: even if there\n",
    "                # are multiple bugs on a user story we want to increment it only once. Therefore we do so only if the \n",
    "                # 'bugs_per_story' records no prior bugs for this story in this loop, i.e., for the first bug\n",
    "                if (item.taskType == S_.UNFINISHED_STORIES):\n",
    "                    completed[idx] += 1\n",
    "                else: # Must be a bug\n",
    "                    ticket = ticketsRepo.findTicket(item.ticketId)\n",
    "                    assert(ticket != None)\n",
    "                    # Record this is a  ticket. After loop in another loop we increment counters\n",
    "                    if item.userStoryId not in bugs_per_story.keys(): #Create the key with an empty value\n",
    "                        bugs_per_story[item.userStoryId] = {OPEN_BUGS: [], CLOSED_BUGS: []}\n",
    "                        \n",
    "                    if item.percentAchieved == 1.0:  \n",
    "                        bugs_per_story[item.userStoryId][CLOSED_BUGS].append(ticket)\n",
    "                    else:\n",
    "                        bugs_per_story[item.userStoryId][OPEN_BUGS].append(ticket)\n",
    "            else:\n",
    "                if (uss.percentAchieved == 0.0):\n",
    "                    not_started[idx] += 1\n",
    "                else:\n",
    "                    progressed[idx] += (story.originalEstimate * uss.percentAchieved)/story.originalEstimate\n",
    "                    to_finish[idx] += (story.originalEstimate * (1-uss.percentAchieved))/story.originalEstimate\n",
    "                    \n",
    "            over_budget[idx] += (item.actual - item.estimate*item.percentAchieved)/story.originalEstimate\n",
    "            \n",
    "        # We need to loop again, not over the items but over the bugs we detected. Bugs are always against stories\n",
    "        # completed in prior releases. So the counters to increment are associated to regressions for the story, and\n",
    "        # even if there are multiple bugs we only increment one counter and only once (since we are counting \n",
    "        # stories in the logs, not bugs). So if there are open bugs, count it as a regression. Otherwise if\n",
    "        # there are no open bugs but there are closed bugs, count it as a completion. Else no counter grows            \n",
    "        for storyId in bugs_per_story.keys():\n",
    "            story = storiesRepo.findStory(storyId)\n",
    "            cat = ReleaseLog._getCategory(story.originalEstimate)\n",
    "            idx = categories.index(cat) + 1 # offset by 1 since first element in arrays is the layer\n",
    "            if len(bugs_per_story[storyId][OPEN_BUGS]) > 0: # we didn't fix all the bugs we set out to in the sprint\n",
    "                regressed[idx] += 1\n",
    "            else:\n",
    "                if len(bugs_per_story[storyId][CLOSED_BUGS]) > 0: # we planned to fix bugs and we fixed them all\n",
    "                    completed[idx] += 1\n",
    "         \n",
    "        data = []\n",
    "        data.append(completed)\n",
    "        data.append(progressed)\n",
    "        data.append(to_finish)\n",
    "        data.append(not_started)\n",
    "        data.append(over_budget)\n",
    "        data.append(regressed)\n",
    "        data_df = pd.DataFrame(data, columns=cols)\n",
    "        return data_df\n",
    "\n",
    "    def _build_backlog_df(context, globalRepo):\n",
    "        \n",
    "        teamId                 = context.teamId\n",
    "        sprintDuration         = context.sprintDuration\n",
    "\n",
    "        teamsRepo              = globalRepo.teamsRepo\n",
    "        storiesRepo            = globalRepo.storiesRepo\n",
    "        ticketsRepo            = globalRepo.ticketsRepo\n",
    "        \n",
    "        team = teamsRepo.findTeam(teamId)\n",
    "        backlog = team.backlog.pendingUserStories\n",
    "        \n",
    "        cols = [ReleaseLog.BREAKOUT]\n",
    "        categories = []\n",
    "        for x in range(sprintDuration + 1): # inlude 0 as a category for tasks with less than 1 person-day to go\n",
    "            category = x\n",
    "            categories.append(category)\n",
    "        cols.extend(categories)\n",
    "\n",
    "        unplanned = [ReleaseLog.UNPLANNED]\n",
    "        completed = [ReleaseLog.COMPLETED]\n",
    "        planned_progressed = [ReleaseLog.PROGRESSED]\n",
    "        planned_remaining = [ReleaseLog.TO_FINISH]\n",
    "        not_started = [ReleaseLog.NOT_STARTED]\n",
    "        regressed = [ReleaseLog.REGRESSED]\n",
    "\n",
    "        for cat in categories:\n",
    "            unplanned.append(0.0)\n",
    "            completed.append(0.0)\n",
    "            planned_progressed.append(0.0)\n",
    "            planned_remaining.append(0.0)\n",
    "            not_started.append(0.0)\n",
    "            regressed.append(0.0)\n",
    "        \n",
    "        for uss in backlog:\n",
    "            story = storiesRepo.findStory(uss.userStoryId)\n",
    "            cat = ReleaseLog._getCategory(story.originalEstimate)\n",
    "            idx = categories.index(cat) + 1 # offset by 1 since first element in arrays is the layer\n",
    "        \n",
    "            if (uss.percentAchieved == 0.0):\n",
    "                if (uss.planned == False):\n",
    "                    unplanned[idx] += 1\n",
    "                else:\n",
    "                    not_started[idx] += 1\n",
    "            else:\n",
    "                if (uss.percentAchieved == 1.0):\n",
    "                    bugs = ticketsRepo.getOpenTickets(uss.userStoryId)\n",
    "                    if (len(bugs) > 0):\n",
    "                        regressed[idx] += 1\n",
    "                    else:\n",
    "                        completed[idx] += 1                    \n",
    "                else:\n",
    "                    planned_progressed[idx] += (story.originalEstimate * uss.percentAchieved)/story.originalEstimate\n",
    "                    planned_remaining[idx] += (story.originalEstimate * (1-uss.percentAchieved))/story.originalEstimate\n",
    "         \n",
    "        data = []\n",
    "        data.append(unplanned)\n",
    "        data.append(completed)\n",
    "        data.append(planned_progressed)\n",
    "        data.append(planned_remaining)\n",
    "        data.append(not_started)\n",
    "        data.append(regressed)\n",
    "        data_df = pd.DataFrame(data, columns=cols)\n",
    "        return data_df\n",
    "    \n",
    "    # Returns a dataframe of merged dataframes across all sprints and teams for a given snaphot name.\n",
    "    # -snapshot_name: a string for the type of snapshot we will merge across all sprints and teams.\n",
    "    # Possible choices:\n",
    "    #   'planned_Start_CURRENT_SPRINT'\n",
    "    #   'planned_End_CURRENT_SPRINT'\n",
    "    #   'planned_Start_NEXT_SPRINT'\n",
    "    #   'planned_End_NEXT_SPRINT'\n",
    "    #   'backlog'\n",
    "    #   'Resourcing'    \n",
    "    #   'Outcome'    \n",
    "    def mergeLogs(self, snapshot_name):\n",
    "        log = self.log\n",
    "        frames = []\n",
    "        for teamId in log.keys():\n",
    "            for sprint in log[teamId].keys():\n",
    "                snapshot_df = log[teamId][sprint][snapshot_name]\n",
    "                snapshot_df['Team Id'] = teamId\n",
    "                snapshot_df['Sprint'] = sprint\n",
    "                frames.append(snapshot_df)\n",
    "        merged_df = pd.concat(frames)\n",
    "        merged_df = merged_df.reset_index().drop(columns=['index'])\n",
    "        return merged_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def runReleaseCycle(startDate, sprintDuration, numberOfSprints, modelsConfig):\n",
    "# Runs the dynamics of release cycle, iterating through all the sprints. For each sprint a WorkAssignment work sheet \n",
    "# is created for each team, recording what the team aims to do during the sprint. At the end of the sprint the \n",
    "# work sheet is updated with what was actually accomplished.\n",
    "#\n",
    "# This function returns two objects: a detailed timecards dataframe (one row for each row in any of the sheets, across all \n",
    "# teams and all sprints), and a ReleaseLog instance\n",
    "# The timecards dataframes has only scalars. The work sheet dataframe has WorkAssignment objects in one column, and an\n",
    "# informative list of backlog items not yet planned.\n",
    "#\n",
    "# Input parameters:\n",
    "# -startDate: a datetime object for when the release cycle starts\n",
    "# -sprintDuration: an integer representing the number of man-days that a sprint lasts.\n",
    "# -numberOfSprints: an integer, representing for how many sprints are we going to run the release. This should be set\n",
    "# high enough that all work (including delays and bug fixing) is completed within these numberOfSprints, even if the \n",
    "# original estimates are for much less. The reason for needing to set it high enough is that timecard entries will stop\n",
    "# after numberOfSprints.\n",
    "# -modelsConfig: a ModelsConfig instance. Has the simulation models and parameters used to drive the simulated release\n",
    "# cycle.\n",
    "    \n",
    "    timecards_dict = {'Sprint': [], 'Date': [], 'Team': [],'Developer': [], \\\n",
    "                      'User Story': [], 'Task Type': [], 'Task Description': [],'Time Spent': []}\n",
    "    \n",
    "    #Used to record how decisions are made at each sprint.\n",
    "    log = ReleaseLog()\n",
    "    \n",
    "    sprintEndDate = startDate\n",
    "    for n in range(numberOfSprints):\n",
    "        sprintEndDate = addBusinessDays(sprintEndDate, sprintDuration)\n",
    "        sprint = n+1\n",
    "        for team in modelsConfig.globalRepo.teamsRepo.teams:\n",
    "            teamId = team.teamId\n",
    "\n",
    "            # Set context to inform the environment in which decisions and events for this cycle occur\n",
    "            modelsConfig.context = ReleaseCycleContext(teamId, sprint, sprintDuration)\n",
    "            \n",
    "            log.snapshotSprintBacklog(modelsConfig) \n",
    "\n",
    "            # Do the sprint\n",
    "            work = chooseWhatToDoInSprint(modelsConfig) \n",
    "            log.snapshotSprintPlan(work, modelsConfig) \n",
    "\n",
    "            deliverSprint(work, modelsConfig) # mutates 'work'\n",
    "            inflow = inflowOfTickets(modelsConfig) #Bugs reported this sprint. Should be for stories completed on prior sprints\n",
    "            updateBacklogAfterSprint(work, modelsConfig) # Does not mutate 'work' but mutates the UserStoryStatus's\n",
    "            \n",
    "            log.snapshotSprintOutcome(work, modelsConfig) \n",
    "\n",
    "\n",
    "            sprintOutcome = work.committedTasks()\n",
    "            for index, row in sprintOutcome.iterrows():\n",
    "                timecards_dict['Sprint'].append(n+1)\n",
    "                timecards_dict['Date'].append(sprintEndDate)\n",
    "                timecards_dict['Developer'].append(row['Owner'])\n",
    "                timecards_dict['Team'].append(teamId)\n",
    "                timecards_dict['User Story'].append(row['User Story Id'])\n",
    "                timecards_dict['Task Type'].append(row['Task Type'])\n",
    "                timecards_dict['Task Description'].append(row['Task Description'])\n",
    "                timecards_dict['Time Spent'].append(row['Effort Spent']) #Even 0, record it to indicate it was in scope\n",
    "            # Boundary case: if we finished all work before all sprints are through, enter 0 time spent\n",
    "            if (sprintOutcome.index.size == 0):\n",
    "                timecards_dict['Sprint'].append(n+1)\n",
    "                timecards_dict['Date'].append(sprintEndDate)\n",
    "                timecards_dict['Developer'].append(None)\n",
    "                timecards_dict['Team'].append(teamId)\n",
    "                timecards_dict['User Story'].append(None)\n",
    "                timecards_dict['Task Type'].append(None)\n",
    "                timecards_dict['Task Description'].append(None)\n",
    "                timecards_dict['Time Spent'].append(0) \n",
    "                        \n",
    "    return pd.DataFrame(timecards_dict), log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Number of user stories worked on in a Sprint, either to implement or fix bugs on them\n",
    "def countUniques(seriesGroup):\n",
    "    cleanedSeriesGroup = pd.Series([x for x in seriesGroup if x != None]) # Remove nulls as they break the count of uniques\n",
    "    return cleanedSeriesGroup.unique().size\n",
    "\n",
    "def releaseBurnout(timecard):\n",
    "    \n",
    "    bystory             = timecard.groupby('User Story')\n",
    "    ends                = bystory['Sprint'].max()\n",
    "    starts              = bystory['Sprint'].min()\n",
    "\n",
    "    impl                = timecard[timecard['Task Type'] == S_.UNFINISHED_STORIES]\n",
    "    bugs                = timecard[timecard['Task Type'] == S_.DEV_TIME_BUGS]\n",
    "\n",
    "    bysprint_all        = timecard.groupby('Sprint')\n",
    "    bysprint_impl       = impl.groupby('Sprint')\n",
    "    bysprint_bugs       = bugs.groupby('Sprint')\n",
    "    \n",
    "    counts_all          = bysprint_all['User Story'].apply(lambda x: countUniques(x)) \n",
    "    counts_impl         = bysprint_impl['User Story'].apply(lambda x: countUniques(x)) \n",
    "    counts_bugs         = bysprint_bugs['User Story'].apply(lambda x: countUniques(x)) \n",
    "\n",
    "\n",
    "    efforts_all         = bysprint_all['Time Spent'].sum()\n",
    "    efforts_impl        = bysprint_impl['Time Spent'].sum()\n",
    "    efforts_bugs        = bysprint_bugs['Time Spent'].sum()\n",
    "\n",
    "    d = {'Sprint': [], 'Stories Started': [], 'Stories Active': [], 'Implementing (# stories)': [], \\\n",
    "         'Debugging (# stories)': [], 'Stories Completed': [], \\\n",
    "         'Effort': [], 'Implementation Effort': [], 'Debugging Effort': [], 'Active Developers': []}\n",
    "\n",
    "    # Initialize\n",
    "    for sprint in counts_all.index:\n",
    "        d['Sprint']                                 .append(sprint)\n",
    "        d['Stories Active']                         .append(counts_all[sprint])\n",
    "        if sprint in counts_impl.index:\n",
    "            d['Implementing (# stories)']           .append(counts_impl[sprint])\n",
    "        else:\n",
    "            d['Implementing (# stories)']           .append(0.0)\n",
    "        \n",
    "        if sprint in counts_bugs.index:\n",
    "            d['Debugging (# stories)']              .append(counts_bugs[sprint])\n",
    "        else:\n",
    "            d['Debugging (# stories)']              .append(0.0)\n",
    "        \n",
    "        d['Effort']                                 .append(efforts_all[sprint])\n",
    "        if sprint in efforts_impl.index:\n",
    "            d['Implementation Effort']              .append(efforts_impl[sprint])\n",
    "        else:\n",
    "            d['Implementation Effort']              .append(0.0)\n",
    "        if sprint in efforts_bugs.index:        \n",
    "            d['Debugging Effort']                   .append(efforts_bugs[sprint])\n",
    "        else:\n",
    "            d['Debugging Effort']                   .append(0.0)\n",
    "            \n",
    "        for s,group in bysprint_all:\n",
    "            if s==sprint: #found it\n",
    "                count = group['Developer'].unique().size\n",
    "                if (count == 1): #It might be that actually no developer has work left, if the 'unique' is None\n",
    "                    if (None == (group['Developer'].unique())[0]):\n",
    "                        count = 0\n",
    "                d['Active Developers'].append(count)\n",
    "\n",
    "        # Allocate space, we'll come back to set a value\n",
    "        d['Stories Completed'].append(0)\n",
    "        d['Stories Started'].append(0) \n",
    "\n",
    "    for story in ends.index:\n",
    "        sprint = ends[story]\n",
    "        if sprint in d['Sprint']:\n",
    "            idx = d['Sprint'].index(sprint)\n",
    "            d['Stories Completed'][idx] += 1\n",
    "        else:\n",
    "            d['Sprint'].append(sprint)\n",
    "            d['Stories Completed'].append(1)\n",
    "            d['Stories Started'].append(0) # Allocate space, we'll come back to set a value\n",
    "    for story in starts.index:\n",
    "        sprint = starts[story]\n",
    "        if sprint in d['Sprint']:\n",
    "            idx = d['Sprint'].index(sprint)\n",
    "            d['Stories Started'][idx] += 1\n",
    "        else:\n",
    "            d['Sprint'].append(sprint)\n",
    "            d['Stories Started'].append(1)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame(d)\n",
    "    return df.sort_values(by='Sprint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
