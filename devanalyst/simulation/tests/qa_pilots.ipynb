{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "#import math\n",
    "#from random import choices\n",
    "#import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib.colors import ListedColormap\n",
    "#import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\alex\\code\\labs\\devanalyst\\devanalyst\\simulation\\statics.ipynb\n",
      "importing Jupyter notebook from c:\\alex\\code\\labs\\devanalyst\\devanalyst\\simulation\\businessObjects.ipynb\n",
      "importing Jupyter notebook from c:\\alex\\code\\labs\\devanalyst\\devanalyst\\simulation\\simulationModels.ipynb\n",
      "importing Jupyter notebook from c:\\alex\\code\\labs\\devanalyst\\devanalyst\\simulation\\generateTimecards.ipynb\n"
     ]
    }
   ],
   "source": [
    "import devanalyst.simulation.statics as S_\n",
    "\n",
    "from devanalyst.simulation.businessObjects import WorkAssignments, ReleaseCycleContext\n",
    "from devanalyst.simulation.simulationModels import BalancedAllocationModel, GreedyAllocationModel, ModelsConfig, \\\n",
    "Distribution, DefaultCostModel, QualityModel\n",
    "\n",
    "import devanalyst.simulation.generateTimecards as timecard\n",
    "#from devanalyst.simulation.generateTimecards import WorkAssignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\alex\\code\\labs\\devanalyst\\devanalyst\\simulation\\tests\\test_utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import devanalyst.simulation.tests.test_utils as tu_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\alex\\code\\labs\\devanalyst\\devanalyst\\simulation\\visualizations\\simm_visuals.ipynb\n",
      "importing Jupyter notebook from c:\\alex\\code\\labs\\devanalyst\\devanalyst\\simulation\\visualizations\\timecard_visuals.ipynb\n"
     ]
    }
   ],
   "source": [
    "import devanalyst.simulation.visualizations.simm_visuals as simm_visuals\n",
    "import devanalyst.simulation.visualizations.timecard_visuals as tc_visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pilots</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bug inflow prototypes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DistributedLagQualityModel(QualityModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DistributedLagQualityModel, self).__init__()\n",
    "        return\n",
    "    \n",
    "    # Returns a list of Ticket instances.\n",
    "    # -modelsConfig: a ModelsConfig instance\n",
    "    def findBugs(self, modelsConfig): \n",
    "        uss_list = DistributedLagQualityModel._findFinishedStories(modelsConfig.context)\n",
    "        \n",
    "        bugs = []\n",
    "        current_sprint = modelsConfig.context.sprint\n",
    "        for uss in uss_list:\n",
    "            delivery_sprint = uss.sprintDelivered\n",
    "            lag = current_sprint - delivery_sprint\n",
    "            story = modelsConfig.context.storiesRepo.findStory(uss.userStoryId)\n",
    "            story_bugs = DistributedLagQualityModel._findDefectsInStory(lag, story, modelsConfig)\n",
    "            bugs.extend(story_bugs)\n",
    "        return bugs\n",
    "\n",
    "    # Returns a list of UserStoryStatus instances, corresponding to all user stories that have been finished.\n",
    "    def _findFinishedStories(context):\n",
    "        uss_list = []\n",
    "        ids = context.storiesRepo.findIds()\n",
    "        for userStoryId in ids:\n",
    "            uss = context.teamsRepo.getUserStoryStatus(userStoryId)\n",
    "            if (uss.percentAchieved == 1.0):\n",
    "                uss_list.append(uss)\n",
    "        return uss_list\n",
    "    \n",
    "    # Returns a list of Ticket instances\n",
    "    def _findDefectsInStory(lag, userStory, modelsConfig):\n",
    "        if lag < 1 or lag > 3: # No bugs for stories just finished or which were finished a while ago\n",
    "            return []\n",
    "        # Exposure is the probability of finding a bug. For now hardcode a 50% exposure distributed over \n",
    "        # 3 sprints with the surge in the middle one\n",
    "        if lag == 1:\n",
    "            exposure = 0.125\n",
    "        if lag == 2:\n",
    "            exposure = 0.25\n",
    "        if lag == 3:\n",
    "            exposure = 0.125\n",
    "        possible_defect_count  = [0, 1] # Possible values for number of bugs found\n",
    "        likelihoods            = [1-exposure, exposure]\n",
    "        defect_count           = modelsConfig.random.pickOneWithWeights(possible_defect_count, likelihoods)\n",
    "        \n",
    "        # Issue defect Tickets\n",
    "        defects = []\n",
    "        repo = modelsConfig.context.ticketsRepo\n",
    "        for i in range(defect_count):\n",
    "            costToFix = DistributedLagQualityModel._estimateCostToFix(userStory, modelsConfig)\n",
    "            ticket = repo.addTicket(userStory.userStoryId, costToFix)\n",
    "            defects.append(ticket)\n",
    "        return defects\n",
    "    \n",
    "        \n",
    "    def _estimateCostToFix(userStory, modelsConfig):\n",
    "    # For now hard-code a simplistic cost to fix: each bug costs 20% of the original estimate of the story.\n",
    "    # Better would be a percentage of the actual cost to develop.\n",
    "         return 0.20 * userStory.originalEstimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testTicketInflow(modelsConfig):\n",
    "    RELEASE_DURATION = 60\n",
    "    SPRINT_DURATION = 10\n",
    "    \n",
    "    tu_.loadTestResources()\n",
    "    \n",
    "    teams_df, stories_df, teamsRepo, storiesRepo, ticketsRepo = tu_.initTestData(tu_.DEV_DF, \\\n",
    "                                                                                           tu_.PM_DF, \\\n",
    "                                                                                           RELEASE_DURATION, \\\n",
    "                                                                                           SPRINT_DURATION, \\\n",
    "                                                                                          modelsConfig)\n",
    "    TEAM_ID = 'Team A'\n",
    "    SPRINT = 1    \n",
    "    ctx = ReleaseCycleContext(TEAM_ID, teamsRepo, storiesRepo, ticketsRepo, SPRINT, SPRINT_DURATION)\n",
    "    modelsConfig.context = ctx\n",
    "\n",
    "    # Pretend all stories have been completed on the first sprint\n",
    "    uss_list = []\n",
    "    ids = ctx.storiesRepo.findIds()\n",
    "    for userStoryId in ids:\n",
    "        uss = ctx.teamsRepo.getUserStoryStatus(userStoryId)\n",
    "        uss.percentAchieved = 1.0\n",
    "        uss.planned = True\n",
    "        uss.sprintPlanned = 1\n",
    "        uss.sprintDelivered = 1\n",
    "    \n",
    "    # Now pretend we raverse the next 5 sprints, generating bugs\n",
    "    bugs = []\n",
    "    for i in range(5):\n",
    "        ctx.sprint = SPRINT + i + 1\n",
    "        qualityModel = modelsConfig.qualityModels[0]\n",
    "        bugs.extend(qualityModel.findBugs(modelsConfig))\n",
    "    return bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -bugs: a list of Tickets\n",
    "def build_bugs_df(bugs):\n",
    "    bugs_dict = {}\n",
    "    bugs_dict['Ticket Id']        = []\n",
    "    bugs_dict['User Story Id']    = []\n",
    "    bugs_dict['Cost to Fix']      = []\n",
    "    bugs_dict['Effort to Date']   = []\n",
    "    bugs_dict['Percent Achieved'] = []\n",
    "    \n",
    "    for bug in bugs:\n",
    "        bugs_dict['Ticket Id']        .append(bug.ticketId)\n",
    "        bugs_dict['User Story Id']    .append(bug.userStoryId)\n",
    "        bugs_dict['Cost to Fix']      .append(bug.costToFix)\n",
    "        bugs_dict['Effort to Date']   .append(bug.effortToDate)\n",
    "        bugs_dict['Percent Achieved']  .append(bug.percentAchieved)\n",
    "        \n",
    "    bugs_df = pd.DataFrame(bugs_dict)\n",
    "    return bugs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -bmodelsConfig\n",
    "def build_stories_df(modelsConfig):\n",
    "    stories_dict = {}\n",
    "    stories_dict['User Story Id']          = []\n",
    "    stories_dict['Original Estimate']  = []\n",
    "    stories_dict['Developer']          = []\n",
    "    stories_dict['Product Manager']    = []\n",
    "    \n",
    "    repo = modelsConfig.context.storiesRepo\n",
    "    for storyId in repo.findIds():\n",
    "        story = repo.findStory(storyId)\n",
    "        stories_dict['User Story Id']       .append(story.userStoryId)\n",
    "        stories_dict['Original Estimate']   .append(story.originalEstimate)\n",
    "        stories_dict['Developer']           .append(story.developer)\n",
    "        stories_dict['Product Manager']     .append(story.productManager)\n",
    "        \n",
    "    stories_df = pd.DataFrame(stories_dict)\n",
    "    return stories_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket Id</th>\n",
       "      <th>User Story Id</th>\n",
       "      <th>Cost to Fix</th>\n",
       "      <th>Effort to Date</th>\n",
       "      <th>Percent Achieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ticket #1</td>\n",
       "      <td>UserStory #3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ticket #2</td>\n",
       "      <td>UserStory #10</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ticket #3</td>\n",
       "      <td>UserStory #15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ticket #4</td>\n",
       "      <td>UserStory #22</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket #5</td>\n",
       "      <td>UserStory #30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ticket #6</td>\n",
       "      <td>UserStory #36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticket Id  User Story Id  Cost to Fix  Effort to Date  Percent Achieved\n",
       "0  Ticket #1   UserStory #3          0.8             0.0               0.0\n",
       "1  Ticket #2  UserStory #10          1.8             0.0               0.0\n",
       "2  Ticket #3  UserStory #15          0.6             0.0               0.0\n",
       "3  Ticket #4  UserStory #22          0.6             0.0               0.0\n",
       "4  Ticket #5  UserStory #30          0.4             0.0               0.0\n",
       "5  Ticket #6  UserStory #36          2.0             0.0               0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsConfig = ModelsConfig([DefaultCostModel(0.25)], [DistributedLagQualityModel()], GreedyAllocationModel()) \n",
    "modelsConfig.random.reset(271)\n",
    "bugs = testTicketInflow(modelsConfig)\n",
    "bugs_df = build_bugs_df(bugs)\n",
    "bugs_df[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df['Cost to Fix'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Story Id</th>\n",
       "      <th>Original Estimate</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Product Manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UserStory #1</td>\n",
       "      <td>10</td>\n",
       "      <td>Beau Hockensmith</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UserStory #2</td>\n",
       "      <td>10</td>\n",
       "      <td>Glenna Mcghie</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UserStory #3</td>\n",
       "      <td>4</td>\n",
       "      <td>Francisco Hoppe</td>\n",
       "      <td>Edgar Hibbler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UserStory #4</td>\n",
       "      <td>7</td>\n",
       "      <td>Beau Hockensmith</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UserStory #5</td>\n",
       "      <td>3</td>\n",
       "      <td>Gregorio Darr</td>\n",
       "      <td>Edgar Hibbler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UserStory #6</td>\n",
       "      <td>3</td>\n",
       "      <td>Beau Hockensmith</td>\n",
       "      <td>Sherlyn Cordle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User Story Id  Original Estimate         Developer Product Manager\n",
       "0  UserStory #1                 10  Beau Hockensmith  Sherlyn Cordle\n",
       "1  UserStory #2                 10     Glenna Mcghie  Sherlyn Cordle\n",
       "2  UserStory #3                  4   Francisco Hoppe   Edgar Hibbler\n",
       "3  UserStory #4                  7  Beau Hockensmith  Sherlyn Cordle\n",
       "4  UserStory #5                  3     Gregorio Darr   Edgar Hibbler\n",
       "5  UserStory #6                  3  Beau Hockensmith  Sherlyn Cordle"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_df = build_stories_df(modelsConfig)\n",
    "stories_df[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1686"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stories_df['Original Estimate'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countUniques(seriesGroup):\n",
    "    if (seriesGroup.unique()[0] == None):\n",
    "        return 0\n",
    "    else:\n",
    "        return seriesGroup.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countUniques(bugs_df['User Story Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bugs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsConfig.context.sprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTX = modelsConfig.context\n",
    "TEAM_ID = 'Team A'\n",
    "work = WorkAssignments(TEAM_ID, CTX.teamsRepo, CTX.storiesRepo, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Owner</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>User Story Id</th>\n",
       "      <th>Planned for Sprint</th>\n",
       "      <th>Delivered in Sprint</th>\n",
       "      <th>Original Estimate</th>\n",
       "      <th>Bucket</th>\n",
       "      <th>Effort Spent</th>\n",
       "      <th>Effort Remaining</th>\n",
       "      <th>Percent Achieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Owner, Task Type, User Story Id, Planned for Sprint, Delivered in Sprint, Original Estimate, Bucket, Effort Spent, Effort Remaining, Percent Achieved]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work.committedTasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "team = CTX.teamsRepo.findTeam(TEAM_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<devanalyst.simulation.businessObjects.UserStoryStatus at 0x2206e83fb38>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team.backlog.pendingUserStories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTX.teamsRepo.getUserStoryStatus('UserStory #3').pendingTickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def genReleaseCycleSheets(modelsConfig):\n",
    "    RELEASE_DURATION = 60\n",
    "    SPRINT_DURATION = 10\n",
    "    \n",
    "    tu_.loadTestResources()\n",
    "    \n",
    "    teams_df, stories_df, teamsRepo, storiesRepo, ticketsRepo = tu_.initTestData(tu_.DEV_DF, \\\n",
    "                                                                                           tu_.PM_DF, \\\n",
    "                                                                                           RELEASE_DURATION, \\\n",
    "                                                                                           SPRINT_DURATION, \\\n",
    "                                                                                          modelsConfig)\n",
    "    \n",
    "    NUMBER_OF_SPRINTS = 25\n",
    "\n",
    "    entries_df, releaseLog = timecard.runReleaseCycle(teamsRepo, ticketsRepo, storiesRepo, datetime(2018, 1, 15), \\\n",
    "                                                   SPRINT_DURATION, NUMBER_OF_SPRINTS, modelsConfig)    \n",
    "    \n",
    "    return entries_df, releaseLog, teamsRepo, storiesRepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRINT_DURATION = 10\n",
    "modelsConfig = ModelsConfig([DefaultCostModel(0.25)], [DistributedLagQualityModel()], GreedyAllocationModel()) \n",
    "modelsConfig.random.reset(271)\n",
    "entries_df, releaseLog, TEAMS_REPO, STORIES_REPO = genReleaseCycleSheets(modelsConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_visuals.renderReleaseCycleLog('Team A', releaseLog, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_df = releaseLog.log['Team A'][1]['planned_End_CURRENT_SPRINT']\n",
    "end_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Burnout in release cycle - Pilot</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def genReleaseCycle(modelsConfig):\n",
    "    RELEASE_DURATION = 60\n",
    "    SPRINT_DURATION = 10\n",
    "    \n",
    "    tu_.loadTestResources()\n",
    "    \n",
    "    teams_df, stories_df, teamsRepo, storiesRepo, ticketsRepo = tu_.initTestData(tu_.DEV_DF, \\\n",
    "                                                                                           tu_.PM_DF, \\\n",
    "                                                                                           RELEASE_DURATION, \\\n",
    "                                                                                           SPRINT_DURATION, \\\n",
    "                                                                                          modelsConfig)\n",
    "    \n",
    "    NUMBER_OF_SPRINTS = 25\n",
    "\n",
    "    entries_df, worksheets = timecard.runReleaseCycle(teamsRepo, ticketsRepo, storiesRepo, datetime(2018, 1, 15), \\\n",
    "                                                   SPRINT_DURATION, NUMBER_OF_SPRINTS, modelsConfig)    \n",
    "    \n",
    "    return entries_df, worksheets, storiesRepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genBurnout(entries_df, storiesRepo):\n",
    "    bystory = entries_df.groupby('User Story')\n",
    "    u = bystory.apply(storyInfo, storiesRepo)\n",
    "    \n",
    "    \n",
    "    u = u.reset_index()\n",
    "    u.drop(['level_1'], axis='columns', inplace=True)\n",
    "    s = u.groupby('Final Sprint')\n",
    "    burnout = s.apply(sprintInfo)\n",
    "    burnout = burnout.reset_index()\n",
    "    burnout.drop(['level_1'], axis='columns', inplace=True)\n",
    "    \n",
    "\n",
    "    return burnout, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storyInfo(group_df, storiesRepo):\n",
    "    info = {}\n",
    "    \n",
    "    #Go back, as min['Date'] is end of first sprint\n",
    "    info['Start'] = [timecard.subtractBusinessDays(group_df['Date'].min(), SPRINT_DURATION)] \n",
    "    info['End'] = [group_df['Date'].max()]\n",
    "    info['Elapsed Time'] = (info['End'][0] - info['Start'][0]).days\n",
    "    info['Effort'] = group_df['Time Spent'].sum()\n",
    "    info['Initial Sprint'] = [group_df['Sprint'].min()]\n",
    "    info['Final Sprint'] = [group_df['Sprint'].max()]  \n",
    "    '''\n",
    "    userStoryId = group_df['User Story']\n",
    "    userStory = storiesRepo.findStory(userStoryId)\n",
    "    info['Original estimate'] = userStory.originalEstimate    \n",
    "    '''\n",
    "    \n",
    "    return pd.DataFrame(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sprintInfo(group_df):\n",
    "    info = {}\n",
    "    \n",
    "    info['Effort'] = group_df['Effort'].sum()\n",
    "    info['Avg Effort'] = group_df['Effort'].mean()\n",
    "    info['Stories Completed'] = [group_df['User Story'].count()]\n",
    "    info['Over 1 sprint'] = [group_df[group_df['Elapsed Time']==14]['User Story'].count()]\n",
    "    info['Over 2 sprint'] = [group_df[group_df['Elapsed Time']==28]['User Story'].count()]\n",
    "    info['Over 3 sprint'] = [group_df[group_df['Elapsed Time']==42]['User Story'].count()]\n",
    "    info['Over 4 sprint'] = [group_df[group_df['Elapsed Time']==56]['User Story'].count()]\n",
    " \n",
    "    \n",
    "    return pd.DataFrame(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRINT_DURATION = 10\n",
    "modelsConfig1 = ModelsConfig([DefaultCostModel(0.0)], [], BalancedAllocationModel(SPRINT_DURATION)) \n",
    "modelsConfig1.random.reset(271)\n",
    "entries_df1, worksheets1, storiesRepo = genReleaseCycle(modelsConfig1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn1, u1 = genBurnout(entries_df1, storiesRepo)\n",
    "burn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPRINT_DURATION = 10\n",
    "modelsConfig2 = ModelsConfig([DefaultCostModel(0.0)], [], GreedyAllocationModel(SPRINT_DURATION)) \n",
    "modelsConfig2.random.reset(271)\n",
    "entries_df2, worksheets2, storiesRepo = genReleaseCycle(modelsConfig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn2, u2 = genBurnout(entries_df2, storiesRepo)\n",
    "burn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn1['Effort'].plot(label = 'Balanced'), burn2['Effort'].plot(label = 'Greedy'), plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn1['Avg Effort'].plot(label = 'Balanced'), burn2['Avg Effort'].plot(label = 'Greedy'), plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1_10 = u1[u1['Final Sprint'] == 10]\n",
    "u1_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1_10[u1_10['Initial Sprint'] == 10]['Effort'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1_10['Effort'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1_10[u1_10['Initial Sprint'] == 10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1_10[u1_10['Initial Sprint'] == 9]['Effort'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1_10[u1_10['Initial Sprint'] == 9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
